# 分离式架构支持

SGLang支持预填充和解码分离的分离式架构，允许将预填充和解码过程分别部署在不同的服务器上，以支持超大模型和提高资源利用率。

## 分离模式类型

SGLang定义了三种分离模式：

```python
class DisaggregationMode(Enum):
    NULL = "null"           # 非分离模式（标准模式）
    PREFILL = "prefill"     # 预填充服务器模式
    DECODE = "decode"       # 解码服务器模式
```

## 预填充分离架构

### PrefillBootstrapQueue

预填充服务器使用PrefillBootstrapQueue管理传入的请求：

```python
class PrefillBootstrapQueue:
    """预填充启动队列管理器"""
    
    def __init__(self, 
                 max_total_num_tokens: int,
                 kv_manager: BaseKVManager,
                 transfer_backend: TransferBackend,
                 bootstrap_port: int,
                 tp_rank: int,
                 pp_rank: int,
                 scheduler: Scheduler):
        self.max_total_num_tokens = max_total_num_tokens
        self.kv_manager = kv_manager
        self.transfer_backend = transfer_backend
        self.bootstrap_port = bootstrap_port
        self.tp_rank = tp_rank
        self.pp_rank = pp_rank
        self.scheduler = scheduler
        self.queue: List[Req] = []

    def add(self, req: Req, num_kv_heads: int) -> None:
        """添加请求到预填充队列"""
        if self._check_if_req_exceed_kv_capacity(req):
            return

        # 创建KV发送器
        if req.bootstrap_host == FAKE_BOOTSTRAP_HOST:
            kv_sender_class = get_kv_class(TransferBackend.FAKE, KVClassType.SENDER)
        else:
            kv_sender_class = get_kv_class(self.transfer_backend, KVClassType.SENDER)

        dest_tp_ranks = [self.tp_rank]

        req.disagg_kv_sender = kv_sender_class(
            mgr=self.kv_manager,
            bootstrap_addr=f"{req.bootstrap_host}:{self.bootstrap_port}",
            bootstrap_room=req.bootstrap_room,
            dest_tp_ranks=dest_tp_ranks,
            pp_rank=self.pp_rank,
        )
        self._process_req(req)
        self.queue.append(req)

    def extend(self, reqs: List[Req], num_kv_heads: int) -> None:
        """批量添加请求"""
        for req in reqs:
            self.add(req, num_kv_heads)

    def _check_if_req_exceed_kv_capacity(self, req: Req) -> bool:
        """检查请求是否超出KV容量限制"""
        if len(req.origin_input_ids) > self.max_total_num_tokens:
            message = f"Request {req.rid} exceeds the maximum number of tokens: {len(req.origin_input_ids)} > {self.max_total_num_tokens}"
            logger.error(message)
            prepare_abort(req, message, status_code=HTTPStatus.BAD_REQUEST)
            self.scheduler.stream_output([req], req.return_logprob)
            return True
        return False

    def _process_req(self, req: Req) -> None:
        """处理请求，设置max_new_tokens=1以便PrefillAdder内存估算准确"""
        req.sampling_params.max_new_tokens = 1
```

### 预填充事件循环

预填充服务器有专门的事件循环：

```python
@DynamicGradMode()
def event_loop_normal_disagg_prefill(self: Scheduler):
    """预填充服务器的标准事件循环"""
    while True:
        # 接收和处理请求
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        # 从启动队列获取可运行的请求
        can_run_list = self.disagg_prefill_bootstrap_queue.pop_bootstrapped()
        
        if can_run_list:
            # 创建预填充批次
            batch = self.get_new_batch_prefill_from_disagg_queue(can_run_list)
            if batch:
                result = self.run_batch(batch)
                self.process_batch_result(batch, result)
        else:
            self.self_check_during_idle()

@DynamicGradMode()
def event_loop_overlap_disagg_prefill(self: Scheduler):
    """预填充服务器的重叠事件循环"""
    self.result_queue = deque()
    
    while True:
        # 接收和处理请求
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        # 获取可运行请求并创建批次
        can_run_list = self.disagg_prefill_bootstrap_queue.pop_bootstrapped()
        batch = None
        if can_run_list:
            batch = self.get_new_batch_prefill_from_disagg_queue(can_run_list)

        if batch:
            batch.launch_done = threading.Event()
            result = self.run_batch(batch)
            self.result_queue.append((batch.copy(), result))

        # 处理上一批次的结果
        if self.last_batch:
            tmp_batch, tmp_result = self.result_queue.popleft()
            tmp_batch.next_batch_sampling_info = None
            self.process_batch_result(tmp_batch, tmp_result, 
                                    batch.launch_done if batch else None)
        elif batch is None:
            self.self_check_during_idle()

        self.last_batch = batch
```

## 解码分离架构

### 解码队列管理

解码服务器使用两个队列管理请求：

```python
class DecodePreallocQueue:
    """解码预分配队列"""
    
    def add(self, req: Req) -> None:
        """添加请求到预分配队列"""
        self.queue.append(req)
    
    def extend(self, reqs: List[Req], is_retracted: bool = False) -> None:
        """批量添加请求"""
        if is_retracted:
            # 回退的请求优先处理
            self.queue = reqs + self.queue
        else:
            self.queue.extend(reqs)

class DecodeTransferQueue:
    """解码传输队列"""
    
    def add(self, req: Req) -> None:
        """添加已准备好的请求到传输队列"""
        self.queue.append(req)
    
    def pop_ready(self) -> List[Req]:
        """弹出准备好进行解码的请求"""
        ready_reqs = []
        remaining_reqs = []
        
        for req in self.queue:
            if req.disagg_kv_receiver.is_ready():
                ready_reqs.append(req)
            else:
                remaining_reqs.append(req)
        
        self.queue = remaining_reqs
        return ready_reqs
```

### 解码批次创建

```python
def get_new_prebuilt_batch(self: Scheduler) -> Optional[ScheduleBatch]:
    """为伪造的已完成预填充创建调度批次"""
    if self.grammar_queue:
        self.move_ready_grammar_requests()

    if len(self.waiting_queue) == 0:
        return None

    curr_batch_size = self.running_batch.batch_size()
    batch_size = min(self.req_to_token_pool.size, self.max_running_requests)
    num_not_used_batch = batch_size - curr_batch_size

    # 从等待队列弹出请求
    can_run_list: List[Req] = []
    waiting_queue: List[Req] = []

    for i in range(len(self.waiting_queue)):
        req = self.waiting_queue[i]
        # 只能添加不超过num_not_used_batch的新批次到运行队列
        if i < num_not_used_batch:
            can_run_list.append(req)
            req.init_next_round_input(self.tree_cache)
        else:
            waiting_queue.append(req)

    self.waiting_queue = waiting_queue
    if len(can_run_list) == 0:
        return None

    # 使用这些请求构造调度批次并标记为解码
    new_batch = ScheduleBatch.init_new(
        can_run_list,
        self.req_to_token_pool,
        self.token_to_kv_pool_allocator,
        self.tree_cache,
        self.model_config,
        self.enable_overlap,
        self.spec_algorithm,
    )

    # 构造伪造的已完成预填充
    new_batch.prepare_for_prebuilt_extend()
    new_batch.process_prebuilt_extend(self.server_args, self.model_config)

    return new_batch
```

### 解码事件循环

```python
@DynamicGradMode()
def event_loop_normal_disagg_decode(self: Scheduler):
    """解码服务器的标准事件循环"""
    while True:
        # 处理解码队列
        self.process_decode_queue()
        
        # 接收和处理请求
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        # 获取下一个要运行的批次
        batch = self.get_next_disagg_decode_batch_to_run()
        self.cur_batch = batch

        if batch:
            result = self.run_batch(batch)
            self.process_batch_result(batch, result)
        else:
            self.self_check_during_idle()

        self.last_batch = batch

@DynamicGradMode()
def event_loop_overlap_disagg_decode(self: Scheduler):
    """解码服务器的重叠事件循环"""
    result_queue = deque()
    
    while True:
        # 处理解码队列
        self.process_decode_queue()
        
        # 接收和处理请求
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        # 获取批次
        batch = self.get_next_disagg_decode_batch_to_run()
        self.cur_batch = batch

        if batch:
            batch.launch_done = threading.Event()
            result = self.run_batch(batch)
            result_queue.append((batch.copy(), result))

        # 处理上一批次结果
        if self.last_batch:
            tmp_batch, tmp_result = result_queue.popleft()
            tmp_batch.next_batch_sampling_info = (
                self.tp_worker.cur_sampling_info if batch else None
            )
            self.process_batch_result(
                tmp_batch, tmp_result, batch.launch_done if batch else None
            )
        elif batch is None:
            self.self_check_during_idle()

        self.last_batch = batch
```

## KV传输机制

### KV发送器和接收器

分离式架构通过KV发送器和接收器在预填充和解码服务器之间传输KV缓存：

```python
class BaseKVSender:
    """KV缓存发送器基类"""
    
    def send_kv_cache(self, req: Req, kv_data: torch.Tensor):
        """发送KV缓存数据到解码服务器"""
        raise NotImplementedError

class BaseKVReceiver:
    """KV缓存接收器基类"""
    
    def receive_kv_cache(self, req: Req) -> torch.Tensor:
        """从预填充服务器接收KV缓存数据"""
        raise NotImplementedError
    
    def is_ready(self) -> bool:
        """检查KV缓存是否准备就绪"""
        raise NotImplementedError
```

### 传输后端

SGLang支持多种传输后端：

```python
class TransferBackend(Enum):
    FAKE = "fake"           # 假传输（测试用）
    NCCL = "nccl"          # NCCL传输
    GLOO = "gloo"          # Gloo传输
    TCP = "tcp"            # TCP传输
```

## 监控和调试

分离式架构需要额外的监控指标：

```python
def log_decode_stats(self, can_run_cuda_graph: bool, running_batch: ScheduleBatch = None):
    """记录解码阶段统计信息，包括分离式架构指标"""
    
    # 处理分离式架构的额外指标
    if self.disaggregation_mode == DisaggregationMode.DECODE:
        self.stats.num_decode_prealloc_queue_reqs = len(
            self.disagg_decode_prealloc_queue.queue
        )
        self.stats.num_decode_transfer_queue_reqs = len(
            self.disagg_decode_transfer_queue.queue
        )
    
    # 发送标准指标
    self.metrics_collector.log_stats(self.stats)
```

## 部署配置

### 预填充服务器配置

```python
server_args = ServerArgs(
    model_path="model_name",
    disaggregation_mode="prefill",
    disaggregation_bootstrap_port=8001,
    kv_transfer_backend="nccl",
    # 其他预填充服务器配置...
)
```

### 解码服务器配置

```python
server_args = ServerArgs(
    model_path="model_name", 
    disaggregation_mode="decode",
    disaggregation_bootstrap_port=8001,
    kv_transfer_backend="nccl",
    # 其他解码服务器配置...
)
```

## 总结

SGLang的分离式架构支持具有以下特点：

**核心功能**:
- 预填充和解码过程完全分离
- 专门的队列管理系统
- 高效的KV缓存传输机制
- 多种传输后端支持

**架构优势**:
- 支持超大模型的分布式推理
- 提高资源利用率和系统可扩展性
- 独立的事件循环优化不同阶段的性能
- 完整的监控和调试支持

**适用场景**:
- 超大语言模型推理（如175B+参数模型）
- 资源受限的部署环境
- 需要独立扩展预填充和解码能力的场景
- 多租户部署环境

分离式架构是SGLang支持超大模型推理的重要特性，通过将计算密集的预填充和内存密集的解码分离，实现了更好的资源利用和系统扩展性。
