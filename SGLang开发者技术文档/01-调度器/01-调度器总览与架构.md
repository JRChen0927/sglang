# 调度器总览与架构

SGLang的调度器是整个推理系统的核心组件，负责管理张量并行GPU worker的工作协调。作为系统的"大脑"，调度器承担着请求调度、批处理优化、资源管理和并行协调等关键职责。

## 核心职责

调度器的主要职责包括以下几个方面：

**请求生命周期管理**  
从接收用户请求开始，调度器负责整个请求的生命周期管理，包括请求验证、排队调度、批次组织、推理执行和结果返回的全流程控制。

**批处理优化**  
调度器实现了动态批处理机制，能够智能地将多个请求组织成批次进行处理，最大化GPU的利用率和系统吞吐量。

**资源统一调度**  
调度器统一管理GPU内存、KV缓存、计算资源等系统资源，确保资源的高效分配和使用。

**多维并行协调**  
在分布式环境下，调度器协调张量并行、流水线并行、数据并行和专家并行等多种并行策略。

## 架构设计

### Mixin模式设计

SGLang调度器采用多重继承的Mixin模式，将不同功能模块解耦，实现高度的模块化设计：

```python
class Scheduler(
    SchedulerOutputProcessorMixin,
    SchedulerUpdateWeightsMixin,
    SchedulerProfilerMixin,
    SchedulerMetricsMixin,
    SchedulerDisaggregationDecodeMixin,
    SchedulerDisaggregationPrefillMixin,
):
    """A scheduler that manages a tensor parallel GPU worker."""
```

每个Mixin类负责特定的功能领域，这种设计带来了良好的代码组织和可维护性：

**SchedulerOutputProcessorMixin**: 处理模型输出和流式响应，包括预填充和解码结果的处理、流式传输控制等。

**SchedulerUpdateWeightsMixin**: 支持动态权重更新，包括从磁盘加载权重、分布式权重更新、张量权重更新等功能：

```python
def update_weights_from_disk(self, recv_req: UpdateWeightFromDiskReqInput):
    """从磁盘就地更新权重"""
    success, message = self.tp_worker.update_weights_from_disk(recv_req)
    if success:
        flush_cache_success = self.flush_cache()
        assert flush_cache_success, "权重更新后缓存刷新失败"
    return UpdateWeightFromDiskReqOutput(success, message, 0)
```

**SchedulerProfilerMixin**: 提供性能分析功能，支持PyTorch profiler集成和自定义性能指标收集。

**SchedulerMetricsMixin**: 负责指标收集，包括吞吐量、延迟、缓存命中率等关键性能指标的统计。

**SchedulerDisaggregationDecodeMixin/PrefillMixin**: 支持预填充和解码分离的分离式架构，用于超大模型的分布式推理。

### 并行配置管理

调度器的初始化过程中，需要处理复杂的并行配置。在__init__方法中，调度器解析各种并行参数：

```python
def __init__(self, server_args: ServerArgs, port_args: PortArgs, gpu_id: int,
             tp_rank: int, moe_ep_rank: int, pp_rank: int, dp_rank: Optional[int]):
    # 解析并行配置
    self.tp_rank = tp_rank              # 张量并行rank
    self.moe_ep_rank = moe_ep_rank      # 专家并行rank
    self.pp_rank = pp_rank              # 流水线并行rank
    self.dp_rank = dp_rank              # 数据并行rank
    self.tp_size = server_args.tp_size  # 张量并行大小
    self.moe_ep_size = server_args.ep_size
    self.pp_size = server_args.pp_size
    self.dp_size = server_args.dp_size
```

这些参数定义了当前调度器实例在分布式系统中的位置和作用范围，是后续所有并行协调工作的基础。

## 事件循环架构

调度器的核心工作机制是事件循环，根据不同的配置和优化需求，SGLang提供了多种事件循环实现：

**标准事件循环**  
event_loop_normal是最基础的事件循环实现，采用串行处理模式，逻辑清晰，适合调试和开发环境。

**重叠事件循环**  
event_loop_overlap实现了CPU处理和GPU计算的重叠，能够显著提升系统吞吐量，适合生产环境。

**流水线并行事件循环**  
event_loop_pp专门为流水线并行设计，支持大模型的分层处理，能够有效利用多个GPU节点。

**分离式事件循环**  
针对预填充和解码分离的场景，提供了专门的事件循环实现，包括event_loop_overlap_disagg_prefill和event_loop_normal_disagg_decode等。

### 事件循环选择逻辑

调度器根据配置参数自动选择合适的事件循环：

```python
disaggregation_mode = scheduler.disaggregation_mode
if disaggregation_mode == DisaggregationMode.NULL:
    if server_args.pp_size > 1:
        scheduler.event_loop_pp()
    elif scheduler.enable_overlap:
        scheduler.event_loop_overlap()
    else:
        scheduler.event_loop_normal()
```

这种自动选择机制确保了调度器能够根据部署配置选择最优的执行模式。

## 请求分发机制

### TypeBasedDispatcher架构

调度器使用TypeBasedDispatcher来分发不同类型的请求：

```python
# 初始化请求分发器
self._request_dispatcher = TypeBasedDispatcher([
    (TokenizedGenerateReqInput, self.handle_generate_request),
    (TokenizedEmbeddingReqInput, self.handle_embedding_request),
    (FlushCacheReqInput, self.flush_cache_wrapped),
    (AbortReq, self.abort_request),
    (OpenSessionReqInput, self.open_session),
    (CloseSessionReqInput, self.close_session),
    (UpdateWeightFromDiskReqInput, self.update_weights_from_disk),
    (InitWeightsUpdateGroupReqInput, self.init_weights_update_group),
    (UpdateWeightsFromDistributedReqInput, self.update_weights_from_distributed),
    (UpdateWeightsFromTensorReqInput, self.update_weights_from_tensor),
    (GetWeightsByNameReqInput, self.get_weights_by_name),
    (ReleaseMemoryOccupationReqInput, self.release_memory_occupation),
    (ResumeMemoryOccupationReqInput, self.resume_memory_occupation),
    (SlowDownReqInput, self.slow_down),
    (ProfileReq, self.profile),
    (LoadLoRAAdapterReqInput, self.load_lora_adapter),
    (UnloadLoRAAdapterReqInput, self.unload_lora_adapter),
])
```

这种设计支持了十多种不同类型的请求，从基本的生成和嵌入请求，到高级的权重更新、性能分析、LoRA适配器管理等功能。

## 核心方法解析

### 请求处理流程

调度器通过一系列核心方法处理请求：

**recv_requests方法**负责从网络接收新的请求，支持分布式环境下的请求广播和同步。

**process_input_requests方法**处理接收到的请求，包括请求验证、类型分发和异常处理。

**handle_generate_request方法**专门处理生成类请求，创建Req对象并加入调度队列。

**handle_embedding_request方法**处理嵌入类请求，支持向量检索等应用场景。

### 批处理管理

**get_next_batch_to_run方法**是批处理调度的核心，负责从等待队列中选择请求组成批次。

**get_new_batch_prefill方法**创建新的预填充批次，实现动态批处理和连续批处理。

**run_batch方法**执行批次推理，调用底层的模型运行器进行GPU计算。

**process_batch_result方法**处理推理结果，包括输出解码、流式传输和请求完成检查。

### 系统维护

**self_check_during_idle方法**在系统空闲时执行自检和状态重置，确保系统的长期稳定运行。

**flush_cache方法**提供缓存清理功能，支持系统状态重置。

**watchdog_thread方法**实现看门狗机制，监控系统健康状态。

## 内存和资源管理

调度器统一管理系统的内存和计算资源。在初始化过程中，调度器会创建和配置各种资源管理组件，包括内存池、KV缓存、RadixCache等。这些组件协同工作，确保内存的高效使用和缓存的智能管理。

调度器还负责请求的资源分配和回收，确保每个请求都能获得足够的资源进行处理，同时在请求完成后及时释放资源供其他请求使用。

## 并行策略协调

在分布式环境下，调度器需要协调多种并行策略。张量并行通过rank和size参数进行控制，调度器确保所有张量并行worker之间的同步和协调。流水线并行通过专门的事件循环实现，调度器管理不同pipeline stage之间的数据传递。数据并行通过balance_meta进行负载均衡，调度器监控各个副本的负载情况。专家并行处理MoE模型的专家分布，调度器协调不同专家之间的计算任务分配。

## 性能监控和调试

调度器内置了完善的性能监控和调试功能。通过SchedulerMetricsMixin，调度器能够收集各种运行时指标，包括请求处理延迟、批次大小、资源利用率等。SchedulerProfilerMixin提供了详细的性能分析功能，能够帮助开发者识别性能瓶颈和优化机会。

调度器还支持请求状态转储、内存使用监控、缓存命中率统计等调试功能，为系统优化和问题排查提供了强有力的工具。

## 总结

SGLang调度器通过精心设计的架构和丰富的功能，为高性能语言模型推理提供了强大的调度能力。其Mixin模式的设计确保了功能的模块化和可扩展性，多种事件循环模式适应了不同的部署场景，完善的资源管理和并行协调机制支撑了大规模分布式推理，而内置的监控和调试功能则为系统的稳定运行提供了保障。理解调度器的设计理念和工作原理，是掌握SGLang系统的关键所在。
