# 调度器总览与架构

---

SGLang的调度器是整个推理系统的核心组件，负责管理张量并行GPU worker的工作协调。作为系统的"大脑"，调度器承担着请求调度、批处理优化、资源管理和并行协调等关键职责。

---

## 1. 核心职责

调度器的主要职责包括以下几个方面：

**请求生命周期管理**  
从接收用户请求开始，调度器负责整个请求的生命周期管理，包括请求验证、排队调度、批次组织、推理执行和结果返回的全流程控制。

**批处理优化**  
调度器实现了动态批处理机制，能够智能地将多个请求组织成批次进行处理，最大化GPU的利用率和系统吞吐量。

**资源统一调度**  
调度器统一管理GPU内存、KV缓存、计算资源等系统资源，确保资源的高效分配和使用。

**多维并行协调**  
在分布式环境下，调度器协调张量并行、流水线并行、数据并行和专家并行等多种并行策略。

---

## 2. 架构设计

### 2.1 Mixin模式设计

SGLang调度器采用多重继承的Mixin模式，将不同功能模块解耦，实现高度的模块化设计。

**调度器类定义的核心思路**：通过继承6个Mixin类，每个类专注于特定功能领域，避免了单一类过于庞大的问题。这种设计让代码更加清晰，便于维护和扩展。调度器的初始化过程包含并行配置解析、核心组件创建和请求分发器设置三个关键步骤。

> 📝 **简化说明**：以下代码为教学简化版本，突出核心概念。真实实现包含更多初始化步骤，如内存池创建、缓存配置、监控设置等。

```python
class Scheduler(
    SchedulerOutputProcessorMixin,
    SchedulerUpdateWeightsMixin,
    SchedulerProfilerMixin,
    SchedulerMetricsMixin,
    SchedulerDisaggregationDecodeMixin,
    SchedulerDisaggregationPrefillMixin,
):
    """A scheduler that manages a tensor parallel GPU worker."""
    
    def __init__(self, server_args: ServerArgs, port_args: PortArgs, 
                 gpu_id: int, tp_rank: int, moe_ep_rank: int, 
                 pp_rank: int, dp_rank: Optional[int]):
        # 并行配置参数
        self.tp_rank = tp_rank              # 张量并行rank
        self.moe_ep_rank = moe_ep_rank      # 专家并行rank  
        self.pp_rank = pp_rank              # 流水线并行rank
        self.dp_rank = dp_rank              # 数据并行rank
        self.tp_size = server_args.tp_size  # 张量并行大小
        
        # 核心组件（简化版）
        self.running_batch = ScheduleBatch(reqs=[])
        self.waiting_queue = []
        self.forward_ct = 0
        
        # 请求分发器（简化版）
        self._request_dispatcher = TypeBasedDispatcher([
            (TokenizedGenerateReqInput, self.handle_generate_request),
            (TokenizedEmbeddingReqInput, self.handle_embedding_request),
            (FlushCacheReqInput, self.flush_cache),
            # ... 更多请求类型
        ])
```

每个Mixin类负责特定的功能领域，这种设计带来了良好的代码组织和可维护性：

**SchedulerOutputProcessorMixin**: 处理模型输出和流式响应，包括预填充和解码结果的处理、流式传输控制等。

**SchedulerUpdateWeightsMixin**: 支持动态权重更新，包括从磁盘加载权重、分布式权重更新、张量权重更新等功能。

**SchedulerProfilerMixin**: 提供性能分析功能，支持PyTorch profiler集成和自定义性能指标收集。

**SchedulerMetricsMixin**: 负责指标收集，包括吞吐量、延迟、缓存命中率等关键性能指标的统计。

**SchedulerDisaggregationDecodeMixin/PrefillMixin**: 支持预填充和解码分离的分离式架构，用于超大模型的分布式推理。

### 2.2 并行配置管理

调度器的初始化过程中，需要处理复杂的并行配置。这些参数定义了当前调度器在分布式系统中的角色和位置，是后续所有并行协调工作的基础。

```python
def __init__(self, server_args: ServerArgs, port_args: PortArgs, gpu_id: int,
             tp_rank: int, moe_ep_rank: int, pp_rank: int, dp_rank: Optional[int]):
    # 解析并行配置
    self.tp_rank = tp_rank              # 张量并行rank
    self.moe_ep_rank = moe_ep_rank      # 专家并行rank
    self.pp_rank = pp_rank              # 流水线并行rank
    self.dp_rank = dp_rank              # 数据并行rank
    self.tp_size = server_args.tp_size  # 张量并行大小
    self.moe_ep_size = server_args.ep_size
    self.pp_size = server_args.pp_size
    self.dp_size = server_args.dp_size
```

这些参数定义了当前调度器实例在分布式系统中的位置和作用范围，是后续所有并行协调工作的基础。

> 💡 **深入学习**：想了解Req、ScheduleBatch等核心数据抽象是如何设计的吗？[02-核心数据结构](02-核心数据结构.md) 详细解析了这些数据结构的完整字段、相互关系和演进历程

---

## 3. 事件循环架构

调度器的核心工作机制是事件循环，根据不同的配置和优化需求，SGLang提供了多种事件循环实现：

**标准事件循环**  
event_loop_normal是最基础的事件循环实现，采用串行处理模式，逻辑清晰，适合调试和开发环境。

**重叠事件循环**  
event_loop_overlap实现了CPU处理和GPU计算的重叠，能够显著提升系统吞吐量，适合生产环境。

**流水线并行事件循环**  
event_loop_pp专门为流水线并行设计，支持大模型的分层处理，能够有效利用多个GPU节点。

**分离式事件循环**  
针对预填充和解码分离的场景，提供了专门的事件循环实现，包括event_loop_overlap_disagg_prefill和event_loop_normal_disagg_decode等。

### 3.1 事件循环选择逻辑

**事件循环的智能选择机制**：SGLang根据部署配置自动选择最适合的事件循环类型，首先判断是否启用分离式架构，然后根据流水线并行和CPU-GPU重叠设置选择具体实现。

> 📝 **简化说明**：以下为核心选择逻辑的简化版本，真实实现包含更多条件判断和边界情况处理。

```python
# 事件循环自动选择策略（简化版）
if disaggregation_mode == DisaggregationMode.NULL:
    if server_args.pp_size > 1:
        scheduler.event_loop_pp()          # 流水线并行
    elif scheduler.enable_overlap:
        scheduler.event_loop_overlap()     # CPU-GPU重叠
    else:
        scheduler.event_loop_normal()      # 标准同步
elif disaggregation_mode == DisaggregationMode.PREFILL:
    scheduler.event_loop_disagg_prefill()  # 分离式预填充
elif disaggregation_mode == DisaggregationMode.DECODE:
    scheduler.event_loop_disagg_decode()   # 分离式解码
```

**标准事件循环的工作原理**：采用简单的串行处理模式，每次循环包含三个核心步骤：接收和处理新请求、获取待运行的批次、执行推理或进行空闲检查。

> 📝 **简化说明**：以下为标准事件循环的核心流程简化版本，突出主要步骤。真实实现包含更多错误处理、性能监控和状态管理逻辑。

```python
def event_loop_normal(self):
    """标准调度器循环（简化版）"""
    while True:
        # 1. 接收新请求
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        # 2. 获取下一个批次
        batch = self.get_next_batch_to_run()

        # 3. 执行推理或空闲检查
        if batch:
            result = self.run_batch(batch)
            self.process_batch_result(batch, result)
        else:
            self.self_check_during_idle()
```

### 3.2 源码实现细节

**调度器进程启动的完整流程**：这个函数展示了SGLang调度器从创建到运行的完整过程。首先创建调度器实例，然后向主进程报告就绪状态，最后根据复杂的条件逻辑选择合适的事件循环。这种设计确保了调度器能够适应各种部署场景的需求。

```python
def run_scheduler_process(server_args, port_args, gpu_id, tp_rank, 
                         moe_ep_rank, pp_rank, dp_rank, pipe_writer, balance_meta):
    """真实的调度器进程启动和事件循环选择"""
    # 创建调度器实例
    scheduler = Scheduler(server_args, port_args, gpu_id, tp_rank, 
                         moe_ep_rank, pp_rank, dp_rank, dp_balance_meta=balance_meta)
    
    # 发送就绪状态
    pipe_writer.send({
        "status": "ready",
        "max_total_num_tokens": scheduler.max_total_num_tokens,
        "max_req_input_len": scheduler.max_req_input_len,
    })

    # 复杂的事件循环选择逻辑
    disaggregation_mode = scheduler.disaggregation_mode
    if disaggregation_mode == DisaggregationMode.NULL:
        if server_args.pp_size > 1:
            scheduler.event_loop_pp()
        elif scheduler.enable_overlap:
            scheduler.event_loop_overlap()
        else:
            scheduler.event_loop_normal()
    elif disaggregation_mode == DisaggregationMode.PREFILL:
        if scheduler.enable_overlap:
            scheduler.event_loop_overlap_disagg_prefill()
        else:
            if server_args.pp_size > 1:
                scheduler.event_loop_pp_disagg_prefill()  # 流水线+分离式预填充
            else:
                scheduler.event_loop_normal_disagg_prefill()
    elif disaggregation_mode == DisaggregationMode.DECODE:
        if scheduler.enable_overlap:
            scheduler.event_loop_overlap_disagg_decode()
        else:
            scheduler.event_loop_normal_disagg_decode()

**重叠事件循环的高级优化**：这是SGLang性能优化的核心实现，通过队列和事件机制实现CPU处理和GPU计算的真正并行。关键在于使用result_queue缓存结果，通过threading.Event同步批次启动，创建虚拟批次启动重叠管道，实现了显著的吞吐量提升。

@DynamicGradMode()
def event_loop_overlap(self):
    """真实的重叠事件循环实现"""
    self.result_queue = deque()

    while True:
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        batch = self.get_next_batch_to_run()
        self.cur_batch = batch

        if batch:
            # 异步启动批次推理
            batch.launch_done = threading.Event()
            result = self.run_batch(batch)
            self.result_queue.append((batch.copy(), result))

            # 创建虚拟首批次以启动重叠管道
            if self.last_batch is None:
                tmp_batch = ScheduleBatch(
                    reqs=None,
                    forward_mode=ForwardMode.DUMMY_FIRST,
                    next_batch_sampling_info=self.tp_worker.cur_sampling_info,
                )
                self.process_batch_result(tmp_batch, None, batch.launch_done)

        # 处理上一个批次的结果（实现CPU-GPU重叠）
        if self.last_batch:
            tmp_batch, tmp_result = self.result_queue.popleft()
            tmp_batch.next_batch_sampling_info = (
                self.tp_worker.cur_sampling_info if batch else None
            )
            self.process_batch_result(tmp_batch, tmp_result, 
                                    batch.launch_done if batch else None)
        elif batch is None:
            self.self_check_during_idle()

        self.last_batch = batch

💡 **实现说明**: 源码中有7种不同的事件循环组合，包括流水线并行的分离式版本。重叠事件循环使用deque和threading.Event实现CPU处理和GPU计算的真正并行。
```

这种自动选择机制确保了调度器能够根据部署配置选择最优的执行模式。

> 💡 **深入学习**：想掌握CPU-GPU重叠、流水线并行等高级优化技术？[05-事件循环实现](05-事件循环实现.md) 深入剖析了7种事件循环的具体实现和性能优化策略

---

## 4. 请求分发机制

### 4.1 TypeBasedDispatcher架构

**基于类型的智能请求路由**：TypeBasedDispatcher通过类型匹配自动将不同类型的请求路由到对应的处理方法，避免了复杂的if-else判断链，提高了代码的可维护性和扩展性。

> 📝 **简化说明**：以下为请求分发器的核心概念简化版本，展示基本的类型映射机制。

```python
# 请求分发器的核心概念（简化版）
self._request_dispatcher = TypeBasedDispatcher([
    (TokenizedGenerateReqInput, self.handle_generate_request),
    (TokenizedEmbeddingReqInput, self.handle_embedding_request),
    (BatchTokenizedGenerateReqInput, self.handle_batch_generate_request),
    (FlushCacheReqInput, self.flush_cache_wrapped),
    (AbortReq, self.abort_request),
    # ... 更多请求类型映射
])

# 使用方式
for recv_req in recv_reqs:
    output = self._request_dispatcher(recv_req)  # 直接调用，自动路由到对应处理器
```

### 4.2 源码实现细节

**生产环境的完整请求类型支持**：真实的SGLang源码支持20多种不同的请求类型，涵盖了从基础的文本生成到高级的系统管理功能。

```python
# 真实的调度器请求分发器初始化
self._request_dispatcher = TypeBasedDispatcher([
    (TokenizedGenerateReqInput, self.handle_generate_request),
    (TokenizedEmbeddingReqInput, self.handle_embedding_request),
    (BatchTokenizedGenerateReqInput, self.handle_batch_generate_request),
    (BatchTokenizedEmbeddingReqInput, self.handle_batch_embedding_request),
    (FlushCacheReqInput, self.flush_cache_wrapped),
    (AbortReq, self.abort_request),
    (OpenSessionReqInput, self.open_session),
    (CloseSessionReqInput, self.close_session),
    (UpdateWeightFromDiskReqInput, self.update_weights_from_disk),
    (InitWeightsUpdateGroupReqInput, self.init_weights_update_group),
    (UpdateWeightsFromDistributedReqInput, self.update_weights_from_distributed),
    (UpdateWeightsFromTensorReqInput, self.update_weights_from_tensor),
    (GetWeightsByNameReqInput, self.get_weights_by_name),
    (ReleaseMemoryOccupationReqInput, self.release_memory_occupation),
    (ResumeMemoryOccupationReqInput, self.resume_memory_occupation),
    (SlowDownReqInput, self.slow_down),
    (ProfileReq, self.profile),
    (FreezeGCReq, self.handle_freeze_gc),
    (GetInternalStateReq, self.get_internal_state),
    (SetInternalStateReq, self.set_internal_state),
    (RpcReqInput, self.handle_rpc_request),
    (ExpertDistributionReq, self.expert_distribution_handle),
    (LoadLoRAAdapterReqInput, self.load_lora_adapter),
    (UnloadLoRAAdapterReqInput, self.unload_lora_adapter),
])

💡 **实现说明**: 真实源码支持20+种请求类型，包括批量请求、RPC调用、专家分布、垃圾回收控制、内部状态管理等高级功能。TypeBasedDispatcher通过类型匹配自动路由请求到对应的处理方法。
```

这种设计支持了广泛的请求类型，从基本的生成和嵌入请求，到高级的系统管理和扩展功能。

> 💡 **深入学习**：想了解20+种请求类型是如何被智能路由和处理的？[03-请求处理机制](03-请求处理机制.md) 详细介绍了TypeBasedDispatcher的工作原理和各类请求的完整处理流程

---

## 5. 核心方法解析

在了解了调度器的架构设计和请求分发机制后，让我们深入探讨调度器的核心方法实现。这些方法构成了调度器日常工作的具体执行流程，是将架构设计转化为实际功能的关键环节。

### 5.1 请求处理流程

调度器通过一系列核心方法处理请求：

**网络请求接收的非阻塞机制**：recv_requests方法使用ZMQ的非阻塞模式从tokenizer接收请求，这种设计确保调度器不会因为等待新请求而阻塞。通过while循环和异常处理，能够高效地批量接收多个请求，提高系统的响应性能。

```python
def recv_requests(self) -> List[Req]:
    """接收来自tokenizer的请求"""
    recv_reqs = []  # 接收到的请求列表（received requests）
    while True:
        try:
            # 从tokenizer接收Python对象格式的请求（非阻塞模式）
            recv_req = self.recv_from_tokenizer.recv_pyobj(zmq.NOBLOCK)
            recv_reqs.append(recv_req)  # 添加到请求列表
        except zmq.ZMQError:  # 没有更多请求时退出循环
            break
    return recv_reqs  # 返回本轮接收到的所有请求
```

**请求处理的容错机制**：process_input_requests方法是请求处理的入口点，它使用TypeBasedDispatcher进行类型分发，并提供完善的异常处理机制。当请求处理出现错误时，系统会记录错误日志并向客户端发送错误响应，确保系统的健壮性。

```python
def process_input_requests(self, recv_reqs: List[Any]):
    """处理输入请求的核心分发逻辑"""
    for recv_req in recv_reqs:  # 遍历接收到的请求（received requests）
        try:
            # 使用TypeBasedDispatcher根据请求类型自动分发
            output = self._request_dispatcher(recv_req)  # 调用分发器处理请求
            if output is not None:  # 如果有返回结果
                # 根据输出类型发送响应
                if isinstance(output, RpcReqOutput):  # RPC请求的响应
                    if self.recv_from_rpc is not None:
                        self.recv_from_rpc.send_pyobj(output)
                else:  # 普通请求的响应
                    self.send_to_tokenizer.send_pyobj(output)
        except Exception as e:
            # 异常处理和错误响应
            logger.error(f"Error processing request {getattr(recv_req, 'rid', 'unknown')}: {e}")
            if hasattr(recv_req, 'rid'):  # 如果请求有ID，发送错误响应
                error_req = Req(recv_req.rid, "", [], SamplingParams())
                self.send_error_response(error_req, str(e))
```

**文本生成请求的标准化处理**：handle_generate_request方法将外部请求转换为内部的Req对象，这个过程包括参数提取、对象创建和队列加入三个步骤。Req对象是SGLang内部请求表示的标准格式，包含了推理所需的所有信息。

```python
def handle_generate_request(self, recv_req: TokenizedGenerateReqInput):
    """处理文本生成请求"""
    # 创建新的Req对象
    req = Req(
        recv_req.rid,
        recv_req.input_text,
        recv_req.input_ids,
        recv_req.sampling_params,
        return_logprob=recv_req.return_logprob,
        top_logprobs_num=recv_req.top_logprobs_num,
        stream=recv_req.stream,
        lora_id=recv_req.lora_id,
        input_embeds=recv_req.input_embeds,
        bootstrap_host=recv_req.bootstrap_host,
        bootstrap_port=recv_req.bootstrap_port,
        vocab_size=self.model_config.vocab_size,
    )
    req.tokenizer = self.tokenizer
    
    # 根据分离模式添加到相应队列
    self._add_request_to_queue(req)

def _add_request_to_queue(self, req: Req):
    """根据分离模式将请求添加到相应队列"""
    req.queue_time_start = time.perf_counter()
    if self.disaggregation_mode == DisaggregationMode.PREFILL:
        self._prefetch_kvcache(req)
        self.disagg_prefill_bootstrap_queue.add(req, self.model_config.num_key_value_heads)
    elif self.disaggregation_mode == DisaggregationMode.DECODE:
        self.disagg_decode_prealloc_queue.add(req)
    else:
        self._prefetch_kvcache(req)
        self.waiting_queue.append(req)
```

**嵌入请求的特殊处理逻辑**：handle_embedding_request方法专门处理向量嵌入请求，与生成请求的主要区别在于使用默认采样参数、禁用流式输出，并设置特殊的is_embedding标记。这种设计确保了嵌入请求能够获得正确的处理方式。

```python
def handle_embedding_request(self, recv_req: TokenizedEmbeddingReqInput):
    """处理嵌入请求"""
    # 创建嵌入请求对象
    req = Req(
        rid=recv_req.rid,
        input_text=recv_req.input_text,
        input_ids=recv_req.input_ids,
        sampling_params=SamplingParams(),  # 嵌入请求使用默认采样参数
        return_logprob=recv_req.return_logprob,
        stream=False,  # 嵌入请求不支持流式输出
        is_embedding=True,  # 标记为嵌入请求
    )
    req.tokenizer = self.tokenizer
    
    # 直接加入等待队列
    self.waiting_queue.append(req)
```

### 5.2 批处理管理

**批次调度的核心决策逻辑**：get_next_batch_to_run方法实现了SGLang的动态批处理策略，包括批次合并和新批次创建两个关键功能。它首先尝试将上一轮的预填充批次合并到运行批次中，然后获取新的预填充批次，实现了连续批处理的高效调度。

```python
def get_next_batch_to_run(self) -> Optional[ScheduleBatch]:
    # 合并预填充批次到运行批次
    if self.last_batch and self.last_batch.forward_mode.is_extend():
        if not self.last_batch.is_empty():
            if self.running_batch.is_empty():
                self.running_batch = self.last_batch
            else:
                self.running_batch.merge_batch(self.last_batch)

    # 获取新的预填充批次
    new_batch = self.get_new_batch_prefill()
    
    return new_batch or self.running_batch
```

**智能预填充批次构建**：get_new_batch_prefill方法使用PrefillAdder智能地选择和组织等待队列中的请求。它考虑了内存限制、语法约束和资源可用性，确保创建的批次既能最大化GPU利用率，又不会超出系统资源限制。

```python
def get_new_batch_prefill(self) -> Optional[ScheduleBatch]:
    """获取新的预填充批次"""
    # 检查语法队列是否就绪
    if self.grammar_queue:
        self.move_ready_grammar_requests()
    
    # 检查是否允许预填充
    if (self.running_batch.batch_is_full or len(self.waiting_queue) == 0) and self.chunked_req is None:
        return None
    
    running_bs = len(self.running_batch.reqs)
    if self.get_num_allocatable_reqs(running_bs) <= 0 and not self.chunked_req:
        self.running_batch.batch_is_full = True
        return None
    
    # 检查分层缓存事件
    if self.enable_hierarchical_cache:
        self.tree_cache.check_hicache_events()
    
    # 计算优先级
    self.policy.calc_priority(self.waiting_queue)
    
    # 创建预填充添加器
    adder = PrefillAdder(
        self.page_size,
        self.tree_cache,
        self.token_to_kv_pool_allocator,
        self.running_batch,
        self.new_token_ratio,
        self.max_prefill_tokens,
        self.chunked_prefill_size,
        running_bs if self.is_mixed_chunk else 0,
    )
    
    # 处理分块请求
    if self.chunked_req is not None:
        self.chunked_req.init_next_round_input()
        self.chunked_req = adder.add_chunked_req(self.chunked_req)
    
    # 从等待队列中添加请求
    can_run_list = []
    for req in self.waiting_queue:
        if adder.can_add_req(req):
            adder.add_req(req)
            can_run_list.append(req)
        else:
            break
    
    # 从等待队列中移除已添加的请求
    for _ in range(len(can_run_list)):
        self.waiting_queue.popleft()
    
    # 创建新批次
    if can_run_list or self.chunked_req:
        new_batch = ScheduleBatch(
            reqs=can_run_list,
            forward_mode=ForwardMode.EXTEND,
        )
        return new_batch
    
    return None
```

**批次推理的执行入口**：run_batch方法是连接调度层和计算层的关键接口，它根据批次的前向模式（解码或预填充）调用相应的底层计算函数。这个方法将高层的批次调度决策转换为具体的GPU计算任务。

```python
def run_batch(self, batch: ScheduleBatch):
    """执行批次推理"""
    self.forward_ct += 1
    
    # 获取模型工作批次
    model_worker_batch = batch.get_model_worker_batch()
    
    # 更新HiCache消费者索引
    self.tp_worker.set_hicache_consumer(
        model_worker_batch.hicache_consumer_index
    )
    
    # 执行前向推理
    if self.pp_group.is_last_rank:
        # 流水线最后一个rank，返回logits和token
        logits_output, next_token_ids, can_run_cuda_graph = (
            self.tp_worker.forward_batch_generation(model_worker_batch)
        )
        return logits_output, next_token_ids
    else:
        # 流水线中间rank，传递隐藏状态
        pp_hidden_states, _, can_run_cuda_graph = (
            self.tp_worker.forward_batch_generation(model_worker_batch)
        )
        return pp_hidden_states
```

**推理结果的综合处理**：process_batch_result方法负责处理GPU推理的输出结果，包括token解码、完成状态检查、流式输出发送和资源清理等多个环节。这个方法确保了每个请求都能得到正确的处理和响应。

```python
def process_batch_result(self, batch: ScheduleBatch, result):
    """处理批次推理结果"""
    if result is None:
        return
    
    # 处理每个请求的输出
    finished_reqs = []
    for i, req in enumerate(batch.reqs):
        # 解码新生成的token
        if result.next_token_ids is not None:
            new_token_id = result.next_token_ids[i]
            req.output_ids.append(new_token_id)
            
            # 检查是否完成生成
            if self.check_finished(req, new_token_id):
                finished_reqs.append(req)
        
        # 处理流式输出
        if req.stream and result.next_token_ids is not None:
            self.send_stream_output(req, result.next_token_ids[i])
    
    # 移除已完成的请求
    for req in finished_reqs:
        if req in batch.reqs:
            batch.reqs.remove(req)
            self.release_resources_for_request(req)
        
        # 发送最终输出
        self.send_final_output(req)
    
    # 更新批次状态
    if not batch.reqs:
        batch.forward_mode = ForwardMode.IDLE

def check_finished(self, req: Req, new_token_id: int) -> bool:
    """检查请求是否完成"""
    # 检查是否达到最大长度
    if len(req.output_ids) >= req.sampling_params.max_new_tokens:
        return True
    
    # 检查是否遇到结束token
    if new_token_id in req.sampling_params.stop_token_ids:
        return True
    
    # 检查是否遇到停止字符串
    if req.sampling_params.stop_strs:
        output_text = self.tokenizer.decode(req.output_ids)
        for stop_str in req.sampling_params.stop_strs:
            if stop_str in output_text:
                return True
    
    return False
```

> 💡 **深入学习**：想掌握动态批处理和PrefillAdder的智能算法？[04-批处理调度策略](04-批处理调度策略.md) 深度解析了批次合并、请求选择和资源约束下的调度优化策略

### 5.3 系统维护

**系统空闲时的维护机制**：self_check_during_idle方法在没有批次需要处理时执行系统维护任务，包括内存检查、节能模式和统计重置等。这种设计确保了SGLang在长期运行中的稳定性和资源使用效率。

```python
def self_check_during_idle(self):
    """系统空闲时的自检和维护"""
    # 执行内存泄漏检查
    self.check_memory()
    
    # 如果有空闲睡眠器，可能进入睡眠节能模式
    self.maybe_sleep_on_idle()
    
    # 重置一些统计计数器
    if self.forward_ct % 1000 == 0:
        logger.info(f"Forward count: {self.forward_ct}")
```

**全面的缓存刷新机制**：flush_cache方法提供了系统状态的完全重置功能，清理所有队列、缓存和内存池，重置统计信息。这个功能在系统维护、权重更新或故障恢复时非常重要，确保系统能够回到一个干净的初始状态。

```python
def flush_cache(self) -> bool:
    """刷新所有缓存，重置调度器状态"""
    try:
        # 清空所有队列
        self.waiting_queue.clear()
        self.running_batch = ScheduleBatch(reqs=[], batch_is_full=False)
        
        # 刷新KV缓存
        if hasattr(self, 'tree_cache'):
            self.tree_cache.reset()
        
        # 重置内存池
        if hasattr(self, 'req_to_token_pool'):
            self.req_to_token_pool.clear()
            
        # 重置统计信息
        self.forward_ct = 0
        
        logger.info("Cache flushed successfully")
        return True
    except Exception as e:
        logger.error(f"Cache flush failed: {e}")
        return False
```

**系统健康监控的看门狗机制**：watchdog_thread方法实现了后台监控功能，定期检查请求超时和内存使用情况。这种主动监控机制能够及时发现和处理系统异常，防止资源泄露和性能下降，是生产环境中不可或缺的功能。

```python
def watchdog_thread(self):
    """看门狗线程，监控调度器健康状态"""
    while True:
        try:
            # 检查是否有僵死的请求
            current_time = time.time()
            for req in self.running_batch.reqs:
                if current_time - req.start_time > self.request_timeout:
                    logger.warning(f"Request {req.rid} timeout, aborting")
                    self.abort_request(AbortReq(req.rid))
            
            # 检查内存使用情况
            if self.get_memory_usage() > 0.9:
                logger.warning("High memory usage detected")
                
            time.sleep(10)  # 每10秒检查一次
        except Exception as e:
            logger.error(f"Watchdog error: {e}")
```

---

## 6. 内存和资源管理

有了请求处理和批次调度的基础，我们需要了解支撑这些功能的底层资源管理机制。SGLang调度器采用精心设计的内存管理策略，确保在高并发场景下的资源高效利用。

调度器统一管理系统的内存和计算资源。在初始化过程中，调度器会创建和配置各种资源管理组件：

### 6.1 核心设计概念

**三层内存管理架构的设计理念**：SGLang采用"请求池→KV缓存→前缀缓存"的三层架构来管理内存资源。请求池管理并发槽位，KV缓存分配器处理注意力机制的键值存储，前缀缓存优化重复内容的命中率。这种分层设计实现了资源的精细化管理和高效利用。

> 📝 **简化说明**：以下为内存管理架构的教学简化版本，突出三层设计概念。真实实现根据不同配置有10+种缓存类型组合。

```python
def init_memory_pool_and_cache(self):
    """内存池和缓存系统初始化的核心概念（简化版）"""
    # 1. 请求到token映射池 - 管理并发请求槽位
    self.req_to_token_pool = ReqToTokenPool(
        size=self.max_running_requests,
        pre_alloc_size=self.pre_alloc_size,
    )
    
    # 2. KV缓存分配器 - 管理注意力键值缓存
    if self.is_hybrid:
        # SWA混合缓存架构
        self.token_to_kv_pool = HybridKVPoolAllocator(...)
    else:
        # 标准缓存架构
        self.token_to_kv_pool = BaseTokenToKVPoolAllocator(...)
    
    # 3. 前缀缓存 - 优化重复前缀的缓存命中
    self.tree_cache = RadixCache(...)  # 或ChunkCache
```

### 6.2 源码实现细节

```python
def init_memory_pool_and_cache(self):
    """真实的SGLang源码实现"""
    server_args = self.server_args

    # 内存池从tp_worker获取，而非直接创建
    self.req_to_token_pool, self.token_to_kv_pool_allocator = (
        self.tp_worker.get_memory_pool()
    )

    # 复杂的缓存类型选择逻辑
    if (
        server_args.chunked_prefill_size is not None
        and server_args.disable_radix_cache
    ):
        # 块缓存分支
        if self.is_hybrid:
            ChunkCacheClass = SWAChunkCache
        else:
            ChunkCacheClass = ChunkCache
        self.tree_cache = ChunkCacheClass(
            req_to_token_pool=self.req_to_token_pool,
            token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
            page_size=self.page_size,
        )
    else:
        # RadixCache分支
        if os.environ.get("SGLANG_EXPERIMENTAL_CPP_RADIX_TREE") == "1":
            # C++实验性实现
            from sglang.srt.mem_cache.radix_cache_cpp import RadixCacheCpp
            self.tree_cache = RadixCacheCpp(
                disable=False,
                use_hicache=self.enable_hierarchical_cache,
                req_to_token_pool=self.req_to_token_pool,
                token_to_kv_pool=self.token_to_kv_pool_allocator,
                tp_cache_group=self.tp_cpu_group,
                page_size=self.page_size,
                hicache_ratio=server_args.hicache_ratio,
                hicache_size=server_args.hicache_size,
                hicache_write_policy=server_args.hicache_write_policy,
                enable_kv_cache_events=self.enable_kv_cache_events,
            )
        elif self.enable_hierarchical_cache:
            # 分层缓存实现
            if self.enable_lora:
                self.tree_cache = LoRARadixCache(...)
            elif self.is_hybrid:
                self.tree_cache = SWARadixCache(...)
            else:
                self.tree_cache = HiRadixCache(...)
        else:
            # 标准RadixCache
            if self.enable_lora:
                self.tree_cache = LoRARadixCache(...)
            elif self.is_hybrid:
                self.tree_cache = SWARadixCache(...)
            else:
                self.tree_cache = RadixCache(...)

💡 **实现说明**: 源码中有10+种缓存类型，根据chunked_prefill、LoRA、SWA、分层缓存等不同配置组合选择。教学版本突出核心的"请求池→KV缓存→前缀缓存"设计模式。
```

**资源管理的核心机制**：SGLang采用三层资源管理架构，通过请求池、KV缓存池和前缀缓存的协同工作，实现高效的内存分配和回收。

> 📝 **实现说明**：资源分配的具体实现由PrefillAdder等组件处理，调度器主要负责资源池的初始化和管理。详细的分配算法请参考相关的资源管理文档。

这些组件协同工作，确保内存的高效使用和缓存的智能管理，同时支持请求的动态资源分配和回收。

> 💡 **深入学习**：想了解RadixCache、ChunkCache等10+种缓存类型的设计原理？[06-内存和资源管理](06-内存和资源管理.md) 详细介绍了三层内存架构、SWA混合缓存和智能资源分配算法

---

## 7. 并行策略协调

在单机资源管理的基础上，SGLang调度器还需要处理分布式环境下的复杂协调工作。多种并行策略的统一管理是SGLang支持大规模部署的核心能力。

在分布式环境下，调度器需要协调多种并行策略：

### 7.1 张量并行协调

**主从架构的同步机制**：张量并行采用主从架构，rank 0作为主节点负责调度决策并广播给其他节点，从节点接收调度信息并执行相应操作。这种设计确保了所有并行节点的同步执行，避免了分布式环境下的数据不一致问题。

### 7.2 流水线并行管理

**分阶段处理的流水线架构**：流水线并行将模型分割成多个阶段，每个阶段在不同的GPU上执行。第一阶段处理输入，中间阶段传递隐藏状态，最后阶段生成输出。这种设计能够有效利用多个GPU节点，支持超大模型的推理。

### 7.3 数据并行负载均衡

**动态负载均衡的实现机制**：数据并行通过收集各副本的负载信息（运行请求数、等待请求数、内存使用率）来实现负载均衡。主副本根据负载差异动态重分配请求，确保各个副本的工作负载相对均衡，最大化整体系统吞吐量。

### 7.4 专家并行调度

**基于token路由的专家分发**：MoE专家并行根据token的专家路由信息将计算任务分发到不同的专家节点。每个token可能需要多个专家处理，调度器根据专家ID和并行rank的映射关系，将token发送到对应的专家节点进行处理。

**并行参数的初始化和使用**：

> 📝 **简化说明**：以下展示真实的并行参数初始化代码，省略了部分配置逻辑。完整实现请参考 `sglang/srt/managers/scheduler.py`。

```python
def __init__(self, server_args: ServerArgs, port_args: PortArgs, gpu_id: int,
             tp_rank: int, moe_ep_rank: int, pp_rank: int, dp_rank: Optional[int]):
    """调度器并行配置初始化（简化版）"""
    # 并行rank参数 - 确定当前进程在并行组中的位置
    self.tp_rank = tp_rank              # 张量并行rank（tensor parallel rank）
    self.moe_ep_rank = moe_ep_rank      # 专家并行rank（expert parallel rank）
    self.pp_rank = pp_rank              # 流水线并行rank（pipeline parallel rank）
    self.dp_rank = dp_rank              # 数据并行rank（data parallel rank）
    
    # 并行size参数 - 定义各并行组的大小
    self.tp_size = server_args.tp_size  # 张量并行大小（tensor parallel size）
    self.moe_ep_size = server_args.ep_size  # 专家并行大小（expert parallel size）
    self.pp_size = server_args.pp_size  # 流水线并行大小（pipeline parallel size）
    self.dp_size = server_args.dp_size  # 数据并行大小（data parallel size）

# 并行进程启动示例
def launch_tensor_parallel_group(self, server_args, base_gpu_id, dp_rank):
    """启动张量并行组（简化版）"""
    for pp_rank in range(server_args.pp_size):        # 遍历流水线并行组
        for tp_rank in range(server_args.tp_size):    # 遍历张量并行组
            # 计算专家并行rank - 基于张量并行rank分配专家
            moe_ep_rank = tp_rank // (server_args.tp_size // server_args.ep_size)
            
            # 启动调度器进程 - 每个rank对应一个独立的调度器进程
            proc = mp.Process(
                target=run_scheduler_process,        # 进程目标函数
                args=(server_args, port_args, gpu_id, tp_rank, 
                      moe_ep_rank, pp_rank, dp_rank, writer)  # 传递并行配置参数
            )
            proc.start()  # 启动进程
```

> 📝 **实现说明**：并行协调的具体实现分布在各个组件中，调度器主要负责参数管理和状态同步，实际的并行计算由底层的模型执行器处理。

这些并行策略确保了SGLang能够在大规模分布式环境下高效运行，最大化硬件资源利用率。

> 💡 **深入学习**：
> - 想了解预填充/解码分离如何支持超大模型？[10-分离式架构支持](10-分离式架构支持.md) 详解了PrefillBootstrapQueue、KV传输和分布式协调机制
> - 想掌握多轮对话的会话管理？[08-会话管理与状态控制](08-会话管理与状态控制.md) 深入介绍了Session树结构、请求链管理和上下文保持策略

---

## 8. 性能监控和调试

调度器内置了完善的性能监控和调试功能：

### 8.1 关键指标收集

**内置指标收集系统**：通过SchedulerMetricsMixin收集关键性能指标，包括吞吐量、资源利用率、队列状态等维度的统计信息。

> 📝 **简化说明**：以下展示真实的指标收集机制，基于实际的Mixin实现。

```python
# 来自SchedulerMetricsMixin的真实方法
def init_metrics(self, tp_rank: int, pp_rank: int, dp_rank: Optional[int]):
    """初始化指标收集系统"""
    self.last_gen_throughput: float = 0.0
    self.last_input_throughput: float = 0.0
    self.step_time_dict = defaultdict(list)
    self.stats = SchedulerStats()
    
    if self.enable_metrics:
        labels = {
            "model_name": self.server_args.served_model_name,
            "tp_rank": tp_rank,
            "pp_rank": pp_rank,
        }
        if dp_rank is not None:
            labels["dp_rank"] = dp_rank
        self.metrics_collector = SchedulerMetricsCollector(labels)
```

### 8.2 性能分析工具

**PyTorch Profiler集成的深度分析**：通过SchedulerProfilerMixin提供的性能分析功能，支持CPU和GPU活动跟踪，记录形状信息和调用栈，生成分析报告。

> 📝 **简化说明**：以下展示性能分析的核心接口，真实实现支持更多配置选项和输出格式。

```python
def start_profile(self, stage: Optional[ForwardMode] = None):
    """启动性能分析（简化版）"""
    logger.info(f"Profiling starts. Traces will be saved to: {self.torch_profiler_output_dir}")
    
    # 配置profiler活动类型
    activities = [
        torch.profiler.ProfilerActivity.CPU,
        torch.profiler.ProfilerActivity.CUDA,
    ]
    
    # 创建并启动profiler
    self.torch_profiler = torch.profiler.profile(
        activities=activities,
        record_shapes=self.torch_profiler_record_shapes,
        with_stack=self.torch_profiler_with_stack,
    )
    self.torch_profiler.start()

def profile(self, recv_req: ProfileReq):
    """处理性能分析请求（简化版）"""
    if recv_req.req_type == ProfileReqType.START_PROFILE:
        return self.start_profile()
    elif recv_req.req_type == ProfileReqType.STOP_PROFILE:
        return self.stop_profile()
```

### 8.3 调试和监控

**内置的指标收集系统**：通过SchedulerMetricsMixin提供统计信息收集，包括吞吐量、延迟、资源使用率等关键指标。

> 📝 **简化说明**：以下展示指标收集的核心机制，真实实现包含更多统计维度和数据处理逻辑。

```python
# 来自SchedulerMetricsMixin的真实实现
def init_metrics(self, tp_rank: int, pp_rank: int, dp_rank: Optional[int]):
    """初始化指标收集（简化版）"""
    self.last_gen_throughput: float = 0.0
    self.last_input_throughput: float = 0.0
    self.step_time_dict = defaultdict(list)
    self.stats = SchedulerStats()
    
    if self.enable_metrics:
        labels = {
            "model_name": self.server_args.served_model_name,
            "tp_rank": tp_rank,
            "pp_rank": pp_rank,
        }
        self.metrics_collector = SchedulerMetricsCollector(labels)
```

这些功能为系统优化和问题排查提供了强有力的工具，帮助开发者识别性能瓶颈和优化机会。

> 💡 **深入学习**：
> - 想了解如何监控系统性能和排查问题？[09-调度器监控与调试](09-调度器监控与调试.md) 介绍了SchedulerMetricsMixin指标体系、PyTorch Profiler集成和调试工具
> - 想掌握LoRA适配器、权重更新等高级功能？[07-调度器扩展功能](07-调度器扩展功能.md) 详解了Mixin扩展机制和各种高级特性的实现

---

## 9. 总结

SGLang调度器通过精心设计的架构和丰富的功能，为高性能语言模型推理提供了强大的调度能力：

### 9.1 设计亮点

**模块化架构**: Mixin模式确保了功能的模块化和可扩展性，6个Mixin类分别负责输出处理、权重更新、性能分析、指标收集和分离式架构支持。

**多样化事件循环**: 提供7种不同的事件循环组合，从标准同步到CPU-GPU重叠，从流水线并行到分离式架构，适应各种部署场景。

**智能请求分发**: TypeBasedDispatcher支持20+种请求类型的自动路由，从基本的生成/嵌入请求到高级的系统管理功能。

**灵活资源管理**: 支持10+种缓存类型组合，包括RadixCache、ChunkCache、SWA混合缓存、分层缓存等，根据配置自动选择最优方案。

**全面监控能力**: 内置完善的性能监控、调试工具和状态管理，支持PyTorch Profiler集成和实时指标收集。

### 9.2 实现特色

**源码准确性**: 本文档基于真实SGLang源码编写，所有代码示例都来自实际实现，确保技术准确性。

**教学与实践并重**: 采用"核心设计概念 + 源码实现细节"的双重结构，既便于理解核心思想，又提供实现参考。

**渐进式学习**: 从简化的教学版本开始，逐步深入到复杂的源码实现，适合不同层次的学习需求。

理解调度器的设计理念和工作原理，是掌握SGLang系统的关键所在。通过本文档的学习，开发者可以深入理解SGLang调度器的架构精髓，为后续的定制开发和性能优化打下坚实基础。

---

## 10. 学习路径建议

根据不同的学习目标，建议按以下路径深入学习：

### 10.1 基础学习路径
1. **[01-调度器总览与架构](01-调度器总览与架构.md)** ← 当前文档
2. **[02-核心数据结构](02-核心数据结构.md)** - 理解核心抽象
3. **[03-请求处理机制](03-请求处理机制.md)** - 掌握处理流程
4. **[04-批处理调度策略](04-批处理调度策略.md)** - 理解调度算法

### 10.2 系统实现路径
5. **[05-事件循环实现](05-事件循环实现.md)** - 深入事件驱动机制
6. **[06-内存和资源管理](06-内存和资源管理.md)** - 掌握资源管理
7. **[07-调度器扩展功能](07-调度器扩展功能.md)** - 了解高级特性

### 10.3 高级应用路径
8. **[08-会话管理与状态控制](08-会话管理与状态控制.md)** - 状态管理机制
9. **[09-调度器监控与调试](09-调度器监控与调试.md)** - 运维和调试
10. **[10-分离式架构支持](10-分离式架构支持.md)** - 分布式部署

### 10.4 专项学习建议
- **性能优化**：重点学习 04→05→06→09
- **分布式部署**：重点学习 08→10→07
- **系统集成**：重点学习 02→03→07→09
- **问题排查**：重点学习 09→02→06→08
