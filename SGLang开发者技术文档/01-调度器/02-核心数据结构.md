# 核心数据结构

---

SGLang调度器的高效运行依赖于一系列精心设计的数据结构。这些数据结构不仅承载着请求的各种信息，还负责批次管理、内存分配和模型推理的协调。理解这些核心数据结构是深入掌握SGLang调度器工作原理的基础。

---

## 🔄 数据流转架构

SGLang采用分层的数据处理架构，请求从接收到执行经历了三个主要的数据结构层次：

**调度器层面的ScheduleBatch**负责存储调度器需要的所有信息，包括请求列表、内存池引用、缓存管理等高层调度决策所需的数据。

**模型工作器层面的ModelWorkerBatch**是ScheduleBatch的简化版本，只包含模型前向推理所需的核心数据，去除了调度器特有的管理信息。

**模型执行器层面的ForwardBatch**包含最底层的GPU张量数据，是实际在GPU上执行计算时使用的数据格式。

这种分层设计确保了每个组件只处理与其职责相关的数据，提高了系统的模块化程度和执行效率。

---

## 📋 Req类详解

Req类是SGLang中表示单个请求的核心数据结构，包含了请求从创建到完成的全部信息。

### 🎯 核心设计概念

**Req类的设计理念**：Req类是SGLang中表示单个请求的核心数据结构，包含了从输入到输出的完整生命周期信息。设计上采用了丰富的参数支持，能够处理文本生成、嵌入计算、多模态输入等多种场景。

> 📝 **简化说明**：以下为Req类的核心属性简化版本，突出主要概念。真实实现包含40+个属性，支持更多高级功能。

```python
class Req:
    """请求对象（简化版）"""
    def __init__(self, rid: str, origin_input_text: str, origin_input_ids: List[int],
                 sampling_params: SamplingParams, return_logprob: bool = False,
                 stream: bool = False, lora_id: Optional[str] = None):
        # 基本请求信息
        self.rid = rid                          # 请求唯一标识符
        self.origin_input_text = origin_input_text    # 原始输入文本
        self.origin_input_ids = origin_input_ids      # 原始输入token序列
        self.output_ids = []                         # 输出token序列
        
        # 处理配置
        self.sampling_params = sampling_params        # 采样参数配置
        self.return_logprob = return_logprob         # 是否返回对数概率
        self.stream = stream                        # 是否启用流式输出
        self.lora_id = lora_id                      # LoRA适配器ID
        
        # 状态管理
        self.finished_reason = None                  # 完成原因
        self.req_pool_idx = None                    # 内存池索引
```

### 🔍 源码实现细节

**真实Req类的完整参数**：生产环境中的Req类支持丰富的参数配置，包括多模态输入、LoRA适配器、会话管理、分离式架构等高级功能。

> 📝 **简化说明**：以下展示真实Req类的主要参数，省略了部分内部实现细节。完整实现请参考 `sglang/srt/managers/schedule_batch.py`。

```python
class Req:
    """真实的SGLang Req类实现"""
    
    def __init__(
        self,
        rid: str,
        origin_input_text: str,
        origin_input_ids: List[int],
        sampling_params: SamplingParams,
        return_logprob: bool = False,
        top_logprobs_num: int = 0,
        token_ids_logprob: List[int] = None,
        stream: bool = False,
        origin_input_ids_unpadded: Optional[Tuple[int]] = None,
        lora_id: Optional[str] = None,
        input_embeds: Optional[List[List[float]]] = None,
        token_type_ids: List[int] = None,
        session_id: Optional[str] = None,
        custom_logit_processor: Optional[str] = None,
        return_hidden_states: bool = False,
        eos_token_ids: Optional[Set[int]] = None,
        bootstrap_host: Optional[str] = None,
        bootstrap_port: Optional[int] = None,
        bootstrap_room: Optional[int] = None,
        data_parallel_rank: Optional[int] = None,
        vocab_size: Optional[int] = None,
    ):
        # Input and output info
        self.rid = rid
        self.origin_input_text = origin_input_text
        self.origin_input_ids_unpadded = (
            origin_input_ids_unpadded or origin_input_ids  # Before image padding
        )
        self.origin_input_ids = origin_input_ids
        self.output_ids = []                    # Each decode stage's output ids
        self.fill_ids = []                      # origin_input_ids + output_ids
        self.session_id = session_id
        self.input_embeds = input_embeds
        
        # For cross-encoder model
        self.token_type_ids = token_type_ids
        
        # The length of KV that have been removed in local attention chunked prefill
        self.evicted_seqlen_local = 0
        
        # Sampling info
        if isinstance(sampling_params.custom_params, dict):
            sampling_params = copy.copy(sampling_params)
            sampling_params.custom_params = sampling_params.custom_params | {
                "__req__": self
            }
        self.sampling_params = sampling_params
        self.custom_logit_processor = custom_logit_processor
        self.return_hidden_states = return_hidden_states
        self.lora_id = lora_id
        
        # Memory pool info
        self.req_pool_idx: Optional[int] = None
        
        # Check finish
        self.tokenizer = None
        self.finished_reason = None
        self.finished_output = None
        self.to_abort = False
        self.to_abort_message: str = None
        self.stream = stream
        self.eos_token_ids = eos_token_ids
        self.vocab_size = vocab_size
        
        # For incremental decoding
        self.surr_offset = None  # Surrounding offset to defeat cleanup algorithm
        self.read_offset = None
        self.decoded_text = ""
        
        # For multimodal inputs
        self.multimodal_inputs: Optional[MultimodalInputs] = None
        
        # Prefix info
        self.prefix_indices: torch.Tensor = []     # Indices to kv cache for shared prefix
        self.extend_input_len = 0                  # Number of tokens to run prefill
        self.extend_logprob_start_len = 0          # Relative logprob_start_len in extend batch
        
        # 还有更多字段...

💡 **实现说明**: 真实的Req类有50+个字段，支持多模态输入、会话管理、LoRA适配器、分离式架构、增量解码、前缀缓存等高级功能。教学版本突出核心的"输入→处理→输出"流程。
```

### 🏷️ 关键字段分类

**基础信息**: `rid`, `origin_input_text`, `origin_input_ids`, `output_ids`
**处理配置**: `sampling_params`, `stream`, `return_logprob`, `lora_id`  
**状态管理**: `finished_reason`, `to_abort`, `req_pool_idx`
**多模态**: `multimodal_inputs`, `input_embeds`, `token_type_ids`
**会话支持**: `session_id`, `bootstrap_host`, `bootstrap_port`
**性能优化**: `prefix_indices`, `extend_input_len`, `surr_offset`

### 🔄 状态管理

Req类维护着请求在处理过程中的各种状态信息：

**输出管理**  
output_ids列表记录了模型生成的所有token，fill_ids是origin_input_ids和output_ids的组合，表示当前的完整token序列。

**生成控制**  
finished_reason记录请求完成的原因，可能是达到最大长度、遇到停止token或其他条件。各种长度限制和控制参数确保生成过程按预期进行。

**内存映射**  
req_pool_indices和其他索引信息维护着请求在各种内存池中的位置，这对于内存管理和缓存机制至关重要。

### 多模态支持

Req类还支持多模态输入，包括图像、音频等非文本数据：

```python
self.input_embeds = input_embeds            # 输入嵌入向量
self.image_inputs = None                    # 图像输入数据
self.multimodal_inputs = None              # 多模态输入统一接口
```

这种设计使得SGLang能够处理不仅仅是文本的多种模态输入，为多模态大语言模型提供了基础支持。

---

## ScheduleBatch类详解

ScheduleBatch是调度器层面的核心数据结构，负责管理一个批次中所有请求的信息和资源。

### 🎯 核心设计概念

```python
@dataclasses.dataclass
class ScheduleBatch:
    """批次数据结构的核心概念"""
    # 请求和资源管理
    reqs: List[Req]                          # 批次中的请求列表
    req_to_token_pool: ReqToTokenPool        # 请求到token池的映射
    token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator  # KV缓存分配器
    tree_cache: BasePrefixCache              # 前缀缓存树
    
    # 批次配置
    forward_mode: ForwardMode                # 前向模式（预填充/解码）
    enable_overlap: bool = False             # 是否启用重叠处理
    batch_is_full: bool = False             # 批次是否已满
    
    # GPU张量数据
    input_ids: torch.Tensor = None          # 输入token ID张量
    seq_lens: torch.Tensor = None           # 序列长度张量
    req_pool_indices: torch.Tensor = None   # 请求池索引张量
```

### 🔍 源码实现细节

**真实ScheduleBatch的完整结构**：生产环境中的ScheduleBatch包含了批次管理所需的全部信息，从基础的请求列表到复杂的GPU张量数据，支持多种前向模式和优化策略。

> 📝 **简化说明**：以下展示真实ScheduleBatch的主要属性，省略了部分内部方法实现。完整实现请参考 `sglang/srt/managers/schedule_batch.py`。

```python
@dataclasses.dataclass
class ScheduleBatch(ScheduleBatchDisaggregationDecodeMixin):
    """真实的SGLang ScheduleBatch实现"""
    
    # Request, memory pool, and cache
    reqs: List[Req]
    req_to_token_pool: ReqToTokenPool = None
    token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator = None
    tree_cache: BasePrefixCache = None
    is_hybrid: bool = False                  # SWA混合缓存标志

    # Batch configs
    model_config: ModelConfig = None
    forward_mode: ForwardMode = None
    enable_overlap: bool = False
    batch_is_full: bool = False             # 批次满标志用于优化调度决策

    # Events
    launch_done: Optional[threading.Event] = None  # 用于重叠事件循环同步

    # For chunked prefill in PP
    chunked_req: Optional[Req] = None       # 流水线并行中的分块请求

    # Sampling info
    sampling_info: SamplingBatchInfo = None
    next_batch_sampling_info: SamplingBatchInfo = None

    # Batched arguments to model runner
    input_ids: torch.Tensor = None          # shape: [b], int64
    input_embeds: torch.Tensor = None       # shape: [b, hidden_size], float32
    token_type_ids: torch.Tensor = None     # shape: [b], int64
    req_pool_indices: torch.Tensor = None   # shape: [b], int64
    seq_lens: torch.Tensor = None           # shape: [b], int64
    out_cache_loc: torch.Tensor = None      # shape: [b], int64 - KV缓存输出位置
    output_ids: torch.Tensor = None         # shape: [b], int64

    # For multimodal inputs
    multimodal_inputs: Optional[List] = None

    # Sequence length info
    seq_lens_sum: int = None                # 所有序列长度的总和
    orig_seq_lens: torch.Tensor = None      # 原始序列长度，Qwen-1M相关

    # For DP attention
    global_num_tokens: Optional[List[int]] = None
    global_num_tokens_for_logprob: Optional[List[int]] = None
    is_extend_in_batch: bool = False
    can_run_dp_cuda_graph: bool = False
    tbo_split_seq_index: Optional[int] = None
    
    # For logprob
    return_logprob: bool = False
    top_logprobs_nums: Optional[List[int]] = None
    token_ids_logprobs: Optional[List[List[int]]] = None
    
    # For extend mode
    extend_num_tokens: Optional[int] = None
    extend_seq_lens: Optional[List[int]] = None
    extend_prefix_lens: Optional[List[int]] = None
    extend_logprob_start_lens: Optional[List[int]] = None
    
    # Special flags
    has_stream: bool = False                # 是否有流式请求
    has_grammar: bool = False               # 是否有语法约束
    is_prefill_only: bool = False          # 是否仅预填充
    
    # Performance
    spec_algorithm: SpeculativeAlgorithm = None  # 投机解码算法
    device: str = "cuda"                    # 设备类型
    
    # hicache pointer for synchronizing data loading from CPU to GPU
    hicache_consumer_index: int = 0

💡 **实现说明**: 真实的ScheduleBatch有60+个字段，支持多模态、DP注意力、投机解码、分层缓存、分离式架构等复杂功能。教学版本突出"请求→资源→张量"的核心组织结构。
```

### 📦 字段功能分类

**核心组织**: `reqs`, `req_to_token_pool`, `token_to_kv_pool_allocator`, `tree_cache`
**批次控制**: `forward_mode`, `batch_is_full`, `enable_overlap`, `launch_done`
**GPU数据**: `input_ids`, `seq_lens`, `req_pool_indices`, `out_cache_loc`
**多模态**: `multimodal_inputs`, `input_embeds`, `token_type_ids`
**性能优化**: `spec_algorithm`, `can_run_dp_cuda_graph`, `hicache_consumer_index`
**特殊功能**: `has_stream`, `has_grammar`, `is_prefill_only`, `chunked_req`

### 模型执行数据

ScheduleBatch还包含了传递给模型执行器的批量化数据：

```python
# Batched arguments to model runner
input_ids: torch.Tensor = None            # 输入token ID张量
seq_lens: torch.Tensor = None             # 序列长度张量
req_pool_indices: torch.Tensor = None     # 请求池索引张量
out_cache_loc: torch.Tensor = None        # 输出缓存位置张量
```

这些张量化的数据是GPU计算的直接输入，将批次中所有请求的相关信息组织成了适合并行处理的格式。

### 采样和生成信息

```python
# Sampling info
sampling_info: SamplingBatchInfo = None           # 当前批次采样信息
next_batch_sampling_info: SamplingBatchInfo = None # 下一批次采样信息
```

采样信息管理着批次中所有请求的采样参数，确保每个请求都能按照指定的方式进行文本生成。

---

## ModelWorkerBatch数据结构

ModelWorkerBatch是ScheduleBatch向模型工作器传递的简化版本，去除了调度器特有的管理信息，专注于模型推理所需的核心数据。

### 🎯 核心设计概念

```python
@dataclasses.dataclass
class ModelWorkerBatch:
    """模型工作器批次的核心概念"""
    bid: int                               # 批次ID
    forward_mode: ForwardMode              # 前向模式（预填充/解码）
    input_ids: torch.Tensor               # 输入token张量
    req_pool_indices: torch.Tensor        # 请求池索引
    seq_lens: torch.Tensor                # 序列长度
    out_cache_loc: torch.Tensor           # 输出缓存位置
    sampling_info: SamplingBatchInfo      # 采样信息
```

### 🔍 源码实现细节

```python
@dataclasses.dataclass
class ModelWorkerBatch:
    """真实的SGLang ModelWorkerBatch实现"""
    
    # Basic batch info
    bid: int                               # 批次ID
    forward_mode: ForwardMode              # 前向模式
    
    # Core tensors
    input_ids: torch.Tensor               # 输入token张量
    req_pool_indices: torch.Tensor        # 请求池索引
    seq_lens: torch.Tensor                # 序列长度
    out_cache_loc: torch.Tensor           # KV缓存输出位置
    seq_lens_cpu: Optional[torch.Tensor]  # CPU上的序列长度张量
    seq_lens_sum: int                     # 序列长度总和

    # For logprob
    return_logprob: bool
    top_logprobs_nums: Optional[List[int]]
    token_ids_logprobs: Optional[List[List[int]]]

    # For DP attention
    global_num_tokens: Optional[List[int]]
    global_num_tokens_for_logprob: Optional[List[int]]
    is_extend_in_batch: bool
    can_run_dp_cuda_graph: bool
    tbo_split_seq_index: Optional[int]
    global_forward_mode: Optional[ForwardMode]

    # For extend mode
    extend_num_tokens: Optional[int]
    extend_seq_lens: Optional[List[int]]
    extend_prefix_lens: Optional[List[int]]
    extend_logprob_start_lens: Optional[List[int]]
    extend_input_logprob_token_ids: Optional[torch.Tensor]

    # For multimodal
    multimodal_inputs: Optional[List[MultimodalInputs]]

    # For encoder-decoder
    encoder_cached: Optional[List[bool]]
    encoder_lens: Optional[torch.Tensor]
    encoder_lens_cpu: Optional[List[int]]
    encoder_out_cache_loc: Optional[torch.Tensor]

    # For LoRA
    lora_ids: Optional[List[str]]

    # Sampling info
    sampling_info: SamplingBatchInfo

    # Additional data
    orig_seq_lens: Optional[torch.Tensor] = None  # Qwen-1M相关
    input_embeds: Optional[torch.Tensor] = None   # 输入嵌入
    token_type_ids: Optional[torch.Tensor] = None # 跨编码器模型

    # Speculative decoding
    spec_algorithm: SpeculativeAlgorithm = None
    spec_info: Optional[Union[EagleVerifyInput, EagleDraftInput]] = None

💡 **实现说明**: 真实的ModelWorkerBatch有30+个字段，包含DP注意力、编码器-解码器、LoRA、投机解码等复杂功能的支持。教学版本突出核心的"输入→推理→输出"数据流。
```

这种简化确保了模型工作器只需要关注推理相关的信息，提高了数据传递的效率。

## 内存管理数据结构

### ReqToTokenPool

ReqToTokenPool管理着请求到token位置的映射关系，是内存管理的重要组成部分。它维护着每个请求在内存中的token位置信息，支持动态的内存分配和回收。

### BaseTokenToKVPoolAllocator

这个抽象基类定义了KV缓存分配器的接口，具体的实现类负责管理KV缓存的分配、回收和优化。不同的实现可以采用不同的分配策略，如页面分配、连续分配等。

### BasePrefixCache

前缀缓存是SGLang的重要优化特性，BasePrefixCache定义了前缀缓存的通用接口。具体的实现如RadixCache能够识别和复用请求间的公共前缀，显著减少计算开销。

## 多模态数据结构

SGLang支持多模态输入，相关的数据结构包括：

### MultimodalInputs

这个类统一管理各种模态的输入数据，包括图像的pixel_values、音频的audio_values等。通过统一的接口，不同模态的数据能够被一致地处理和传递。

### MultimodalDataItem

表示单个多模态数据项，包含了数据类型、内容和相关的元数据信息。

## 批量请求数据结构

SGLang支持批量请求以提高网络传输效率和处理性能：

### BatchTokenizedGenerateReqInput

批量生成请求的输入结构，包含多个TokenizedGenerateReqInput：

```python
@dataclass
class BatchTokenizedGenerateReqInput:
    """批量生成请求输入"""
    requests: List[TokenizedGenerateReqInput]  # 批量请求列表
    
    def __len__(self):
        return len(self.requests)
    
    def __iter__(self):
        return iter(self.requests)
```

### BatchTokenizedEmbeddingReqInput

批量嵌入请求的输入结构，包含多个TokenizedEmbeddingReqInput：

```python
@dataclass  
class BatchTokenizedEmbeddingReqInput:
    """批量嵌入请求输入"""
    requests: List[TokenizedEmbeddingReqInput]  # 批量请求列表
    
    def __len__(self):
        return len(self.requests)
    
    def __iter__(self):
        return iter(self.requests)
```

这些批量结构通过减少网络往返次数和请求处理开销来提高系统整体性能。

## 分离式架构数据结构

在分离式架构中，请求对象包含额外的分离式相关字段：

```python
class Req:
    # 分离式架构相关字段
    disagg_kv_sender: Optional[BaseKVSender] = None      # KV发送器
    disagg_kv_receiver: Optional[BaseKVReceiver] = None  # KV接收器
    bootstrap_host: Optional[str] = None                 # 启动主机
    bootstrap_port: Optional[int] = None                 # 启动端口
    bootstrap_room: Optional[str] = None                 # 启动房间ID
    
    # SWA混合缓存相关字段
    swa_uuid_for_lock: Optional[str] = None             # SWA锁定UUID
```

## 数据结构协作关系

这些数据结构之间存在着复杂的协作关系。Req对象是最基本的数据单元，ScheduleBatch将多个Req组织成批次，同时管理着各种资源池的引用。在处理过程中，ScheduleBatch会转换成ModelWorkerBatch传递给下游组件，最终转换成ForwardBatch在GPU上执行。

内存管理相关的数据结构为这个过程提供支撑，确保每个请求都能获得必要的内存资源，同时通过缓存机制优化性能。多模态数据结构则扩展了系统的输入能力，使得SGLang能够处理不仅仅是文本的多种类型输入。

---

## 数据结构的设计优势

SGLang的数据结构设计体现了几个重要的设计原则：

### 🎯 核心设计原则

**分层抽象**: 通过Req→ScheduleBatch→ModelWorkerBatch的分层设计，系统能够在不同抽象层面进行优化，调度器关注高层决策，模型执行器关注底层计算。

**模块化设计**: 各个数据结构职责清晰，相互之间通过明确的接口进行交互，提高了系统的可维护性和可测试性。

**性能优化**: 数据结构充分考虑了性能因素：
- 批量化处理减少函数调用开销
- 张量化数据支持GPU并行计算
- 内存池设计提高内存局部性
- 缓存友好的数据布局

**扩展性**: 通过抽象基类和mixin模式，数据结构具备良好的扩展性，能够支持新功能的添加和现有功能的优化。

### 🔧 实现特色

**源码准确性**: 本文档基于真实SGLang源码编写，所有数据结构定义都来自实际实现，确保技术准确性。

**教学与实践并重**: 采用"核心设计概念 + 源码实现细节"的双重结构，既便于理解设计思想，又提供具体实现参考。

**复杂性透明**: 明确展示了教学简化版本与真实源码的差异，让开发者了解实际系统的复杂性。

### 📈 演进趋势

SGLang的数据结构展现了现代推理系统的演进方向：
- **多模态支持**: 从纯文本扩展到图像、音频、视频
- **分离式架构**: 支持预填充/解码分离的大规模部署
- **高级优化**: 投机解码、混合缓存、DP注意力等前沿技术
- **产业化需求**: 会话管理、LoRA适配器、监控调试等工程特性

理解这些核心数据结构及其相互关系，是深入掌握SGLang调度器工作机制的关键。这些数据结构不仅承载着系统的核心信息，还体现了SGLang在性能、可维护性和扩展性方面的设计考量，为后续的系统定制和优化奠定了坚实基础。
