# 核心数据结构

---

SGLang调度器的高效运行依赖于一系列精心设计的数据结构。这些数据结构不仅承载着请求的各种信息，还负责批次管理、内存分配和模型推理的协调。理解这些核心数据结构是深入掌握SGLang调度器工作原理的基础。

---

## 1. 数据流转架构

SGLang采用分层的数据处理架构，请求从接收到执行经历了四个主要的数据结构层次，每一层都有明确的职责分工：

**调度器层面的ScheduleBatch**负责存储调度器需要的所有信息，包括请求列表、内存池引用、缓存管理等高层调度决策所需的数据。

**模型工作器层面的ModelWorkerBatch**是ScheduleBatch的简化版本，只包含模型前向推理所需的核心数据，去除了调度器特有的管理信息。

**模型执行器层面的ForwardBatch**包含最底层的GPU张量数据，是实际在GPU上执行计算时使用的数据格式。

### 1.1 数据流转可视化

```mermaid
graph TD
    A["🔄 数据流转架构"] --> B["Req类<br/>请求对象"]
    A --> C["ScheduleBatch类<br/>调度器批次"]
    A --> D["ModelWorkerBatch类<br/>模型工作器批次"]
    A --> E["ForwardBatch类<br/>GPU前向批次"]
    
    B --> |"组织成批次"| C
    C --> |"简化传递"| D
    D --> |"张量转换"| E
    
    F["📋 调度器层面"] --> C
    G["⚙️ 模型工作器层面"] --> D
    H["🔥 GPU执行层面"] --> E
    
    C --> |"包含"| I["reqs: List[Req]<br/>req_to_token_pool<br/>tree_cache"]
    D --> |"包含"| J["input_ids: Tensor<br/>seq_lens: Tensor<br/>sampling_info"]
    E --> |"包含"| K["positions: Tensor<br/>attn_backend<br/>token_to_kv_pool"]
    
    style A fill:#e1f5fe,color:#000000
    style B fill:#f3e5f5,color:#000000
    style C fill:#e8f5e8,color:#000000
    style D fill:#fff3e0,color:#000000
    style E fill:#ffebee,color:#000000
    style F fill:#e3f2fd,color:#000000
    style G fill:#f1f8e9,color:#000000
    style H fill:#fff8e1,color:#000000
    style I fill:#f0f4c3,color:#000000
    style J fill:#e8eaf6,color:#000000
    style K fill:#fce4ec,color:#000000
```

**图示说明**：蓝色节点表示数据流转架构总览，紫色表示基础请求对象，绿色表示调度器批次，橙色表示模型工作器批次，红色表示GPU前向批次。箭头展示了数据的转换和传递关系。

这种分层设计确保了每个组件只处理与其职责相关的数据，提高了系统的模块化程度和执行效率。

---

## 2. Req数据结构

Req类是SGLang中表示单个请求的核心数据结构，包含了请求从创建到完成的全部信息。

### 2.1 核心设计概念

**Req类的设计理念**：Req类是SGLang中表示单个请求的核心数据结构，包含了从输入到输出的完整生命周期信息。设计上采用了丰富的参数支持，能够处理文本生成、嵌入计算、多模态输入等多种场景。

> 📝 **简化说明**：以下为Req类的核心属性简化版本，突出主要概念。真实实现包含40+个属性，支持更多高级功能。

```python
class Req:
    """请求对象（简化版）"""
    def __init__(self, rid: str, origin_input_text: str, origin_input_ids: List[int],
                 sampling_params: SamplingParams, return_logprob: bool = False,
                 stream: bool = False, lora_id: Optional[str] = None):
        # 基本请求信息
        self.rid = rid                          # 请求唯一标识符
        self.origin_input_text = origin_input_text    # 原始输入文本
        self.origin_input_ids = origin_input_ids      # 原始输入token序列
        self.output_ids = []                         # 输出token序列
        
        # 处理配置
        self.sampling_params = sampling_params        # 采样参数配置
        self.return_logprob = return_logprob         # 是否返回对数概率
        self.stream = stream                        # 是否启用流式输出
        self.lora_id = lora_id                      # LoRA适配器ID
        
        # 状态管理
        self.finished_reason = None                  # 完成原因
        self.req_pool_idx = None                    # 内存池索引
```

### 2.2 源码实现细节

**真实Req类的完整参数**：生产环境中的Req类支持丰富的参数配置，包括多模态输入、LoRA适配器、会话管理、分离式架构等高级功能。

> 📝 **简化说明**：以下展示真实Req类的主要参数，省略了部分内部实现细节。完整实现请参考 `sglang/srt/managers/schedule_batch.py`。

```python
class Req:
    """真实的SGLang Req类实现"""
    
    def __init__(
        self,
        rid: str,                              # 请求ID（request id）
        origin_input_text: str,               # 原始输入文本
        origin_input_ids: List[int],          # 原始输入token序列
        sampling_params: SamplingParams,      # 采样参数配置
        return_logprob: bool = False,         # 是否返回对数概率
        stream: bool = False,                 # 是否启用流式输出
        lora_id: Optional[str] = None,        # LoRA适配器ID
        session_id: Optional[str] = None,     # 会话ID
        # ... 还有20+个参数支持多模态、分离式架构等高级功能
    ):
        # 基础请求信息
        self.rid = rid                        # 请求唯一标识符
        self.origin_input_text = origin_input_text  # 原始输入文本
        self.origin_input_ids = origin_input_ids    # 原始token序列
        self.output_ids = []                  # 输出token序列（output token ids）
        self.fill_ids = []                    # 完整token序列（input + output）
        
        # 处理配置
        self.sampling_params = sampling_params      # 采样参数
        self.stream = stream                        # 流式输出标志
        self.lora_id = lora_id                     # LoRA适配器ID
        self.session_id = session_id               # 会话ID
        
        # 状态管理
        self.finished_reason = None           # 完成原因（finish reason）
        self.req_pool_idx: Optional[int] = None  # 请求池索引
        self.to_abort = False                 # 是否需要中止
        
        # 多模态支持
        self.multimodal_inputs: Optional[MultimodalInputs] = None  # 多模态输入
        self.input_embeds = input_embeds      # 输入嵌入向量
        
        # 前缀缓存优化
        self.prefix_indices: torch.Tensor = []      # 前缀缓存索引
        self.extend_input_len = 0                   # 需要预填充的token数量
        
        # 还有30+个字段支持增量解码、分离式架构、性能优化等功能...

💡 **实现说明**: 真实的Req类有50+个字段，支持多模态输入、会话管理、LoRA适配器、分离式架构、增量解码、前缀缓存等高级功能。教学版本突出核心的"输入→处理→输出"流程。
```

### 2.3 关键字段分类

**基础信息**: `rid`, `origin_input_text`, `origin_input_ids`, `output_ids`
**处理配置**: `sampling_params`, `stream`, `return_logprob`, `lora_id`  
**状态管理**: `finished_reason`, `to_abort`, `req_pool_idx`
**多模态**: `multimodal_inputs`, `input_embeds`, `token_type_ids`
**会话支持**: `session_id`, `bootstrap_host`, `bootstrap_port`
**性能优化**: `prefix_indices`, `extend_input_len`, `surr_offset`

### 2.4 状态管理

Req类维护着请求在处理过程中的各种状态信息：

**输出管理**  
output_ids列表记录了模型生成的所有token，fill_ids是origin_input_ids和output_ids的组合，表示当前的完整token序列。

**生成控制**  
finished_reason记录请求完成的原因，可能是达到最大长度、遇到停止token或其他条件。各种长度限制和控制参数确保生成过程按预期进行。

**内存映射**  
req_pool_indices和其他索引信息维护着请求在各种内存池中的位置，这对于内存管理和缓存机制至关重要。

### 多模态支持

Req类还支持多模态输入，包括图像、音频等非文本数据：

```python
self.input_embeds = input_embeds            # 输入嵌入向量
self.image_inputs = None                    # 图像输入数据
self.multimodal_inputs = None              # 多模态输入统一接口
```

这种设计使得SGLang能够处理不仅仅是文本的多种模态输入，为多模态大语言模型提供了基础支持。

---

## 3. ScheduleBatch数据结构

ScheduleBatch是调度器层面的核心数据结构，负责管理一个批次中所有请求的信息和资源。

### 3.1 核心设计概念

```python
@dataclasses.dataclass
class ScheduleBatch:
    """批次数据结构的核心概念"""
    # 请求和资源管理
    reqs: List[Req]                          # 批次中的请求列表
    req_to_token_pool: ReqToTokenPool        # 请求到token池的映射
    token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator  # KV缓存分配器
    tree_cache: BasePrefixCache              # 前缀缓存树
    
    # 批次配置
    forward_mode: ForwardMode                # 前向模式（预填充/解码）
    enable_overlap: bool = False             # 是否启用重叠处理
    batch_is_full: bool = False             # 批次是否已满
    
    # GPU张量数据
    input_ids: torch.Tensor = None          # 输入token ID张量
    seq_lens: torch.Tensor = None           # 序列长度张量
    req_pool_indices: torch.Tensor = None   # 请求池索引张量
```

### 3.2 源码实现细节

**真实ScheduleBatch的完整结构**：生产环境中的ScheduleBatch包含了批次管理所需的全部信息，从基础的请求列表到复杂的GPU张量数据，支持多种前向模式和优化策略。

> 📝 **简化说明**：以下展示真实ScheduleBatch的主要属性，省略了部分内部方法实现。完整实现请参考 `sglang/srt/managers/schedule_batch.py`。

```python
@dataclasses.dataclass
class ScheduleBatch(ScheduleBatchDisaggregationDecodeMixin):
    """真实的SGLang ScheduleBatch实现"""
    
    # 核心组织
    reqs: List[Req]                                    # 批次中的请求列表
    req_to_token_pool: ReqToTokenPool = None          # 请求到token池映射
    token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator = None  # KV缓存分配器
    tree_cache: BasePrefixCache = None                # 前缀缓存
    
    # 批次控制
    forward_mode: ForwardMode = None                  # 前向模式（预填充/解码）
    batch_is_full: bool = False                       # 批次满标志
    enable_overlap: bool = False                      # 是否启用重叠处理
    launch_done: Optional[threading.Event] = None    # 重叠事件循环同步
    
    # GPU张量数据
    input_ids: torch.Tensor = None                    # 输入token ID张量 [b]
    seq_lens: torch.Tensor = None                     # 序列长度张量 [b]
    req_pool_indices: torch.Tensor = None             # 请求池索引张量 [b]
    out_cache_loc: torch.Tensor = None                # KV缓存输出位置 [b]
    
    # 采样信息
    sampling_info: SamplingBatchInfo = None           # 当前批次采样信息
    next_batch_sampling_info: SamplingBatchInfo = None  # 下一批次采样信息
    
    # 多模态与高级功能
    multimodal_inputs: Optional[List] = None          # 多模态输入数据
    spec_algorithm: SpeculativeAlgorithm = None       # 投机解码算法
    has_stream: bool = False                          # 是否有流式请求
    has_grammar: bool = False                         # 是否有语法约束
    
    # ... 还有40+个字段支持DP注意力、分层缓存、分离式架构等高级功能

💡 **实现说明**: 真实的ScheduleBatch有60+个字段，支持多模态、DP注意力、投机解码、分层缓存、分离式架构等复杂功能。上述代码突出"请求→资源→张量"的核心组织结构。
```

### 3.3 字段功能分类

**核心组织**: `reqs`, `req_to_token_pool`, `token_to_kv_pool_allocator`, `tree_cache`
**批次控制**: `forward_mode`, `batch_is_full`, `enable_overlap`, `launch_done`
**GPU数据**: `input_ids`, `seq_lens`, `req_pool_indices`, `out_cache_loc`
**多模态**: `multimodal_inputs`, `input_embeds`, `token_type_ids`
**性能优化**: `spec_algorithm`, `can_run_dp_cuda_graph`, `hicache_consumer_index`
**特殊功能**: `has_stream`, `has_grammar`, `is_prefill_only`, `chunked_req`

### 模型执行数据

ScheduleBatch还包含了传递给模型执行器的批量化数据：

```python
# Batched arguments to model runner
input_ids: torch.Tensor = None            # 输入token ID张量
seq_lens: torch.Tensor = None             # 序列长度张量
req_pool_indices: torch.Tensor = None     # 请求池索引张量
out_cache_loc: torch.Tensor = None        # 输出缓存位置张量
```

这些张量化的数据是GPU计算的直接输入，将批次中所有请求的相关信息组织成了适合并行处理的格式。

### 采样和生成信息

```python
# Sampling info
sampling_info: SamplingBatchInfo = None           # 当前批次采样信息
next_batch_sampling_info: SamplingBatchInfo = None # 下一批次采样信息
```

采样信息管理着批次中所有请求的采样参数，确保每个请求都能按照指定的方式进行文本生成。

---

## 4. ModelWorkerBatch数据结构

ModelWorkerBatch是ScheduleBatch向模型工作器传递的简化版本，去除了调度器特有的管理信息，专注于模型推理所需的核心数据。

### 4.1 核心设计概念

```python
@dataclasses.dataclass
class ModelWorkerBatch:
    """模型工作器批次的核心概念"""
    bid: int                               # 批次ID
    forward_mode: ForwardMode              # 前向模式（预填充/解码）
    input_ids: torch.Tensor               # 输入token张量
    req_pool_indices: torch.Tensor        # 请求池索引
    seq_lens: torch.Tensor                # 序列长度
    out_cache_loc: torch.Tensor           # 输出缓存位置
    sampling_info: SamplingBatchInfo      # 采样信息
```

### 4.2 源码实现细节

```python
@dataclasses.dataclass
class ModelWorkerBatch:
    """真实的SGLang ModelWorkerBatch实现"""
    
    # Basic batch info
    bid: int                               # 批次ID
    forward_mode: ForwardMode              # 前向模式
    
    # Core tensors
    input_ids: torch.Tensor               # 输入token张量
    req_pool_indices: torch.Tensor        # 请求池索引
    seq_lens: torch.Tensor                # 序列长度
    out_cache_loc: torch.Tensor           # KV缓存输出位置
    seq_lens_cpu: Optional[torch.Tensor]  # CPU上的序列长度张量
    seq_lens_sum: int                     # 序列长度总和

    # For logprob
    return_logprob: bool
    top_logprobs_nums: Optional[List[int]]
    token_ids_logprobs: Optional[List[List[int]]]

    # For DP attention
    global_num_tokens: Optional[List[int]]
    global_num_tokens_for_logprob: Optional[List[int]]
    is_extend_in_batch: bool
    can_run_dp_cuda_graph: bool
    tbo_split_seq_index: Optional[int]
    global_forward_mode: Optional[ForwardMode]

    # For extend mode
    extend_num_tokens: Optional[int]
    extend_seq_lens: Optional[List[int]]
    extend_prefix_lens: Optional[List[int]]
    extend_logprob_start_lens: Optional[List[int]]
    extend_input_logprob_token_ids: Optional[torch.Tensor]

    # For multimodal
    multimodal_inputs: Optional[List[MultimodalInputs]]

    # For encoder-decoder
    encoder_cached: Optional[List[bool]]
    encoder_lens: Optional[torch.Tensor]
    encoder_lens_cpu: Optional[List[int]]
    encoder_out_cache_loc: Optional[torch.Tensor]

    # For LoRA
    lora_ids: Optional[List[str]]

    # Sampling info
    sampling_info: SamplingBatchInfo

    # Additional data
    orig_seq_lens: Optional[torch.Tensor] = None  # Qwen-1M相关
    input_embeds: Optional[torch.Tensor] = None   # 输入嵌入
    token_type_ids: Optional[torch.Tensor] = None # 跨编码器模型

    # Speculative decoding
    spec_algorithm: SpeculativeAlgorithm = None
    spec_info: Optional[Union[EagleVerifyInput, EagleDraftInput]] = None

💡 **实现说明**: 真实的ModelWorkerBatch有30+个字段，包含DP注意力、编码器-解码器、LoRA、投机解码等复杂功能的支持。教学版本突出核心的"输入→推理→输出"数据流。
```

这种简化确保了模型工作器只需要关注推理相关的信息，提高了数据传递的效率。

---

## 5. ForwardBatch数据结构

ForwardBatch是数据流转的最底层，包含GPU模型执行时的所有张量数据，是实际在GPU上执行计算的数据格式。

### 5.1 核心设计概念

**GPU计算的数据载体**：ForwardBatch将ModelWorkerBatch进一步转换为GPU友好的张量格式，专注于模型推理的核心计算需求。

> 📝 **简化说明**：以下为ForwardBatch的核心张量简化版本，突出GPU计算要素。真实实现包含50+个字段，支持各种高级优化。

```python
@dataclass
class ForwardBatch:
    """GPU前向计算批次（简化版）"""
    # 基础信息
    forward_mode: ForwardMode           # 前向模式（预填充/解码）
    batch_size: int                     # 批次大小
    
    # 核心张量数据
    input_ids: torch.Tensor            # 输入token ID张量 [batch_size]
    req_pool_indices: torch.Tensor     # 请求池索引 [batch_size]
    seq_lens: torch.Tensor             # 序列长度 [batch_size]
    out_cache_loc: torch.Tensor        # KV缓存输出位置 [batch_size]
    
    # 位置和长度信息
    positions: torch.Tensor            # 位置编码 [total_tokens]
    seq_lens_sum: int                  # 所有序列长度总和
```

### 5.2 源码实现细节

**真实ForwardBatch的完整结构**：生产环境中的ForwardBatch包含了GPU模型执行所需的全部张量数据，支持多模态、投机解码、DP注意力等高级功能。

> 📝 **简化说明**：以下展示真实ForwardBatch的主要张量，省略了部分优化相关字段。完整实现请参考 `sglang/srt/model_executor/forward_batch_info.py`。

```python
@dataclass
class ForwardBatch:
    """真实的SGLang ForwardBatch实现"""
    
    # 基础前向信息
    forward_mode: ForwardMode           # 前向模式
    batch_size: int                     # 批次大小
    
    # 核心输入张量
    input_ids: torch.Tensor            # 输入token ID [batch_size]
    req_pool_indices: torch.Tensor     # 请求池索引 [batch_size]
    seq_lens: torch.Tensor             # 序列长度 [batch_size]
    out_cache_loc: torch.Tensor        # KV缓存输出位置 [batch_size]
    seq_lens_sum: int                  # 序列长度总和
    
    # 位置和注意力信息
    positions: torch.Tensor = None     # 位置编码张量
    seq_lens_cpu: Optional[torch.Tensor] = None  # CPU上的序列长度
    
    # 预填充模式专用
    extend_num_tokens: Optional[int] = None      # 扩展token数量
    extend_seq_lens: Optional[torch.Tensor] = None  # 扩展序列长度
    extend_start_loc: Optional[torch.Tensor] = None  # 扩展起始位置
    
    # 多模态支持
    multimodal_inputs: Optional[List] = None     # 多模态输入数据
    input_embeds: Optional[torch.Tensor] = None  # 输入嵌入张量
    
    # KV缓存和注意力后端
    token_to_kv_pool: KVCache = None            # KV缓存池引用
    attn_backend: AttentionBackend = None       # 注意力后端
    
    # DP注意力优化
    global_num_tokens_gpu: Optional[torch.Tensor] = None  # 全局token数GPU张量
    dp_padding_mode: Optional[DpPaddingMode] = None       # DP填充模式
    
    # 投机解码支持
    spec_algorithm: SpeculativeAlgorithm = None  # 投机解码算法
    spec_info: Optional[Union[EagleVerifyInput, EagleDraftInput]] = None
```

### 5.3 数据转换流程

**从ModelWorkerBatch到ForwardBatch的转换**：

> 📝 **简化说明**：以下展示真实的ForwardBatch创建过程，基于实际的`init_new`类方法。完整实现请参考 `sglang/srt/model_executor/forward_batch_info.py`。

```python
@classmethod
def init_new(cls, batch: ModelWorkerBatch, model_runner: ModelRunner):
    """从ModelWorkerBatch创建ForwardBatch的真实方法"""
    return cls(
        # 基础信息从ModelWorkerBatch直接复制
        forward_mode=batch.forward_mode,           # 前向模式
        batch_size=len(batch.seq_lens),           # 批次大小
        input_ids=batch.input_ids,                # 输入token张量
        req_pool_indices=batch.req_pool_indices,  # 请求池索引
        seq_lens=batch.seq_lens,                  # 序列长度
        out_cache_loc=batch.out_cache_loc,        # 输出缓存位置
        seq_lens_sum=batch.seq_lens_sum,          # 序列长度总和
        
        # 多模态和编码器支持
        multimodal_inputs=batch.multimodal_inputs,      # 多模态输入
        encoder_cached=batch.encoder_cached,            # 编码器缓存状态
        encoder_lens=batch.encoder_lens,                # 编码器长度
        
        # 采样和对数概率
        return_logprob=batch.return_logprob,            # 是否返回对数概率
        top_logprobs_nums=batch.top_logprobs_nums,      # top-k对数概率数量
        token_ids_logprobs=batch.token_ids_logprobs,    # token对数概率
        
        # LoRA和投机解码
        lora_ids=batch.lora_ids,                        # LoRA适配器ID列表
        sampling_info=batch.sampling_info,              # 采样信息
        spec_algorithm=batch.spec_algorithm,            # 投机解码算法
        
        # 从model_runner获取资源引用
        req_to_token_pool=model_runner.req_to_token_pool,    # 请求到token池
        token_to_kv_pool=model_runner.token_to_kv_pool,      # KV缓存池
        attn_backend=model_runner.attn_backend,              # 注意力后端
    )
```

---

## 6. 内存管理数据结构

### 6.1 内存管理组件

**ReqToTokenPool**：管理请求到token位置的映射关系，维护每个请求在内存中的token位置信息，支持动态的内存分配和回收。

**BaseTokenToKVPoolAllocator**：KV缓存分配器的抽象基类，负责管理KV缓存的分配、回收和优化。不同实现可以采用不同的分配策略。

**BasePrefixCache**：前缀缓存的通用接口，具体实现如RadixCache能够识别和复用请求间的公共前缀，显著减少计算开销。

### 6.2 内存分配协作流程

当一个请求被添加到ScheduleBatch时，内存管理组件是如何协同工作的：

```python
def allocate_memory_for_request(req: Req, schedule_batch: ScheduleBatch):
    """为请求分配内存的协作流程（简化版）"""
    # 1. 请求池分配 - 分配请求槽位
    req_pool_idx = schedule_batch.req_to_token_pool.alloc()  # 分配请求池索引
    req.req_pool_idx = req_pool_idx
    
    # 2. KV缓存分配 - 为序列分配KV缓存空间
    num_tokens = len(req.origin_input_ids) + req.sampling_params.max_new_tokens
    kv_indices = schedule_batch.token_to_kv_pool_allocator.alloc(num_tokens)
    
    # 3. 前缀缓存查找 - 检查是否有可复用的前缀
    prefix_len = schedule_batch.tree_cache.match_prefix(req.origin_input_ids)
    if prefix_len > 0:
        # 复用前缀，减少需要分配的KV缓存
        req.prefix_indices = schedule_batch.tree_cache.get_prefix_indices(req)
        req.extend_input_len = len(req.origin_input_ids) - prefix_len
    
    return req_pool_idx, kv_indices

def release_memory_for_request(req: Req, schedule_batch: ScheduleBatch):
    """释放请求内存的协作流程（简化版）"""
    # 1. 释放请求池槽位
    if req.req_pool_idx is not None:
        schedule_batch.req_to_token_pool.free(req.req_pool_idx)
    
    # 2. 释放KV缓存
    if hasattr(req, 'kv_indices'):
        schedule_batch.token_to_kv_pool_allocator.free(req.kv_indices)
    
    # 3. 更新前缀缓存
    schedule_batch.tree_cache.cache_finished_req(req)  # 缓存完成的请求
```

## 7. 多模态数据结构

SGLang支持多模态输入，相关的数据结构包括：

### 7.1 MultimodalInputs

这个类统一管理各种模态的输入数据，包括图像的pixel_values、音频的audio_values等。通过统一的接口，不同模态的数据能够被一致地处理和传递。

### 7.2 MultimodalDataItem

表示单个多模态数据项，包含了数据类型、内容和相关的元数据信息。

## 8. 批量请求数据结构

SGLang支持批量请求以提高网络传输效率和处理性能：

### 8.1 BatchTokenizedGenerateReqInput

批量生成请求的输入结构，包含多个TokenizedGenerateReqInput：

```python
@dataclass
class BatchTokenizedGenerateReqInput:
    """批量生成请求输入"""
    requests: List[TokenizedGenerateReqInput]  # 批量请求列表
    
    def __len__(self):
        return len(self.requests)
    
    def __iter__(self):
        return iter(self.requests)
```

### 8.2 BatchTokenizedEmbeddingReqInput

批量嵌入请求的输入结构，包含多个TokenizedEmbeddingReqInput：

```python
@dataclass  
class BatchTokenizedEmbeddingReqInput:
    """批量嵌入请求输入"""
    requests: List[TokenizedEmbeddingReqInput]  # 批量请求列表
    
    def __len__(self):
        return len(self.requests)
    
    def __iter__(self):
        return iter(self.requests)
```

这些批量结构通过减少网络往返次数和请求处理开销来提高系统整体性能。

## 9. 分离式架构数据结构

在分离式架构中，请求对象包含额外的分离式相关字段：

```python
class Req:
    # 分离式架构相关字段
    disagg_kv_sender: Optional[BaseKVSender] = None      # KV发送器
    disagg_kv_receiver: Optional[BaseKVReceiver] = None  # KV接收器
    bootstrap_host: Optional[str] = None                 # 启动主机
    bootstrap_port: Optional[int] = None                 # 启动端口
    bootstrap_room: Optional[str] = None                 # 启动房间ID
    
    # SWA混合缓存相关字段
    swa_uuid_for_lock: Optional[str] = None             # SWA锁定UUID
```

## 10. 数据结构协作关系

这些数据结构之间存在着复杂的协作关系。Req对象是最基本的数据单元，ScheduleBatch将多个Req组织成批次，同时管理着各种资源池的引用。在处理过程中，ScheduleBatch会转换成ModelWorkerBatch传递给下游组件，最终转换成ForwardBatch在GPU上执行。

内存管理相关的数据结构为这个过程提供支撑，确保每个请求都能获得必要的内存资源，同时通过缓存机制优化性能。多模态数据结构则扩展了系统的输入能力，使得SGLang能够处理不仅仅是文本的多种类型输入。

---

## 11. 核心设计原则

SGLang的数据结构设计体现了几个重要的设计原则：

**分层抽象**: 通过Req→ScheduleBatch→ModelWorkerBatch的分层设计，系统能够在不同抽象层面进行优化，调度器关注高层决策，模型执行器关注底层计算。

**模块化设计**: 各个数据结构职责清晰，相互之间通过明确的接口进行交互，提高了系统的可维护性和可测试性。

**性能优化**: 数据结构充分考虑了性能因素：
- 批量化处理减少函数调用开销
- 张量化数据支持GPU并行计算
- 内存池设计提高内存局部性
- 缓存友好的数据布局

**扩展性**: 通过抽象基类和mixin模式，数据结构具备良好的扩展性，能够支持新功能的添加和现有功能的优化。

### 11.1 实现特色

**源码准确性**: 本文档基于真实SGLang源码编写，所有数据结构定义都来自实际实现，确保技术准确性。

**教学与实践并重**: 采用"核心设计概念 + 源码实现细节"的双重结构，既便于理解设计思想，又提供具体实现参考。

**复杂性透明**: 明确展示了教学简化版本与真实源码的差异，让开发者了解实际系统的复杂性。

### 11.2 演进趋势

SGLang的数据结构展现了现代推理系统的演进方向：
- **多模态支持**: 从纯文本扩展到图像、音频、视频
- **分离式架构**: 支持预填充/解码分离的大规模部署
- **高级优化**: 投机解码、混合缓存、DP注意力等前沿技术
- **产业化需求**: 会话管理、LoRA适配器、监控调试等工程特性

理解这些核心数据结构及其相互关系，是深入掌握SGLang调度器工作机制的关键。这些数据结构不仅承载着系统的核心信息，还体现了SGLang在性能、可维护性和扩展性方面的设计考量。

**承上启下**：在第一章我们了解了调度器的整体架构和设计理念，本章深入剖析了支撑这些架构的核心数据抽象。有了这些基础，我们就为深入探讨调度器在实际运行中的请求处理机制、批次调度策略和内存管理算法奠定了坚实基础。接下来的章节将展示这些数据结构是如何在具体的调度流程中发挥作用的。
