# äº‹ä»¶å¾ªç¯å®ç°

---

SGLangè°ƒåº¦å™¨æ”¯æŒä¸‰ç§ä¸»è¦çš„äº‹ä»¶å¾ªç¯æ¨¡å¼ï¼Œæ¯ç§éƒ½é’ˆå¯¹ç‰¹å®šçš„ä½¿ç”¨åœºæ™¯å’Œæ€§èƒ½éœ€æ±‚è¿›è¡Œäº†ä¼˜åŒ–ã€‚è¿™äº›äº‹ä»¶å¾ªç¯æ˜¯è°ƒåº¦å™¨çš„æ‰§è¡Œå¼•æ“ï¼Œå†³å®šäº†æ•´ä¸ªç³»ç»Ÿçš„å·¥ä½œæµç¨‹å’Œæ€§èƒ½ç‰¹æ€§ã€‚

---

## ğŸ›ï¸ äº‹ä»¶å¾ªç¯é€‰æ‹©æœºåˆ¶

è°ƒåº¦å™¨æ ¹æ®é…ç½®å‚æ•°è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„äº‹ä»¶å¾ªç¯ï¼š

```python
# åœ¨run_scheduler_processä¸­çš„é€‰æ‹©é€»è¾‘
disaggregation_mode: DisaggregationMode = scheduler.disaggregation_mode
if disaggregation_mode == DisaggregationMode.NULL:
    if server_args.pp_size > 1:
        scheduler.event_loop_pp()          # æµæ°´çº¿å¹¶è¡Œ
    elif scheduler.enable_overlap:
        scheduler.event_loop_overlap()     # CPU-GPUé‡å 
    else:
        scheduler.event_loop_normal()      # æ ‡å‡†åŒæ­¥å¾ªç¯
elif disaggregation_mode == DisaggregationMode.PREFILL:
    # é¢„å¡«å……åˆ†ç¦»æ¨¡å¼çš„å„ç§å¾ªç¯...
elif disaggregation_mode == DisaggregationMode.DECODE:
    # è§£ç åˆ†ç¦»æ¨¡å¼çš„å„ç§å¾ªç¯...
```

è¿™ç§è‡ªåŠ¨é€‰æ‹©æœºåˆ¶ç¡®ä¿äº†è°ƒåº¦å™¨èƒ½å¤Ÿæ ¹æ®éƒ¨ç½²é…ç½®é€‰æ‹©æœ€ä¼˜çš„æ‰§è¡Œæ¨¡å¼ã€‚

---

## ğŸ”„ æ ‡å‡†äº‹ä»¶å¾ªç¯

### ğŸ’¡ è®¾è®¡ç†å¿µå’Œå®ç°

æ ‡å‡†äº‹ä»¶å¾ªç¯éµå¾ªç»å…¸çš„ä¸»å¾ªç¯è®¾è®¡æ¨¡å¼ï¼Œé‡‡ç”¨ç®€å•ç›´æ¥çš„ä¸²è¡Œå¤„ç†æ–¹å¼ï¼š

```python
@DynamicGradMode()
def event_loop_normal(self):
    """A normal scheduler loop."""
    while True:
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        batch = self.get_next_batch_to_run()
        self.cur_batch = batch

        if batch:
            result = self.run_batch(batch)
            self.process_batch_result(batch, result)
        else:
            # When the server is idle, do self-check and re-init some states
            self.self_check_during_idle()

        self.last_batch = batch
```

è¿™ä¸ªå®ç°æ¸…æ™°åœ°å±•ç¤ºäº†è°ƒåº¦å™¨çš„æ ¸å¿ƒå·¥ä½œæµç¨‹ï¼šè¯·æ±‚æ¥æ”¶ â†’ è¯·æ±‚å¤„ç† â†’ æ‰¹æ¬¡è°ƒåº¦ â†’ æ¨¡å‹æ¨ç† â†’ ç»“æœå¤„ç† â†’ çŠ¶æ€æ›´æ–°ã€‚æ¯ä¸ªæ­¥éª¤éƒ½æ˜¯åŒæ­¥æ‰§è¡Œï¼Œé€»è¾‘æ¸…æ™°æ˜“äºè°ƒè¯•ã€‚

### ç‰¹ç‚¹

**é€»è¾‘æ¸…æ™°**: ä¸²è¡Œæ‰§è¡Œï¼Œæ¯ä¸ªæ­¥éª¤éƒ½ç­‰å¾…å‰ä¸€æ­¥å®Œæˆ
**å»¶è¿Ÿæœ€ä½**: æ²¡æœ‰é¢å¤–çš„åŒæ­¥å¼€é”€
**ç¨³å®šå¯é **: é€‚åˆå¼€å‘è°ƒè¯•å’Œå»¶è¿Ÿæ•æ„Ÿåœºæ™¯

## é‡å äº‹ä»¶å¾ªç¯

### CPU-GPUé‡å ä¼˜åŒ–

é‡å äº‹ä»¶å¾ªç¯é€šè¿‡event_loop_overlapæ–¹æ³•å®ç°äº†CPUå¤„ç†å’ŒGPUè®¡ç®—çš„å¹¶è¡Œæ‰§è¡Œï¼š

```python
@DynamicGradMode()
def event_loop_overlap(self):
    """A scheduler loop that overlaps the CPU processing and GPU computation."""
    self.result_queue = deque()

    while True:
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        batch = self.get_next_batch_to_run()
        self.cur_batch = batch

        if batch:
            batch.launch_done = threading.Event()
            result = self.run_batch(batch)
            self.result_queue.append((batch.copy(), result))

            if self.last_batch is None:
                # åˆ›å»ºè™šæ‹Ÿé¦–æ‰¹æ¬¡æ¥å¯åŠ¨é‡å è°ƒåº¦çš„æµæ°´çº¿
                tmp_batch = ScheduleBatch(
                    reqs=None,
                    forward_mode=ForwardMode.DUMMY_FIRST,
                    next_batch_sampling_info=self.tp_worker.cur_sampling_info,
                )
                self.process_batch_result(tmp_batch, None, batch.launch_done)

        if self.last_batch:
            # å¤„ç†ä¸Šä¸€æ‰¹æ¬¡çš„ç»“æœ
            tmp_batch, tmp_result = self.result_queue.popleft()
            tmp_batch.next_batch_sampling_info = (
                self.tp_worker.cur_sampling_info if batch else None
            )
            self.process_batch_result(
                tmp_batch, tmp_result, batch.launch_done if batch else None
            )
        elif batch is None:
            self.self_check_during_idle()

        self.last_batch = batch
```

### é‡å æœºåˆ¶åŸç†

é‡å äº‹ä»¶å¾ªç¯çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†CPUå¯†é›†çš„è°ƒåº¦å·¥ä½œä¸GPUå¯†é›†çš„æ¨ç†è®¡ç®—å¹¶è¡Œè¿›è¡Œï¼š

**ç»“æœé˜Ÿåˆ—ç®¡ç†**: ä½¿ç”¨dequeæ¥ç®¡ç†æ‰¹æ¬¡ç»“æœï¼Œæ”¯æŒå¼‚æ­¥çš„ç»“æœå¤„ç†ã€‚

**äº‹ä»¶åŒæ­¥**: é€šè¿‡threading.Eventæ¥åè°ƒCPUå’ŒGPUä¹‹é—´çš„åŒæ­¥ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§ã€‚

**æµæ°´çº¿å¯åŠ¨**: åˆ›å»ºè™šæ‹Ÿçš„é¦–æ‰¹æ¬¡æ¥å¯åŠ¨æµæ°´çº¿ï¼Œé¿å…å†·å¯åŠ¨å»¶è¿Ÿã€‚

**å¹¶è¡Œå¤„ç†**: å½“GPUæ‰§è¡Œå½“å‰æ‰¹æ¬¡æ—¶ï¼ŒCPUåŒæ—¶å¤„ç†ä¸Šä¸€æ‰¹æ¬¡çš„ç»“æœå’Œå‡†å¤‡ä¸‹ä¸€æ‰¹æ¬¡ã€‚

### ç‰¹ç‚¹

**é«˜ååé‡**: å¯æå‡20-40%çš„ååé‡
**èµ„æºå¹¶è¡Œ**: CPUå’ŒGPUåŒæ—¶å·¥ä½œï¼Œæé«˜èµ„æºåˆ©ç”¨ç‡
**ç”Ÿäº§é¦–é€‰**: å¤§å¤šæ•°ç”Ÿäº§ç¯å¢ƒçš„æœ€ä½³é€‰æ‹©

## æµæ°´çº¿å¹¶è¡Œäº‹ä»¶å¾ªç¯

### å¤šå¾®æ‰¹æ¬¡ç®¡ç†

æµæ°´çº¿å¹¶è¡Œäº‹ä»¶å¾ªç¯é€šè¿‡event_loop_ppæ–¹æ³•æ”¯æŒå¤§æ¨¡å‹çš„åˆ†å±‚å¤„ç†ï¼š

```python
@DynamicGradMode()
def event_loop_pp(self):
    """A non-overlap scheduler loop for pipeline parallelism."""
    mbs = [None] * self.pp_size
    last_mbs = [None] * self.pp_size
    self.running_mbs = [
        ScheduleBatch(reqs=[], batch_is_full=False) for _ in range(self.pp_size)
    ]

    while True:
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        # ä¸ºæ¯ä¸ªæµæ°´çº¿é˜¶æ®µå‡†å¤‡å¾®æ‰¹æ¬¡
        for mbi in range(self.pp_size):
            # åˆå¹¶ä¸Šä¸€è½®çš„å¾®æ‰¹æ¬¡ç»“æœ
            if last_mbs[mbi] and last_mbs[mbi].forward_mode.is_extend():
                # è¿‡æ»¤å’Œåˆå¹¶é€»è¾‘...
                
            # è·å–æ–°çš„é¢„å¡«å……æ‰¹æ¬¡
            new_batch = self.get_new_batch_prefill()
            mbs[mbi] = new_batch if new_batch else self.running_mbs[mbi]

        # æ‰§è¡Œæ‰€æœ‰å¾®æ‰¹æ¬¡
        if any(mb and not mb.is_empty() for mb in mbs):
            results = self.run_batch_pp(mbs)
            for mbi, (mb, result) in enumerate(zip(mbs, results)):
                if mb and not mb.is_empty():
                    self.process_batch_result(mb, result)
        else:
            self.self_check_during_idle()

        last_mbs = mbs.copy()
```

### æµæ°´çº¿è°ƒåº¦ç­–ç•¥

æµæ°´çº¿å¹¶è¡Œçš„å…³é”®åœ¨äºå¤šä¸ªå¾®æ‰¹æ¬¡çš„åè°ƒæ‰§è¡Œï¼š

**å¾®æ‰¹æ¬¡åˆ†é…**: æ¯ä¸ªæµæ°´çº¿é˜¶æ®µç»´æŠ¤ç‹¬ç«‹çš„å¾®æ‰¹æ¬¡ï¼Œé¿å…ä¸åŒé˜¶æ®µé—´çš„èµ„æºç«äº‰ã€‚

**åŒæ­¥æœºåˆ¶**: é€šè¿‡barrieråŒæ­¥ç¡®ä¿å„ä¸ªæµæ°´çº¿é˜¶æ®µçš„æ‰§è¡Œé¡ºåºã€‚

**è´Ÿè½½å‡è¡¡**: åŠ¨æ€è°ƒæ•´å„ä¸ªå¾®æ‰¹æ¬¡çš„å¤§å°ï¼Œå¹³è¡¡å„é˜¶æ®µçš„è®¡ç®—è´Ÿè½½ã€‚

### ç‰¹ç‚¹

**æ”¯æŒè¶…å¤§æ¨¡å‹**: çªç ´å•GPUæ˜¾å­˜é™åˆ¶
**çº¿æ€§æ‰©å±•**: ç†è®ºä¸Šå¯ä»¥æ— é™å¢åŠ æ¨¡å‹å±‚æ•°
**ä¸“ç”¨åœºæ™¯**: ä¸»è¦ç”¨äºç‰¹å¤§æ¨¡å‹çš„åˆ†å¸ƒå¼æ¨ç†

## DynamicGradModeè£…é¥°å™¨

@DynamicGradMode()è£…é¥°å™¨æ˜¯æ‰€æœ‰äº‹ä»¶å¾ªç¯çš„é‡è¦ä¼˜åŒ–æœºåˆ¶ï¼š

```python
@DynamicGradMode()
def event_loop_xxx(self):
    # æ ¹æ®å½“å‰æ“ä½œè‡ªåŠ¨åˆ‡æ¢æ¢¯åº¦è®¡ç®—æ¨¡å¼
    # æ¨ç†æ—¶å…³é—­æ¢¯åº¦èŠ‚çœå†…å­˜ï¼ŒLoRAè®­ç»ƒæ—¶å¼€å¯æ¢¯åº¦
```

è¿™ç§åŠ¨æ€åˆ‡æ¢ä½¿å¾—åŒä¸€ä¸ªè°ƒåº¦å™¨èƒ½å¤ŸåŒæ—¶æ”¯æŒçº¯æ¨ç†å’Œå¸¦æ¢¯åº¦çš„æ“ä½œã€‚

## æ€§èƒ½ç‰¹æ€§å¯¹æ¯”

### å»¶è¿Ÿç‰¹æ€§

**æ ‡å‡†å¾ªç¯**: æœ€ä½å»¶è¿Ÿï¼Œé€‚åˆå®æ—¶æ€§è¦æ±‚é«˜çš„åœºæ™¯
**é‡å å¾ªç¯**: ä¸­ç­‰å»¶è¿Ÿï¼Œä½†æ˜¾è‘—æé«˜ååé‡  
**æµæ°´çº¿å¾ªç¯**: è¾ƒé«˜çš„å•æ¬¡å»¶è¿Ÿï¼Œä½†æ”¯æŒæ›´å¤§çš„æ¨¡å‹

### ååé‡ç‰¹æ€§

**æ ‡å‡†å¾ªç¯**: åŸºå‡†ååé‡ï¼Œå—ä¸²è¡Œå¤„ç†é™åˆ¶
**é‡å å¾ªç¯**: å¯æå‡20-40%çš„ååé‡ï¼Œå…·ä½“å–å†³äºCPU/GPUæ¯”ä¾‹
**æµæ°´çº¿å¾ªç¯**: ç†è®ºä¸Šå¯çº¿æ€§æ‰©å±•ï¼Œæ”¯æŒè¶…å¤§æ¨¡å‹æ¨ç†

### é€‚ç”¨åœºæ™¯

**æ ‡å‡†å¾ªç¯**: 
- å¼€å‘è°ƒè¯•ç¯å¢ƒ
- å°è§„æ¨¡éƒ¨ç½²
- å»¶è¿Ÿæ•æ„Ÿåº”ç”¨

**é‡å å¾ªç¯**:
- ç”Ÿäº§ç¯å¢ƒçš„é¦–é€‰
- é«˜ååé‡éœ€æ±‚
- CPU-GPUå‡è¡¡çš„å·¥ä½œè´Ÿè½½

**æµæ°´çº¿å¾ªç¯**:
- è¶…å¤§æ¨¡å‹æ¨ç†
- å¤šGPUé›†ç¾¤éƒ¨ç½²
- æ˜¾å­˜å—é™åœºæ™¯

## æ€»ç»“

SGLangçš„ä¸‰ç§äº‹ä»¶å¾ªç¯è®¾è®¡ä½“ç°äº†å¯¹ä¸åŒåº”ç”¨åœºæ™¯çš„æ·±å…¥ç†è§£å’Œç²¾å¿ƒä¼˜åŒ–ã€‚æ ‡å‡†å¾ªç¯æä¾›äº†ç¨³å®šå¯é çš„åŸºå‡†å®ç°ï¼Œé‡å å¾ªç¯é€šè¿‡CPU-GPUå¹¶è¡Œæ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œæµæ°´çº¿å¾ªç¯åˆ™æ”¯æŒäº†è¶…å¤§æ¨¡å‹çš„åˆ†å¸ƒå¼æ¨ç†ã€‚

æ¯ç§äº‹ä»¶å¾ªç¯éƒ½æœ‰å…¶é€‚ç”¨çš„åœºæ™¯å’Œä¼˜åŠ¿ï¼Œé€šè¿‡è‡ªåŠ¨é€‰æ‹©æœºåˆ¶ï¼ŒSGLangèƒ½å¤Ÿæ ¹æ®é…ç½®å’Œç¡¬ä»¶ç¯å¢ƒé€‰æ‹©æœ€ä¼˜çš„æ‰§è¡Œæ¨¡å¼ã€‚ç†è§£è¿™äº›äº‹ä»¶å¾ªç¯çš„åŸç†å’Œç‰¹æ€§ï¼Œå¯¹äºç³»ç»Ÿéƒ¨ç½²ã€æ€§èƒ½è°ƒä¼˜å’Œé—®é¢˜è¯Šæ–­éƒ½å…·æœ‰é‡è¦æ„ä¹‰ã€‚

åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œå»ºè®®ä¼˜å…ˆé€‰æ‹©é‡å å¾ªç¯ç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œå®ƒåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹èƒ½å¤Ÿæä¾›æœ€ä½³çš„æ€§èƒ½å¹³è¡¡ã€‚å¯¹äºè¶…å¤§æ¨¡å‹æˆ–æ˜¾å­˜å—é™çš„åœºæ™¯ï¼Œæµæ°´çº¿å¾ªç¯æ˜¯å”¯ä¸€å¯è¡Œçš„é€‰æ‹©ã€‚è€Œæ ‡å‡†å¾ªç¯åˆ™ä¸»è¦ç”¨äºå¼€å‘è°ƒè¯•å’Œç‰¹æ®Šçš„å»¶è¿Ÿæ•æ„Ÿåœºæ™¯ã€‚