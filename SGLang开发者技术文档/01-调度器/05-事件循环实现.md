# 事件循环实现

---

SGLang调度器支持三种主要的事件循环模式，每种都针对特定的使用场景和性能需求进行了优化。这些事件循环是调度器的执行引擎，决定了整个系统的工作流程和性能特性。

---

## 🎛️ 事件循环选择机制

调度器根据配置参数自动选择合适的事件循环：

```python
# 在run_scheduler_process中的选择逻辑
disaggregation_mode: DisaggregationMode = scheduler.disaggregation_mode
if disaggregation_mode == DisaggregationMode.NULL:
    if server_args.pp_size > 1:
        scheduler.event_loop_pp()          # 流水线并行
    elif scheduler.enable_overlap:
        scheduler.event_loop_overlap()     # CPU-GPU重叠
    else:
        scheduler.event_loop_normal()      # 标准同步循环
elif disaggregation_mode == DisaggregationMode.PREFILL:
    # 预填充分离模式的各种循环...
elif disaggregation_mode == DisaggregationMode.DECODE:
    # 解码分离模式的各种循环...
```

这种自动选择机制确保了调度器能够根据部署配置选择最优的执行模式。

---

## 🔄 标准事件循环

### 💡 设计理念和实现

标准事件循环遵循经典的主循环设计模式，采用简单直接的串行处理方式：

```python
@DynamicGradMode()
def event_loop_normal(self):
    """A normal scheduler loop."""
    while True:
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        batch = self.get_next_batch_to_run()
        self.cur_batch = batch

        if batch:
            result = self.run_batch(batch)
            self.process_batch_result(batch, result)
        else:
            # When the server is idle, do self-check and re-init some states
            self.self_check_during_idle()

        self.last_batch = batch
```

这个实现清晰地展示了调度器的核心工作流程：请求接收 → 请求处理 → 批次调度 → 模型推理 → 结果处理 → 状态更新。每个步骤都是同步执行，逻辑清晰易于调试。

### 特点

**逻辑清晰**: 串行执行，每个步骤都等待前一步完成
**延迟最低**: 没有额外的同步开销
**稳定可靠**: 适合开发调试和延迟敏感场景

## 重叠事件循环

### CPU-GPU重叠优化

重叠事件循环通过event_loop_overlap方法实现了CPU处理和GPU计算的并行执行：

```python
@DynamicGradMode()
def event_loop_overlap(self):
    """A scheduler loop that overlaps the CPU processing and GPU computation."""
    self.result_queue = deque()

    while True:
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        batch = self.get_next_batch_to_run()
        self.cur_batch = batch

        if batch:
            batch.launch_done = threading.Event()
            result = self.run_batch(batch)
            self.result_queue.append((batch.copy(), result))

            if self.last_batch is None:
                # 创建虚拟首批次来启动重叠调度的流水线
                tmp_batch = ScheduleBatch(
                    reqs=None,
                    forward_mode=ForwardMode.DUMMY_FIRST,
                    next_batch_sampling_info=self.tp_worker.cur_sampling_info,
                )
                self.process_batch_result(tmp_batch, None, batch.launch_done)

        if self.last_batch:
            # 处理上一批次的结果
            tmp_batch, tmp_result = self.result_queue.popleft()
            tmp_batch.next_batch_sampling_info = (
                self.tp_worker.cur_sampling_info if batch else None
            )
            self.process_batch_result(
                tmp_batch, tmp_result, batch.launch_done if batch else None
            )
        elif batch is None:
            self.self_check_during_idle()

        self.last_batch = batch
```

### 重叠机制原理

重叠事件循环的核心思想是将CPU密集的调度工作与GPU密集的推理计算并行进行：

**结果队列管理**: 使用deque来管理批次结果，支持异步的结果处理。

**事件同步**: 通过threading.Event来协调CPU和GPU之间的同步，确保数据一致性。

**流水线启动**: 创建虚拟的首批次来启动流水线，避免冷启动延迟。

**并行处理**: 当GPU执行当前批次时，CPU同时处理上一批次的结果和准备下一批次。

### 特点

**高吞吐量**: 可提升20-40%的吞吐量
**资源并行**: CPU和GPU同时工作，提高资源利用率
**生产首选**: 大多数生产环境的最佳选择

## 流水线并行事件循环

### 多微批次管理

流水线并行事件循环通过event_loop_pp方法支持大模型的分层处理：

```python
@DynamicGradMode()
def event_loop_pp(self):
    """A non-overlap scheduler loop for pipeline parallelism."""
    mbs = [None] * self.pp_size
    last_mbs = [None] * self.pp_size
    self.running_mbs = [
        ScheduleBatch(reqs=[], batch_is_full=False) for _ in range(self.pp_size)
    ]

    while True:
        recv_reqs = self.recv_requests()
        self.process_input_requests(recv_reqs)

        # 为每个流水线阶段准备微批次
        for mbi in range(self.pp_size):
            # 合并上一轮的微批次结果
            if last_mbs[mbi] and last_mbs[mbi].forward_mode.is_extend():
                # 过滤和合并逻辑...
                
            # 获取新的预填充批次
            new_batch = self.get_new_batch_prefill()
            mbs[mbi] = new_batch if new_batch else self.running_mbs[mbi]

        # 执行所有微批次
        if any(mb and not mb.is_empty() for mb in mbs):
            results = self.run_batch_pp(mbs)
            for mbi, (mb, result) in enumerate(zip(mbs, results)):
                if mb and not mb.is_empty():
                    self.process_batch_result(mb, result)
        else:
            self.self_check_during_idle()

        last_mbs = mbs.copy()
```

### 流水线调度策略

流水线并行的关键在于多个微批次的协调执行：

**微批次分配**: 每个流水线阶段维护独立的微批次，避免不同阶段间的资源竞争。

**同步机制**: 通过barrier同步确保各个流水线阶段的执行顺序。

**负载均衡**: 动态调整各个微批次的大小，平衡各阶段的计算负载。

### 特点

**支持超大模型**: 突破单GPU显存限制
**线性扩展**: 理论上可以无限增加模型层数
**专用场景**: 主要用于特大模型的分布式推理

## DynamicGradMode装饰器

@DynamicGradMode()装饰器是所有事件循环的重要优化机制：

```python
@DynamicGradMode()
def event_loop_xxx(self):
    # 根据当前操作自动切换梯度计算模式
    # 推理时关闭梯度节省内存，LoRA训练时开启梯度
```

这种动态切换使得同一个调度器能够同时支持纯推理和带梯度的操作。

## 性能特性对比

### 延迟特性

**标准循环**: 最低延迟，适合实时性要求高的场景
**重叠循环**: 中等延迟，但显著提高吞吐量  
**流水线循环**: 较高的单次延迟，但支持更大的模型

### 吞吐量特性

**标准循环**: 基准吞吐量，受串行处理限制
**重叠循环**: 可提升20-40%的吞吐量，具体取决于CPU/GPU比例
**流水线循环**: 理论上可线性扩展，支持超大模型推理

### 适用场景

**标准循环**: 
- 开发调试环境
- 小规模部署
- 延迟敏感应用

**重叠循环**:
- 生产环境的首选
- 高吞吐量需求
- CPU-GPU均衡的工作负载

**流水线循环**:
- 超大模型推理
- 多GPU集群部署
- 显存受限场景

## 总结

SGLang的三种事件循环设计体现了对不同应用场景的深入理解和精心优化。标准循环提供了稳定可靠的基准实现，重叠循环通过CPU-GPU并行显著提升了性能，流水线循环则支持了超大模型的分布式推理。

每种事件循环都有其适用的场景和优势，通过自动选择机制，SGLang能够根据配置和硬件环境选择最优的执行模式。理解这些事件循环的原理和特性，对于系统部署、性能调优和问题诊断都具有重要意义。

在实际使用中，建议优先选择重叠循环用于生产环境，它在大多数情况下能够提供最佳的性能平衡。对于超大模型或显存受限的场景，流水线循环是唯一可行的选择。而标准循环则主要用于开发调试和特殊的延迟敏感场景。