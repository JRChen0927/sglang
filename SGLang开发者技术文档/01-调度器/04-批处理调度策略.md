# æ‰¹å¤„ç†è°ƒåº¦ç­–ç•¥

---

SGLangè°ƒåº¦å™¨é€šè¿‡æ‰¹å¤„ç†æœºåˆ¶æ¥æé«˜GPUåˆ©ç”¨ç‡å’Œæ¨ç†ååé‡ã€‚æœ¬ç« ä»‹ç»è°ƒåº¦å™¨çš„æ ¸å¿ƒæ‰¹å¤„ç†ç­–ç•¥å’Œå®ç°ã€‚

---

## âš¡ æ ¸å¿ƒæ‰¹å¤„ç†æ–¹æ³•

### ğŸ¯ æ ¸å¿ƒè®¾è®¡æ¦‚å¿µ

```python
def get_next_batch_to_run(self) -> Optional[ScheduleBatch]:
    """æ‰¹å¤„ç†è°ƒåº¦çš„æ ¸å¿ƒæ¦‚å¿µ"""
    # 1. åˆå¹¶ä¸Šä¸€ä¸ªé¢„å¡«å……æ‰¹æ¬¡åˆ°è¿è¡Œæ‰¹æ¬¡
    if self.last_batch and self.last_batch.forward_mode.is_extend():
        if not self.last_batch.is_empty():
            if self.running_batch.is_empty():
                self.running_batch = self.last_batch
            else:
                self.running_batch.merge_batch(self.last_batch)

    # 2. è·å–æ–°çš„é¢„å¡«å……æ‰¹æ¬¡
    new_batch = self.get_new_batch_prefill()
    
    # 3. è¿”å›è¦æ‰§è¡Œçš„æ‰¹æ¬¡
    return new_batch or self.running_batch
```

### ğŸ” æºç å®ç°ç»†èŠ‚

```python
def get_next_batch_to_run(self) -> Optional[ScheduleBatch]:
    """çœŸå®çš„SGLangæ‰¹å¤„ç†è°ƒåº¦å®ç°"""
    # å¤„ç†åˆ†å—è¯·æ±‚çš„åˆå¹¶
    chunked_req_to_exclude = set()
    if self.chunked_req:
        # å°†åˆ†å—è¯·æ±‚ç§»å‡ºæ‰¹æ¬¡ï¼Œä»¥ä¾¿åªå°†å®Œæˆçš„è¯·æ±‚åˆå¹¶åˆ°running_batch
        chunked_req_to_exclude.add(self.chunked_req)
        self.tree_cache.cache_unfinished_req(self.chunked_req)
        # åˆ†å—è¯·æ±‚ä¿æŒridä½†ä¼šè·å¾—æ–°çš„req_pool_idx
        self.req_to_token_pool.free(self.chunked_req.req_pool_idx)
        
    if self.last_batch and self.last_batch.forward_mode.is_extend():
        if self.last_batch.chunked_req is not None:
            # åœ¨pipeline parallelismä¸­ï¼Œéœ€è¦ä¸¢å¼ƒè¿‡æ—¶çš„chunked_req
            chunked_req_to_exclude.add(self.last_batch.chunked_req)

        # è¿‡æ»¤æ‰¹æ¬¡
        last_bs = self.last_batch.batch_size()
        self.last_batch.filter_batch(
            chunked_req_to_exclude=list(chunked_req_to_exclude)
        )
        if self.last_batch.batch_size() < last_bs:
            self.running_batch.batch_is_full = False

        # å°†æ–°æ‰¹æ¬¡åˆå¹¶åˆ°è¿è¡Œæ‰¹æ¬¡ä¸­
        # å¯¹äºä»…é¢„å¡«å……æ‰¹æ¬¡ï¼Œå¯ä»¥é¿å…è§£ç æ­¥éª¤
        if not self.last_batch.is_empty() and not self.last_batch.is_prefill_only:
            if self.running_batch.is_empty():
                self.running_batch = self.last_batch
            else:
                # åˆå¹¶running_batchå’Œprefill batch
                self.running_batch.merge_batch(self.last_batch)

    # è·å–æ–°çš„é¢„å¡«å……æ‰¹æ¬¡
    new_batch = self.get_new_batch_prefill()
    
    # åŠ¨æ€æ‰¹å¤„ç†å†³ç­–
    if new_batch is not None:
        if self.running_batch.is_empty():
            # åªæœ‰é¢„å¡«å……æ‰¹æ¬¡
            return new_batch
        else:
            # æ··åˆé¢„å¡«å……å’Œè§£ç æ‰¹æ¬¡
            new_batch.mix_with_running(self.running_batch)
            return new_batch
    else:
        # åªæœ‰è§£ç æ‰¹æ¬¡æˆ–ç©ºæ‰¹æ¬¡
        return self.running_batch if not self.running_batch.is_empty() else None

ğŸ’¡ **å®ç°è¯´æ˜**: çœŸå®å®ç°åŒ…å«åˆ†å—è¯·æ±‚å¤„ç†ã€æ‰¹æ¬¡è¿‡æ»¤ã€åŠ¨æ€åˆå¹¶ç­‰å¤æ‚é€»è¾‘ã€‚æ•™å­¦ç‰ˆæœ¬çªå‡º"åˆå¹¶â†’è·å–â†’è¿”å›"çš„æ ¸å¿ƒè°ƒåº¦æµç¨‹ã€‚
```

---

### ğŸ”„ get_new_batch_prefill

#### ğŸ¯ æ ¸å¿ƒè®¾è®¡æ¦‚å¿µ

```python
def get_new_batch_prefill(self) -> Optional[ScheduleBatch]:
    """é¢„å¡«å……æ‰¹æ¬¡è·å–çš„æ ¸å¿ƒæ¦‚å¿µ"""
    # 1. æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ›å»ºæ–°æ‰¹æ¬¡
    if self.running_batch.batch_is_full or len(self.waiting_queue) == 0:
        return None
    
    # 2. åˆ›å»ºPrefillAdderæ™ºèƒ½æ·»åŠ è¯·æ±‚
    adder = PrefillAdder(
        self.tree_cache,
        self.token_to_kv_pool_allocator,
        self.running_batch,
        self.max_prefill_tokens,
    )
    
    # 3. ä»ç­‰å¾…é˜Ÿåˆ—ä¸­æ·»åŠ è¯·æ±‚
    for req in self.waiting_queue:
        add_result = adder.add_req(req)
        if add_result != AddReqResult.CONTINUE:
            break
    
    # 4. è¿”å›æ„å»ºçš„æ‰¹æ¬¡
    return adder.get_batch()
```

#### ğŸ” æºç å®ç°ç»†èŠ‚

```python
def get_new_batch_prefill(self) -> Optional[ScheduleBatch]:
    """çœŸå®çš„SGLangé¢„å¡«å……æ‰¹æ¬¡è·å–å®ç°"""
    # æ£€æŸ¥è¯­æ³•é˜Ÿåˆ—ä¸­æ˜¯å¦æœ‰å‡†å¤‡å¥½çš„è¯·æ±‚
    if self.grammar_queue:
        self.move_ready_grammar_requests()

    # å¤„ç†ä¸å…è®¸é¢„å¡«å……çš„æƒ…å†µ
    if (
        self.running_batch.batch_is_full or len(self.waiting_queue) == 0
    ) and self.chunked_req is None:
        return None

    running_bs = len(self.running_batch.reqs)
    
    # æ£€æŸ¥å¯åˆ†é…çš„è¯·æ±‚æ•°é‡
    if self.get_num_allocatable_reqs(running_bs) <= 0 and not self.chunked_req:
        self.running_batch.batch_is_full = True
        return None

    # åˆ†å±‚ç¼“å­˜äº‹ä»¶æ£€æŸ¥
    if self.enable_hierarchical_cache:
        self.tree_cache.check_hicache_events()

    # è®¡ç®—è¯·æ±‚ä¼˜å…ˆçº§
    self.policy.calc_priority(self.waiting_queue)

    # åˆ›å»ºPrefillAdderæ¥å¤„ç†æ–°è¯·æ±‚çš„æ·»åŠ 
    adder = PrefillAdder(
        self.page_size,
        self.tree_cache,
        self.token_to_kv_pool_allocator,
        self.running_batch,
        self.new_token_ratio,
        self.max_prefill_tokens,
        self.chunked_prefill_size,
        running_bs if self.is_mixed_chunk else 0,
    )

    # å¤„ç†åˆ†å—è¯·æ±‚
    if self.chunked_req is not None:
        self.chunked_req.init_next_round_input(self.tree_cache)
        self.chunked_req = adder.add_chunked_req(self.chunked_req)

    # LoRAçº¦æŸå¤„ç†
    if self.enable_lora:
        lora_set = set([req.lora_id for req in self.running_batch.reqs])
    
    # ä»ç­‰å¾…é˜Ÿåˆ—ä¸­æ·»åŠ è¯·æ±‚
    for req in self.waiting_queue:
        # LoRAæ‰¹æ¬¡å¤§å°é™åˆ¶æ£€æŸ¥
        if self.enable_lora and not self.tp_worker.can_run_lora_batch(
            lora_set | set([req.lora_id for req in adder.can_run_list]) | set([req.lora_id])
        ):
            self.running_batch.batch_is_full = True
            break

        # è¯·æ±‚æ•°é‡é™åˆ¶æ£€æŸ¥
        if len(adder.can_run_list) >= self.get_num_allocatable_reqs(running_bs):
            self.running_batch.batch_is_full = True
            break

        # åˆ†ç¦»å¼æ¶æ„å†…å­˜æ£€æŸ¥
        if self.disaggregation_mode == DisaggregationMode.PREFILL:
            if len(adder.can_run_list) >= self.req_to_token_pool.available_size():
                self.running_batch.batch_is_full = True
                break

        # HiCacheå­˜å‚¨é¢„å–æ£€æŸ¥
        if self.enable_hicache_storage:
            prefetch_done = self.tree_cache.check_prefetch_progress(req.rid)
            if not prefetch_done:
                continue

        # åˆå§‹åŒ–è¯·æ±‚çš„ä¸‹ä¸€è½®è¾“å…¥
        req.init_next_round_input(self.tree_cache)
        add_result = adder.add_one_req(req, has_chunked_req=(self.chunked_req is not None))

        if add_result != AddReqResult.CONTINUE:
            if add_result == AddReqResult.NO_TOKEN:
                if self.enable_hierarchical_cache:
                    self.running_batch.batch_is_full = len(adder.can_run_list) > 0 or (
                        not self.running_batch.is_empty()
                    )
                else:
                    self.running_batch.batch_is_full = True
            break
    
    # æ›´æ–°ç­‰å¾…é˜Ÿåˆ—
    can_run_list = adder.can_run_list
    if len(can_run_list) == 0:
        return None
        
    # ä»ç­‰å¾…é˜Ÿåˆ—ä¸­ç§»é™¤å·²æ·»åŠ çš„è¯·æ±‚
    for req in can_run_list:
        if req in self.waiting_queue:
            self.waiting_queue.remove(req)
    
    return adder.get_batch()

ğŸ’¡ **å®ç°è¯´æ˜**: çœŸå®å®ç°åŒ…å«è¯­æ³•é˜Ÿåˆ—ã€LoRAçº¦æŸã€åˆ†å±‚ç¼“å­˜ã€åˆ†ç¦»å¼æ¶æ„ã€HiCacheç­‰å¤æ‚åŠŸèƒ½æ£€æŸ¥ã€‚æ•™å­¦ç‰ˆæœ¬çªå‡º"æ£€æŸ¥â†’æ·»åŠ â†’æ„å»º"çš„æ ¸å¿ƒé¢„å¡«å……æµç¨‹ã€‚
```

---

## ğŸ“¦ ScheduleBatchæ•°æ®ç»“æ„

### ğŸ·ï¸ æ ¸å¿ƒå­—æ®µ

`ScheduleBatch`åŒ…å«æ‰¹å¤„ç†æ‰§è¡Œæ‰€éœ€çš„æ‰€æœ‰ä¿¡æ¯ï¼š

```python
@dataclasses.dataclass
class ScheduleBatch(ScheduleBatchDisaggregationDecodeMixin):
    # è¯·æ±‚ã€å†…å­˜æ± å’Œç¼“å­˜
    reqs: List[Req]
    req_to_token_pool: ReqToTokenPool = None
    token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator = None
    tree_cache: BasePrefixCache = None
    is_hybrid: bool = False

    # æ‰¹æ¬¡é…ç½®
    model_config: ModelConfig = None
    forward_mode: ForwardMode = None
    enable_overlap: bool = False
    batch_is_full: bool = False

    # åˆ†å—é¢„å¡«å……æ”¯æŒ
    chunked_req: Optional[Req] = None

    # æ¨¡å‹è¿è¡Œå™¨çš„æ‰¹å¤„ç†å‚æ•°
    input_ids: torch.Tensor = None          # shape: [b], int64
    input_embeds: torch.Tensor = None       # shape: [b, hidden_size], float32
    req_pool_indices: torch.Tensor = None   # shape: [b], int64
    seq_lens: torch.Tensor = None           # shape: [b], int64
    out_cache_loc: torch.Tensor = None      # shape: [b], int64
    output_ids: torch.Tensor = None         # shape: [b], int64

    # å¤šæ¨¡æ€è¾“å…¥
    multimodal_inputs: Optional[List] = None

    # åºåˆ—é•¿åº¦ä¿¡æ¯
    seq_lens_sum: int = None
    orig_seq_lens: torch.Tensor = None      # shape: [b], int32
```

### åŸºæœ¬æ“ä½œæ–¹æ³•

**æ‰¹æ¬¡çŠ¶æ€æ£€æŸ¥**ï¼š
```python
def is_empty(self):
    return len(self.reqs) == 0

def batch_size(self):
    return len(self.reqs)
```

**å†…å­˜åˆ†é…æ–¹æ³•**ï¼š
```python
def alloc_req_slots(self, num_reqs: int):
    """ä¸ºè¯·æ±‚åˆ†é…æ§½ä½"""
    req_pool_indices = self.req_to_token_pool.alloc(num_reqs)
    if req_pool_indices is None:
        raise RuntimeError(
            "alloc_req_slots runs out of memory. "
            "Please set a smaller number for `--max-running-requests`. "
            f"{self.req_to_token_pool.available_size()=}, "
            f"{num_reqs=}, "
        )
    return req_pool_indices

def alloc_token_slots(self, num_tokens: int, backup_state: bool = False):
    """ä¸ºtokenåˆ†é…KVç¼“å­˜æ§½ä½"""
    self._evict_tree_cache_if_needed(num_tokens)

    if backup_state:
        state = self.token_to_kv_pool_allocator.backup_state()

    out_cache_loc = self.token_to_kv_pool_allocator.alloc(num_tokens)
    if out_cache_loc is None:
        phase_str = "Prefill" if self.forward_mode.is_extend() else "Decode"
        error_msg = (
            f"{phase_str} out of memory. Try to lower your batch size.\n"
            f"Try to allocate {num_tokens} tokens.\n"
            f"{self._available_and_evictable_str()}"
        )
        logger.error(error_msg)
        if self.tree_cache is not None:
            self.tree_cache.pretty_print()
        raise RuntimeError(error_msg)

    if backup_state:
        return out_cache_loc, state
    else:
        return out_cache_loc
```

### æ‰¹æ¬¡åˆå¹¶

**mix_with_running**ï¼š
```python
def mix_with_running(self, running_batch: "ScheduleBatch"):
    """å°†å½“å‰æ‰¹æ¬¡ä¸è¿è¡Œæ‰¹æ¬¡æ··åˆ"""
    self.forward_mode = ForwardMode.MIXED
    running_bs = running_batch.batch_size()

    # ä¸ºè¿è¡Œæ‰¹æ¬¡ä¸­çš„è¯·æ±‚è®¾ç½®è§£ç ä¿¡æ¯
    for req in running_batch.reqs:
        req.fill_ids = req.origin_input_ids + req.output_ids
        req.extend_input_len = 1

    # åˆå¹¶è¾“å…¥tensors
    input_ids = torch.cat([self.input_ids, running_batch.input_ids])
    out_cache_loc = torch.cat([self.out_cache_loc, running_batch.out_cache_loc])

    # åˆå¹¶è¯·æ±‚åˆ—è¡¨
    self.merge_batch(running_batch)
    self.input_ids = input_ids
    self.out_cache_loc = out_cache_loc

    # æ›´æ–°å‰ç¼€å’Œæ‰©å±•é•¿åº¦ä¿¡æ¯
    delta = 0 if self.enable_overlap else -1
    self.prefix_lens.extend([
        len(r.origin_input_ids) + len(r.output_ids) + delta
        for r in running_batch.reqs
    ])
    self.extend_lens.extend([1] * running_bs)
    self.extend_num_tokens += running_bs
    self.extend_logprob_start_lens.extend([0] * running_bs)
```

---

## ğŸ¯ PrefillAdderå¤„ç†ç­–ç•¥

### ğŸ¯ æ ¸å¿ƒè®¾è®¡æ¦‚å¿µ

```python
class PrefillAdder:
    """é¢„å¡«å……æ·»åŠ å™¨çš„æ ¸å¿ƒæ¦‚å¿µ"""
    def __init__(self, tree_cache, token_allocator, running_batch, max_tokens):
        self.tree_cache = tree_cache               # å‰ç¼€ç¼“å­˜
        self.token_allocator = token_allocator     # KVç¼“å­˜åˆ†é…å™¨
        self.running_batch = running_batch         # å½“å‰è¿è¡Œæ‰¹æ¬¡
        self.max_tokens = max_tokens               # æœ€å¤§tokenæ•°
        
        self.can_run_list = []                     # å¯è¿è¡Œè¯·æ±‚åˆ—è¡¨
        
    def add_req(self, req) -> AddReqResult:
        """æ·»åŠ å•ä¸ªè¯·æ±‚çš„æ ¸å¿ƒé€»è¾‘"""
        # 1. æ£€æŸ¥å‰ç¼€ç¼“å­˜å‘½ä¸­
        prefix_len = self.tree_cache.match_prefix(req)
        
        # 2. æ£€æŸ¥tokené¢„ç®—
        if self.check_token_budget(req, prefix_len):
            self.can_run_list.append(req)
            return AddReqResult.CONTINUE
        else:
            return AddReqResult.NO_TOKEN
```

### ğŸ” æºç å®ç°ç»†èŠ‚

```python
class PrefillAdder:
    """çœŸå®çš„SGLang PrefillAdderå®ç°"""
    def __init__(
        self,
        page_size: int,
        tree_cache: BasePrefixCache,
        token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,
        running_batch: ScheduleBatch,
        new_token_ratio: float,
        rem_input_tokens: int,
        rem_chunk_tokens: Optional[int],
        mixed_with_decode_tokens: int = 0,
    ):
        self.page_size = page_size
        self.tree_cache = tree_cache
        self.token_to_kv_pool_allocator = token_to_kv_pool_allocator
        self.running_batch = running_batch
        self.new_token_ratio = new_token_ratio
        self.rem_input_tokens = rem_input_tokens - mixed_with_decode_tokens
        self.rem_chunk_tokens = rem_chunk_tokens
        if self.rem_chunk_tokens is not None:
            self.rem_chunk_tokens -= mixed_with_decode_tokens

        self.rem_total_token_offset = mixed_with_decode_tokens
        self.cur_rem_token_offset = mixed_with_decode_tokens

        self.req_states = None
        self.can_run_list = []
        self.new_chunked_req = None
        self.log_hit_tokens = 0
        self.log_input_tokens = 0

        # è®¡ç®—è§£ç é˜¶æ®µçš„tokenå¼€é”€
        if running_batch is not None:
            self.rem_total_token_offset += sum(
                [
                    min(
                        (r.sampling_params.max_new_tokens - len(r.output_ids)),
                        CLIP_MAX_NEW_TOKENS,
                    )
                    * self.new_token_ratio
                    for r in running_batch.reqs
                ]
            )

        # æ··åˆç¼“å­˜æ£€æŸ¥
        self.is_hybrid = isinstance(
            self.token_to_kv_pool_allocator, SWATokenToKVPoolAllocator
        )

    def add_one_req(self, req: Req, has_chunked_req: bool):
        """æ·»åŠ å•ä¸ªè¯·æ±‚çš„å®Œæ•´å®ç°"""
        req.tree_cache = self.tree_cache
        
        # å‰ç¼€åŒ¹é…å’Œç¼“å­˜å‘½ä¸­æ£€æŸ¥
        prefix_len = len(req.prefix_indices)
        self.log_hit_tokens += prefix_len
        self.log_input_tokens += len(req.fill_ids)

        # è®¡ç®—éœ€è¦çš„input tokens
        input_tokens = len(req.fill_ids) - prefix_len

        # æ£€æŸ¥æ··åˆæ‰¹æ¬¡ä¸­æ˜¯å¦å·²æœ‰chunked request
        if has_chunked_req and len(self.can_run_list) != 0:
            return AddReqResult.OTHER

        # åˆ†å—é¢„å¡«å……é€»è¾‘
        if self.rem_chunk_tokens is None or input_tokens <= self.rem_chunk_tokens:
            # éåˆ†å—é¢„å¡«å……
            self.can_run_list.append(req)
            if self.is_hybrid:
                swa_uuid_for_lock = self.tree_cache.inc_lock_ref(req.last_node)
                req.swa_uuid_for_lock = swa_uuid_for_lock
            else:
                self.tree_cache.inc_lock_ref(req.last_node)
            self._update_prefill_budget(
                prefix_len,
                input_tokens,
                min(req.sampling_params.max_new_tokens, CLIP_MAX_NEW_TOKENS),
            )
        else:
            # åˆ†å—é¢„å¡«å……å¤„ç†
            trunc_len = self.rem_chunk_tokens - self.page_size + 1
            if trunc_len <= 0:
                return AddReqResult.OTHER

            req.extend_input_len = trunc_len
            req.fill_ids = req.fill_ids[: len(req.prefix_indices) + trunc_len]

            self.can_run_list.append(req)
            self.new_chunked_req = req
            if self.is_hybrid:
                swa_uuid_for_lock = self.tree_cache.inc_lock_ref(req.last_node)
                req.swa_uuid_for_lock = swa_uuid_for_lock
            else:
                self.tree_cache.inc_lock_ref(req.last_node)
            self._update_prefill_budget(prefix_len, trunc_len, 0)

        return self.budget_state()

    def budget_state(self):
        """æ£€æŸ¥å½“å‰é¢„ç®—çŠ¶æ€"""
        if self.rem_total_tokens <= 0:
            return AddReqResult.NO_TOKEN
        else:
            return AddReqResult.CONTINUE

ğŸ’¡ **å®ç°è¯´æ˜**: çœŸå®çš„PrefillAdderåŒ…å«å¤æ‚çš„tokené¢„ç®—ç®¡ç†ã€åˆ†å—é¢„å¡«å……ã€æ··åˆç¼“å­˜ã€SWAé”å®šç­‰åŠŸèƒ½ã€‚æ•™å­¦ç‰ˆæœ¬çªå‡º"å‰ç¼€åŒ¹é…â†’é¢„ç®—æ£€æŸ¥â†’æ·»åŠ è¯·æ±‚"çš„æ ¸å¿ƒæµç¨‹ã€‚
```

### ğŸ”¢ æ·»åŠ ç»“æœæšä¸¾

```python
class AddReqResult(Enum):
    CONTINUE = auto()    # ç»§ç»­æ·»åŠ æ›´å¤šè¯·æ±‚
    NO_TOKEN = auto()    # æ²¡æœ‰å‰©ä½™tokené¢„ç®—
    OTHER = auto()       # å…¶ä»–åœæ­¢åŸå› ï¼ˆå¦‚LoRAé™åˆ¶ã€åˆ†å—å†²çªç­‰ï¼‰
```

## è§£ç é˜¶æ®µå†…å­˜é¢„ä¼°

### ä¸‹ä¸€æ¬¡è§£ç çš„é¡µé¢éœ€æ±‚

```python
def new_page_count_next_decode(self):
    """ä¼°ç®—ä¸‹ä¸€æ¬¡è§£ç éœ€è¦çš„æ–°é¡µé¢æ•°é‡"""
    page_size = self.token_to_kv_pool_allocator.page_size
    if page_size == 1:
        return len(self.reqs)
    
    # åœ¨è§£ç é˜¶æ®µï¼Œè¯·æ±‚çš„KVç¼“å­˜é•¿åº¦åº”è¯¥æ˜¯æ€»é•¿åº¦å‡1
    return (
        sum(1 for req in self.reqs if req.seqlen % page_size == 0)
        if self.enable_overlap
        else sum(1 for req in self.reqs if (req.seqlen - 1) % page_size == 0)
    )
```

### è§£ç å†…å­˜æ£€æŸ¥

```python
def check_decode_mem(self, buf_multiplier=1):
    """æ£€æŸ¥è§£ç é˜¶æ®µçš„å†…å­˜éœ€æ±‚"""
    num_tokens = self.new_page_count_next_decode()
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿå†…å­˜è¿›è¡Œä¸‹ä¸€æ¬¡è§£ç 
    available_tokens = self.token_to_kv_pool_allocator.available_size()
    return num_tokens * buf_multiplier <= available_tokens
```

## åˆ†å—é¢„å¡«å……å¤„ç†

### åˆ†å‰²é¢„å¡«å……å‡†å¤‡

```python
def prepare_for_split_prefill(self):
    """ä¸ºåˆ†å‰²é¢„å¡«å……è®¾ç½®å‰å‘æ¨¡å¼"""
    self.forward_mode = ForwardMode.SPLIT_PREFILL
```

å½“è¾“å…¥åºåˆ—è¿‡é•¿æ— æ³•ä¸€æ¬¡å¤„ç†æ—¶ï¼Œè°ƒåº¦å™¨ä¼šå°†å…¶åˆ†æˆå¤šä¸ªchunkè¿›è¡Œå¤„ç†ï¼Œæ¯ä¸ªchunkç‹¬ç«‹æ‰§è¡Œå‰å‘ä¼ æ’­ã€‚

---

## ğŸ“ æ€»ç»“

SGLangçš„æ‰¹å¤„ç†è°ƒåº¦ç­–ç•¥ä½“ç°äº†ç°ä»£æ¨ç†ç³»ç»Ÿçš„æ ¸å¿ƒè®¾è®¡ç†å¿µï¼š

### ğŸ¯ æ ¸å¿ƒè®¾è®¡åŸåˆ™

**åŠ¨æ€æ‰¹å¤„ç†**: é€šè¿‡`get_next_batch_to_run`å®ç°é¢„å¡«å……å’Œè§£ç æ‰¹æ¬¡çš„æ™ºèƒ½åˆå¹¶ï¼Œæœ€å¤§åŒ–GPUåˆ©ç”¨ç‡ã€‚

**æ™ºèƒ½è¯·æ±‚æ·»åŠ **: `PrefillAdder`åŸºäºå‰ç¼€ç¼“å­˜å‘½ä¸­ã€tokené¢„ç®—ã€LoRAçº¦æŸç­‰å¤šç»´åº¦å› ç´ æ™ºèƒ½é€‰æ‹©è¯·æ±‚ã€‚

**å†…å­˜ç²¾ç»†ç®¡ç†**: é€šè¿‡`alloc_req_slots`å’Œ`alloc_token_slots`å®ç°ç»†ç²’åº¦çš„å†…å­˜åˆ†é…å’Œå›æ”¶ã€‚

**åˆ†å—å¤„ç†æ”¯æŒ**: æ”¯æŒè¶…é•¿åºåˆ—çš„åˆ†å—é¢„å¡«å……ï¼Œçªç ´å•æ¬¡å¤„ç†çš„é•¿åº¦é™åˆ¶ã€‚

### ğŸ”§ å®ç°ç‰¹è‰²

**æºç å‡†ç¡®æ€§**: æœ¬æ–‡æ¡£åŸºäºçœŸå®SGLangæºç ç¼–å†™ï¼Œæ‰€æœ‰æ‰¹å¤„ç†é€»è¾‘éƒ½æ¥è‡ªå®é™…å®ç°ï¼Œç¡®ä¿æŠ€æœ¯å‡†ç¡®æ€§ã€‚

**æ•™å­¦ä¸å®è·µå¹¶é‡**: é‡‡ç”¨"æ ¸å¿ƒè®¾è®¡æ¦‚å¿µ + æºç å®ç°ç»†èŠ‚"çš„åŒé‡ç»“æ„ï¼Œæ—¢ä¾¿äºç†è§£æ‰¹å¤„ç†åŸç†ï¼Œåˆæä¾›å®ç°å‚è€ƒã€‚

**å¤æ‚æ€§é€æ˜**: æ˜ç¡®å±•ç¤ºäº†æ•™å­¦ç®€åŒ–ç‰ˆæœ¬ä¸çœŸå®æºç çš„å·®å¼‚ï¼Œè®©å¼€å‘è€…äº†è§£å®é™…æ‰¹å¤„ç†çš„å¤æ‚æ€§ã€‚

### ğŸ“ˆ å…³é”®ä¼˜åŒ–ç­–ç•¥

1. **æ‰¹æ¬¡åˆå¹¶æœºåˆ¶**: é€šè¿‡åŠ¨æ€åˆå¹¶é¢„å¡«å……å’Œè§£ç æ‰¹æ¬¡ï¼Œå®ç°è¿ç»­æ‰¹å¤„ç†
2. **å‰ç¼€ç¼“å­˜ä¼˜åŒ–**: åˆ©ç”¨RadixCacheç­‰ç¼“å­˜æœºåˆ¶å‡å°‘é‡å¤è®¡ç®—
3. **LoRAçº¦æŸç®¡ç†**: åœ¨æ‰¹æ¬¡æ„å»ºæ—¶è€ƒè™‘LoRAé€‚é…å™¨çš„æ•°é‡é™åˆ¶
4. **åˆ†å±‚ç¼“å­˜é›†æˆ**: ä¸HiCacheç­‰åˆ†å±‚ç¼“å­˜ç³»ç»Ÿæ·±åº¦é›†æˆ
5. **åˆ†ç¦»å¼æ¶æ„æ”¯æŒ**: ä¸ºé¢„å¡«å……/è§£ç åˆ†ç¦»æä¾›ä¸“é—¨çš„æ‰¹å¤„ç†ç­–ç•¥
6. **å†…å­˜é¢„ç®—æ§åˆ¶**: åŸºäºtokené¢„ç®—å’Œnew_token_ratioè¿›è¡Œç²¾ç¡®çš„å†…å­˜ç®¡ç†

è¿™äº›æœºåˆ¶ç¡®ä¿äº†SGLangèƒ½å¤Ÿåœ¨å„ç§è´Ÿè½½æ¡ä»¶ä¸‹å®ç°é«˜æ•ˆçš„æ‰¹å¤„ç†æ‰§è¡Œå’Œå†…å­˜åˆ©ç”¨ï¼Œä¸ºå¤§è§„æ¨¡æ¨ç†éƒ¨ç½²æä¾›äº†åšå®çš„è°ƒåº¦åŸºç¡€ã€‚