# æ‰¹å¤„ç†è°ƒåº¦ç­–ç•¥

---

SGLangè°ƒåº¦å™¨é€šè¿‡æ‰¹å¤„ç†æœºåˆ¶æ¥æé«˜GPUåˆ©ç”¨ç‡å’Œæ¨ç†ååé‡ã€‚æœ¬ç« ä»‹ç»è°ƒåº¦å™¨çš„æ ¸å¿ƒæ‰¹å¤„ç†ç­–ç•¥å’Œå®ç°ã€‚

---

## âš¡ æ ¸å¿ƒæ‰¹å¤„ç†æ–¹æ³•

### ğŸ¯ get_next_batch_to_run

è°ƒåº¦å™¨çš„ä¸»è¦æ‰¹å¤„ç†æ–¹æ³•ï¼Œè´Ÿè´£å‡†å¤‡ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„æ‰¹æ¬¡ï¼š

```python
def get_next_batch_to_run(self) -> Optional[ScheduleBatch]:
    # å¤„ç†åˆ†å—è¯·æ±‚çš„åˆå¹¶
    chunked_req_to_exclude = set()
    if self.chunked_req:
        # å°†åˆ†å—è¯·æ±‚ç§»å‡ºæ‰¹æ¬¡ï¼Œä»¥ä¾¿åªå°†å®Œæˆçš„è¯·æ±‚åˆå¹¶åˆ°running_batch
        chunked_req_to_exclude.add(self.chunked_req)
        self.tree_cache.cache_unfinished_req(self.chunked_req)
        # åˆ†å—è¯·æ±‚ä¿æŒridä½†ä¼šè·å¾—æ–°çš„req_pool_idx
        self.req_to_token_pool.free(self.chunked_req.req_pool_idx)
        
    if self.last_batch and self.last_batch.forward_mode.is_extend():
        if self.last_batch.chunked_req is not None:
            # åœ¨pipeline parallelismä¸­ï¼Œéœ€è¦ä¸¢å¼ƒè¿‡æ—¶çš„chunked_req
            chunked_req_to_exclude.add(self.last_batch.chunked_req)

        # è¿‡æ»¤æ‰¹æ¬¡
        last_bs = self.last_batch.batch_size()
        self.last_batch.filter_batch(
            chunked_req_to_exclude=list(chunked_req_to_exclude)
        )
        if self.last_batch.batch_size() < last_bs:
            self.running_batch.batch_is_full = False

        # å°†æ–°æ‰¹æ¬¡åˆå¹¶åˆ°è¿è¡Œæ‰¹æ¬¡ä¸­
        # å¯¹äºä»…é¢„å¡«å……æ‰¹æ¬¡ï¼Œå¯ä»¥é¿å…è§£ç æ­¥éª¤
        if not self.last_batch.is_empty() and not self.last_batch.is_prefill_only:
            if self.running_batch.is_empty():
                self.running_batch = self.last_batch
            else:
                # åˆå¹¶running_batchå’Œprefill batch
                self.running_batch.merge_batch(self.last_batch)

    # è·å–æ–°çš„é¢„å¡«å……æ‰¹æ¬¡
    new_batch = self.get_new_batch_prefill()
    
    # è¿”å›å¤„ç†åçš„æ‰¹æ¬¡...
```

### ğŸ”„ get_new_batch_prefill

è·å–æ–°çš„é¢„å¡«å……æ‰¹æ¬¡çš„æ ¸å¿ƒé€»è¾‘ï¼ˆå®é™…å®ç°ç”±PrefillAdderå¤„ç†ï¼‰ï¼š

```python
def get_new_batch_prefill(self) -> Optional[ScheduleBatch]:
    # é¦–å…ˆæ£€æŸ¥è¯­æ³•é˜Ÿåˆ—ä¸­æ˜¯å¦æœ‰å‡†å¤‡å¥½çš„è¯·æ±‚
    if self.grammar_queue:
        self.move_ready_grammar_requests()

    # å¤„ç†ä¸å…è®¸é¢„å¡«å……çš„æƒ…å†µ
    if (
        self.running_batch.batch_is_full or len(self.waiting_queue) == 0
    ) and self.chunked_req is None:
        return None

    running_bs = len(self.running_batch.reqs)
    
    # æ£€æŸ¥å¯åˆ†é…çš„è¯·æ±‚æ•°é‡
    if self.get_num_allocatable_reqs(running_bs) <= 0 and not self.chunked_req:
        self.running_batch.batch_is_full = True
        return None

    if self.enable_hierarchical_cache:
        self.tree_cache.check_hicache_events()

    # è·å–ä¼˜å…ˆçº§é˜Ÿåˆ—
    self.policy.calc_priority(self.waiting_queue)

    # åˆ›å»ºPrefillAdderæ¥å¤„ç†æ–°è¯·æ±‚çš„æ·»åŠ 
    adder = PrefillAdder(
        self.page_size,
        self.tree_cache,
        self.token_to_kv_pool_allocator,
        self.running_batch,
        self.new_token_ratio,
        self.max_prefill_tokens,
        self.chunked_prefill_size,
        running_bs if self.is_mixed_chunk else 0,
    )

    # å¤„ç†åˆ†å—è¯·æ±‚
    if self.chunked_req is not None:
        self.chunked_req.init_next_round_input()
        self.chunked_req = adder.add_chunked_req(self.chunked_req)

    # å¤„ç†LoRAçº¦æŸ
    if self.enable_lora:
        lora_set = set([req.lora_id for req in self.running_batch.reqs])
    
    # ä»ç­‰å¾…é˜Ÿåˆ—ä¸­æ·»åŠ è¯·æ±‚
    for req in self.waiting_queue:
        # LoRAæ‰¹æ¬¡å¤§å°é™åˆ¶
        if self.enable_lora:
            if req.lora_id not in lora_set:
                if len(lora_set) >= self.max_loras_per_batch:
                    break
                lora_set.add(req.lora_id)
        
        add_result = adder.add_req(req)
        if add_result != AddReqResult.CONTINUE:
            break
    
    return adder.get_batch()
```

---

## ğŸ“¦ ScheduleBatchæ•°æ®ç»“æ„

### ğŸ·ï¸ æ ¸å¿ƒå­—æ®µ

`ScheduleBatch`åŒ…å«æ‰¹å¤„ç†æ‰§è¡Œæ‰€éœ€çš„æ‰€æœ‰ä¿¡æ¯ï¼š

```python
@dataclasses.dataclass
class ScheduleBatch(ScheduleBatchDisaggregationDecodeMixin):
    # è¯·æ±‚ã€å†…å­˜æ± å’Œç¼“å­˜
    reqs: List[Req]
    req_to_token_pool: ReqToTokenPool = None
    token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator = None
    tree_cache: BasePrefixCache = None
    is_hybrid: bool = False

    # æ‰¹æ¬¡é…ç½®
    model_config: ModelConfig = None
    forward_mode: ForwardMode = None
    enable_overlap: bool = False
    batch_is_full: bool = False

    # åˆ†å—é¢„å¡«å……æ”¯æŒ
    chunked_req: Optional[Req] = None

    # æ¨¡å‹è¿è¡Œå™¨çš„æ‰¹å¤„ç†å‚æ•°
    input_ids: torch.Tensor = None          # shape: [b], int64
    input_embeds: torch.Tensor = None       # shape: [b, hidden_size], float32
    req_pool_indices: torch.Tensor = None   # shape: [b], int64
    seq_lens: torch.Tensor = None           # shape: [b], int64
    out_cache_loc: torch.Tensor = None      # shape: [b], int64
    output_ids: torch.Tensor = None         # shape: [b], int64

    # å¤šæ¨¡æ€è¾“å…¥
    multimodal_inputs: Optional[List] = None

    # åºåˆ—é•¿åº¦ä¿¡æ¯
    seq_lens_sum: int = None
    orig_seq_lens: torch.Tensor = None      # shape: [b], int32
```

### åŸºæœ¬æ“ä½œæ–¹æ³•

**æ‰¹æ¬¡çŠ¶æ€æ£€æŸ¥**ï¼š
```python
def is_empty(self):
    return len(self.reqs) == 0

def batch_size(self):
    return len(self.reqs)
```

**å†…å­˜åˆ†é…æ–¹æ³•**ï¼š
```python
def alloc_req_slots(self, num_reqs: int):
    """ä¸ºè¯·æ±‚åˆ†é…æ§½ä½"""
    req_pool_indices = self.req_to_token_pool.alloc(num_reqs)
    if req_pool_indices is None:
        raise RuntimeError(
            "alloc_req_slots runs out of memory. "
            "Please set a smaller number for `--max-running-requests`. "
            f"{self.req_to_token_pool.available_size()=}, "
            f"{num_reqs=}, "
        )
    return req_pool_indices

def alloc_token_slots(self, num_tokens: int, backup_state: bool = False):
    """ä¸ºtokenåˆ†é…KVç¼“å­˜æ§½ä½"""
    self._evict_tree_cache_if_needed(num_tokens)

    if backup_state:
        state = self.token_to_kv_pool_allocator.backup_state()

    out_cache_loc = self.token_to_kv_pool_allocator.alloc(num_tokens)
    if out_cache_loc is None:
        phase_str = "Prefill" if self.forward_mode.is_extend() else "Decode"
        error_msg = (
            f"{phase_str} out of memory. Try to lower your batch size.\n"
            f"Try to allocate {num_tokens} tokens.\n"
            f"{self._available_and_evictable_str()}"
        )
        logger.error(error_msg)
        if self.tree_cache is not None:
            self.tree_cache.pretty_print()
        raise RuntimeError(error_msg)

    if backup_state:
        return out_cache_loc, state
    else:
        return out_cache_loc
```

### æ‰¹æ¬¡åˆå¹¶

**mix_with_running**ï¼š
```python
def mix_with_running(self, running_batch: "ScheduleBatch"):
    """å°†å½“å‰æ‰¹æ¬¡ä¸è¿è¡Œæ‰¹æ¬¡æ··åˆ"""
    self.forward_mode = ForwardMode.MIXED
    running_bs = running_batch.batch_size()

    # ä¸ºè¿è¡Œæ‰¹æ¬¡ä¸­çš„è¯·æ±‚è®¾ç½®è§£ç ä¿¡æ¯
    for req in running_batch.reqs:
        req.fill_ids = req.origin_input_ids + req.output_ids
        req.extend_input_len = 1

    # åˆå¹¶è¾“å…¥tensors
    input_ids = torch.cat([self.input_ids, running_batch.input_ids])
    out_cache_loc = torch.cat([self.out_cache_loc, running_batch.out_cache_loc])

    # åˆå¹¶è¯·æ±‚åˆ—è¡¨
    self.merge_batch(running_batch)
    self.input_ids = input_ids
    self.out_cache_loc = out_cache_loc

    # æ›´æ–°å‰ç¼€å’Œæ‰©å±•é•¿åº¦ä¿¡æ¯
    delta = 0 if self.enable_overlap else -1
    self.prefix_lens.extend([
        len(r.origin_input_ids) + len(r.output_ids) + delta
        for r in running_batch.reqs
    ])
    self.extend_lens.extend([1] * running_bs)
    self.extend_num_tokens += running_bs
    self.extend_logprob_start_lens.extend([0] * running_bs)
```

## PrefillAdderå¤„ç†ç­–ç•¥

### è¯·æ±‚æ·»åŠ é€»è¾‘

PrefillAdderè´Ÿè´£å°†ç­‰å¾…é˜Ÿåˆ—ä¸­çš„è¯·æ±‚æ·»åŠ åˆ°æ–°æ‰¹æ¬¡ä¸­ï¼š

```python
class PrefillAdder:
    def __init__(self, page_size: int, tree_cache: BasePrefixCache,
                 token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,
                 running_batch: ScheduleBatch, new_token_ratio: float,
                 rem_input_tokens: int, rem_chunk_tokens: Optional[int],
                 mixed_with_decode_tokens: int = 0):
        self.page_size = page_size
        self.tree_cache = tree_cache
        self.token_to_kv_pool_allocator = token_to_kv_pool_allocator
        self.running_batch = running_batch
        self.new_token_ratio = new_token_ratio
        self.rem_input_tokens = rem_input_tokens - mixed_with_decode_tokens
        self.rem_chunk_tokens = rem_chunk_tokens
        
        self.can_run_list = []
        self.new_chunked_req = None
        self.log_hit_tokens = 0
        self.log_input_tokens = 0
```

### æ·»åŠ ç»“æœæšä¸¾

```python
class AddReqResult(Enum):
    CONTINUE = auto()    # ç»§ç»­æ·»åŠ æ›´å¤šè¯·æ±‚
    NO_TOKEN = auto()    # æ²¡æœ‰å‰©ä½™token
    OTHER = auto()       # å…¶ä»–åœæ­¢åŸå› 
```

## è§£ç é˜¶æ®µå†…å­˜é¢„ä¼°

### ä¸‹ä¸€æ¬¡è§£ç çš„é¡µé¢éœ€æ±‚

```python
def new_page_count_next_decode(self):
    """ä¼°ç®—ä¸‹ä¸€æ¬¡è§£ç éœ€è¦çš„æ–°é¡µé¢æ•°é‡"""
    page_size = self.token_to_kv_pool_allocator.page_size
    if page_size == 1:
        return len(self.reqs)
    
    # åœ¨è§£ç é˜¶æ®µï¼Œè¯·æ±‚çš„KVç¼“å­˜é•¿åº¦åº”è¯¥æ˜¯æ€»é•¿åº¦å‡1
    return (
        sum(1 for req in self.reqs if req.seqlen % page_size == 0)
        if self.enable_overlap
        else sum(1 for req in self.reqs if (req.seqlen - 1) % page_size == 0)
    )
```

### è§£ç å†…å­˜æ£€æŸ¥

```python
def check_decode_mem(self, buf_multiplier=1):
    """æ£€æŸ¥è§£ç é˜¶æ®µçš„å†…å­˜éœ€æ±‚"""
    num_tokens = self.new_page_count_next_decode()
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿå†…å­˜è¿›è¡Œä¸‹ä¸€æ¬¡è§£ç 
    available_tokens = self.token_to_kv_pool_allocator.available_size()
    return num_tokens * buf_multiplier <= available_tokens
```

## åˆ†å—é¢„å¡«å……å¤„ç†

### åˆ†å‰²é¢„å¡«å……å‡†å¤‡

```python
def prepare_for_split_prefill(self):
    """ä¸ºåˆ†å‰²é¢„å¡«å……è®¾ç½®å‰å‘æ¨¡å¼"""
    self.forward_mode = ForwardMode.SPLIT_PREFILL
```

å½“è¾“å…¥åºåˆ—è¿‡é•¿æ— æ³•ä¸€æ¬¡å¤„ç†æ—¶ï¼Œè°ƒåº¦å™¨ä¼šå°†å…¶åˆ†æˆå¤šä¸ªchunkè¿›è¡Œå¤„ç†ï¼Œæ¯ä¸ªchunkç‹¬ç«‹æ‰§è¡Œå‰å‘ä¼ æ’­ã€‚

## æ€»ç»“

SGLangçš„æ‰¹å¤„ç†è°ƒåº¦ç­–ç•¥åŒ…æ‹¬ï¼š

1. **æ‰¹æ¬¡åˆå¹¶æœºåˆ¶**: é€šè¿‡`get_next_batch_to_run`åˆå¹¶é¢„å¡«å……å’Œè§£ç æ‰¹æ¬¡
2. **å†…å­˜ç®¡ç†**: é€šè¿‡`alloc_req_slots`å’Œ`alloc_token_slots`ç®¡ç†å†…å­˜åˆ†é…
3. **è¯·æ±‚æ·»åŠ ç­–ç•¥**: ä½¿ç”¨`PrefillAdder`æ™ºèƒ½æ·»åŠ æ–°è¯·æ±‚åˆ°æ‰¹æ¬¡
4. **åˆ†å—å¤„ç†**: æ”¯æŒè¶…é•¿åºåˆ—çš„åˆ†å—é¢„å¡«å……
5. **å†…å­˜é¢„ä¼°**: æå‰æ£€æŸ¥ä¸‹ä¸€æ­¥è§£ç çš„å†…å­˜éœ€æ±‚

è¿™äº›æœºåˆ¶ç¡®ä¿äº†é«˜æ•ˆçš„æ‰¹å¤„ç†æ‰§è¡Œå’Œå†…å­˜åˆ©ç”¨ã€‚