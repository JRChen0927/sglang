# 批处理调度策略

---

SGLang调度器通过智能的批处理机制来最大化GPU利用率和推理吞吐量。本章深入介绍调度器的核心批处理策略、连续批处理实现和动态调度算法，揭示SGLang如何实现高效的混合预填充-解码批处理。

---

## 1. 批处理架构总览

SGLang的批处理调度系统是其高性能推理的核心引擎，它通过智能的批次管理和动态调度算法，实现了预填充和解码阶段的高效协调。这个系统不仅要处理单一类型的批次，还要支持混合批次、分块预填充、连续批处理等复杂场景。

**批处理系统的核心挑战**：
- **异构请求管理**：不同长度、不同阶段的请求需要统一的批处理框架
- **内存效率优化**：在有限的GPU内存中最大化批次大小和处理效率
- **动态负载平衡**：根据系统状态动态调整批次组成和执行策略
- **多模式协调**：协调预填充、解码、混合等多种前向模式的执行

**调度策略的设计原则**：
- **连续批处理**：通过last_batch和running_batch的协调，实现无缝的连续处理
- **智能合并机制**：动态决定是否合并预填充和解码批次，优化GPU利用率
- **分块处理支持**：对超长序列提供分块预填充支持，突破单次处理的长度限制
- **前缀缓存集成**：与RadixCache等前缀缓存系统深度集成，减少重复计算

**状态管理的复杂性**：
批处理调度需要管理多个批次状态（last_batch、running_batch、chunked_req），每个状态都有其特定的生命周期和转换规则。这种设计确保了系统能够在复杂的调度场景下保持状态一致性。

### 1.1 批处理调度时序图

```mermaid
sequenceDiagram
    participant S as Scheduler
    participant LB as last_batch
    participant RB as running_batch
    participant PA as PrefillAdder
    participant TC as TreeCache
    participant WQ as waiting_queue

    Note over S: get_next_batch_to_run() 开始
    
    S->>S: 处理chunked_req排除逻辑
    alt 存在chunked_req
        S->>TC: cache_unfinished_req(chunked_req)
        S->>S: req_to_token_pool.free()
    end
    
    alt last_batch存在且为EXTEND模式
        S->>LB: filter_batch(chunked_req_to_exclude)
        LB-->>S: 过滤后的批次大小
        alt 批次大小减少
            S->>RB: batch_is_full = False
        end
        alt 非空且非仅预填充
            alt running_batch为空
                S->>S: running_batch = last_batch
            else
                S->>RB: merge_batch(last_batch)
            end
        end
    end
    
    S->>S: get_new_batch_prefill()
    Note over S: 获取新预填充批次
    
    S->>S: 检查grammar_queue
    S->>S: 验证预填充条件
    S->>S: 计算优先级
    S->>PA: 创建PrefillAdder
    
    loop 遍历waiting_queue
        S->>PA: add_one_req(req)
        PA->>TC: 前缀缓存匹配
        PA->>PA: token预算检查
        alt 预算充足
            PA-->>S: AddReqResult.CONTINUE
        else
            PA-->>S: AddReqResult.NO_TOKEN/OTHER
            break
        end
    end
    
    S->>S: 创建ScheduleBatch.init_new()
    
    alt new_batch存在
        alt running_batch为空
            S-->>S: return new_batch
        else
            S->>S: new_batch.mix_with_running(running_batch)
            S-->>S: return mixed_batch
        end
    else
        S-->>S: return running_batch或None
    end
```

### 1.2 批次状态机图

```mermaid
stateDiagram-v2
    [*] --> Empty: 系统启动
    
    Empty --> PrefillOnly: 获取预填充批次
    PrefillOnly --> Mixed: 合并解码请求
    PrefillOnly --> DecodeOnly: 预填充完成
    
    DecodeOnly --> Mixed: 获取新预填充批次
    DecodeOnly --> Empty: 所有请求完成
    
    Mixed --> DecodeOnly: 预填充部分完成
    Mixed --> Mixed: 持续混合处理
    Mixed --> Empty: 所有请求完成
    
    state PrefillOnly {
        [*] --> Extending
        Extending --> ChunkedPrefill: 序列过长
        ChunkedPrefill --> Extending: 分块完成
        Extending --> [*]: 预填充完成
    }
    
    state DecodeOnly {
        [*] --> Decoding
        Decoding --> [*]: 生成完成
    }
    
    state Mixed {
        [*] --> MixedForward
        MixedForward --> [*]: 混合处理完成
    }

    note right of PrefillOnly: EXTEND/SPLIT_PREFILL模式
    note right of DecodeOnly: DECODE模式  
    note right of Mixed: MIXED模式
```

### 1.3 内存分配映射图

```mermaid
graph TD
    subgraph "🔍 逻辑视图"
        R1["Req1<br/>seq_len=100"]
        R2["Req2<br/>seq_len=200"] 
        R3["Req3<br/>seq_len=150"]
    end

    subgraph "📊 内存池映射"
        RTT["ReqToTokenPool<br/>请求→Token映射"]
        TKV["TokenToKVPool<br/>Token→KV映射"]
    end

    subgraph "💾 物理内存"
        direction TB
        P1["Page0<br/>KV Cache"]
        P2["Page1<br/>KV Cache"]
        P3["Page2<br/>KV Cache"]
        P4["Page3<br/>KV Cache"]
        P5["Page4<br/>KV Cache"]
        P6["..."]
    end

    R1 --> RTT
    R2 --> RTT  
    R3 --> RTT
    RTT --> TKV
    
    TKV --> P1
    TKV --> P2
    TKV --> P3
    TKV --> P4
    TKV --> P5

    style R1 fill:#e3f2fd,color:#000000,stroke:#333
    style R2 fill:#f1f8e9,color:#000000,stroke:#333
    style R3 fill:#fff3e0,color:#000000,stroke:#333
    style RTT fill:#ffebee,color:#000000,stroke:#333
    style TKV fill:#f3e5f5,color:#000000,stroke:#333
    style P1 fill:#e8f5e8,color:#000000,stroke:#333
    style P2 fill:#e8f5e8,color:#000000,stroke:#333
    style P3 fill:#e8f5e8,color:#000000,stroke:#333
    style P4 fill:#e8f5e8,color:#000000,stroke:#333
    style P5 fill:#e8f5e8,color:#000000,stroke:#333
```

**图示说明**：
- **时序图**：展示了get_next_batch_to_run的完整执行流程和组件交互
- **状态机图**：描述了批次状态的转换逻辑和前向模式的切换
- **内存映射图**：展示了请求到物理内存的多层映射关系

---

## 2. 核心批处理方法

### 2.1 get_next_batch_to_run核心实现

get_next_batch_to_run方法是SGLang批处理调度的核心引擎，它负责协调多个批次状态的转换和合并。这个方法需要处理复杂的批次生命周期管理，包括分块请求的特殊处理、上一批次的合并、新预填充批次的获取等多个环节。

**批次调度的核心职责**：
- **分块请求管理**：处理超长序列的分块预填充，确保分块请求的正确状态转换
- **批次状态协调**：管理last_batch到running_batch的转换，实现连续批处理
- **动态合并决策**：根据系统状态决定是否合并预填充和解码批次
- **投机解码兼容**：处理投机解码与数据并行注意力的兼容性问题

**状态转换的复杂性**：
- **分块请求排除**：需要将完成的分块请求从批次中移除，同时缓存未完成的部分
- **批次过滤机制**：过滤掉需要排除的请求，更新批次的满载状态
- **内存池管理**：及时释放分块请求占用的内存池槽位，为新请求腾出空间

**合并策略优化**：
系统会根据批次类型智能决定合并策略。对于仅预填充批次（is_prefill_only），可以跳过解码阶段直接处理；对于混合批次，需要考虑预填充和解码的协调执行。

```python
def get_next_batch_to_run(self) -> Optional[ScheduleBatch]:
    # Merge the prefill batch into the running batch
    chunked_req_to_exclude = set()
    if self.chunked_req:
        # Move the chunked request out of the batch so that we can merge
        # only finished requests to running_batch.
        chunked_req_to_exclude.add(self.chunked_req)
        self.tree_cache.cache_unfinished_req(self.chunked_req)
        # chunked request keeps its rid but will get a new req_pool_idx
        self.req_to_token_pool.free(self.chunked_req.req_pool_idx)
        
    if self.last_batch and self.last_batch.forward_mode.is_extend():
        if self.last_batch.chunked_req is not None:
            # In the context pipeline parallelism, after the last chunk, the current microbatch still track outdated chunked_req.
            # We need to discard it.
            chunked_req_to_exclude.add(self.last_batch.chunked_req)

        # Filter batch
        last_bs = self.last_batch.batch_size()
        self.last_batch.filter_batch(
            chunked_req_to_exclude=list(chunked_req_to_exclude)
        )
        if self.last_batch.batch_size() < last_bs:
            self.running_batch.batch_is_full = False

        # Merge the new batch into the running batch.
        # For prefill-only batch, we can avoid going through decoding step.
        if not self.last_batch.is_empty() and not self.last_batch.is_prefill_only:
            if self.running_batch.is_empty():
                self.running_batch = self.last_batch
            else:
                # Merge running_batch with prefill batch
                self.running_batch.merge_batch(self.last_batch)

    new_batch = self.get_new_batch_prefill()
    
    need_dp_attn_preparation = require_mlp_sync(self.server_args)
    
    if need_dp_attn_preparation and not self.spec_algorithm.is_none():
        if new_batch is not None:
            new_batch.spec_algorithm = SpeculativeAlgorithm.NONE
        if not self.running_batch.is_empty():
            self.running_batch.spec_algorithm = SpeculativeAlgorithm.NONE

    # Return the next batch to run
    if new_batch is not None:
        if self.running_batch.is_empty():
            return new_batch
        else:
            new_batch.mix_with_running(self.running_batch)
            return new_batch
    else:
        return self.running_batch if not self.running_batch.is_empty() else None
```

### 2.2 get_new_batch_prefill实现

get_new_batch_prefill方法是预填充批次构建的核心组件，它从等待队列中智能选择请求并构建新的预填充批次。这个方法需要考虑多种约束条件，包括内存限制、LoRA约束、语法队列状态、分层缓存等复杂因素。

**预填充批次构建的核心流程**：
- **语法队列检查**：优先处理语法队列中已准备好的请求
- **容量预检查**：检查运行批次是否已满，避免不必要的处理开销
- **资源可用性验证**：确保有足够的内存和请求槽位来构建新批次
- **优先级计算**：通过调度策略计算请求的处理优先级

**约束条件的多维度检查**：
- **LoRA批次限制**：检查LoRA适配器的数量是否超过批次限制
- **内存资源限制**：验证可分配的请求数量和token数量
- **分离式架构限制**：在分离式模式下检查特定的资源约束
- **分层缓存状态**：检查HiCache的预取进度和可用性

**PrefillAdder集成**：
方法通过PrefillAdder实现智能的请求添加，该组件负责token预算管理、前缀缓存优化、分块处理等核心功能。PrefillAdder的设计确保了批次构建过程的高效性和准确性。

### 2.2 预填充批次构建流程

预填充批次的构建是一个复杂的决策过程，涉及多层约束检查和优化策略。以下是核心流程的精简实现：

```python
def get_new_batch_prefill(self) -> Optional[ScheduleBatch]:
    # 1. 语法队列优先处理
    if self.grammar_queue:
        self.move_ready_grammar_requests()

    # 2. 预填充条件检查
    if (self.running_batch.batch_is_full or len(self.waiting_queue) == 0) and self.chunked_req is None:
        return None

    # 3. 创建PrefillAdder进行智能请求选择
    adder = PrefillAdder(
        self.page_size,                    # 分页大小
        self.tree_cache,                   # 前缀缓存
        self.token_to_kv_pool_allocator,   # KV缓存分配器
        self.running_batch,                # 当前运行批次
        self.new_token_ratio,              # 新token比率
        self.max_prefill_tokens,           # 最大预填充token数
        self.chunked_prefill_size,         # 分块预填充大小
        running_bs if self.is_mixed_chunk else 0,  # 混合模式下的解码token数
    )

    # 4. 处理分块请求（如果存在）
    if self.chunked_req is not None:
        self.chunked_req.init_next_round_input()
        self.chunked_req = adder.add_chunked_req(self.chunked_req)

    # 5. 遍历等待队列，应用多维度约束
    for req in self.waiting_queue:
        # LoRA约束检查
        if self.enable_lora and not self.tp_worker.can_run_lora_batch(...):
            self.running_batch.batch_is_full = True
            break

        # 请求数量限制检查
        if len(adder.can_run_list) >= self.get_num_allocatable_reqs(running_bs):
            self.running_batch.batch_is_full = True
            break

        # 添加请求到批次
        req.init_next_round_input(self.tree_cache)
        res = adder.add_one_req(req, has_chunked_req=(self.chunked_req is not None))
        
        if res != AddReqResult.CONTINUE:
            break

    # 6. 构建并返回新批次
    if len(adder.can_run_list) == 0:
        return None
        
    new_batch = ScheduleBatch.init_new(
        adder.can_run_list,              # 选中的请求列表
        self.req_to_token_pool,          # 内存池引用
        self.token_to_kv_pool_allocator, # KV缓存分配器
        self.tree_cache,                 # 前缀缓存
        # ... 其他配置参数
    )
    
    new_batch.prepare_for_extend()  # 准备预填充执行
    return new_batch
```

---

## 3. PrefillAdder智能添加策略

PrefillAdder是SGLang批处理系统的核心组件，它负责从等待队列中智能选择请求并构建预填充批次。这个组件需要在多种约束条件下进行优化决策，包括token预算管理、前缀缓存利用、分块处理支持等复杂功能。

**智能添加的核心算法**：
- **token预算管理**：基于new_token_ratio和max_prefill_tokens进行精确的资源预算
- **前缀缓存优化**：利用RadixCache等缓存机制减少重复计算开销
- **分块处理支持**：对超长序列提供分块预填充，突破单次处理限制
- **混合批次协调**：在混合模式下协调预填充和解码请求的资源分配

**约束条件的综合考量**：
- **内存资源约束**：确保token分配不超过GPU内存限制
- **LoRA适配器约束**：控制批次中LoRA适配器的数量
- **分离式架构约束**：在分离式模式下考虑特殊的内存管理需求
- **混合缓存约束**：在SWA等混合缓存模式下的特殊处理

### 3.1 调度决策算法

PrefillAdder的核心是基于多维度约束的智能决策算法，它需要在token预算、内存限制、LoRA约束、缓存状态等多个因素间找到最优平衡。

**决策算法的核心逻辑**：

```mermaid
graph TD
    subgraph "🎯 决策流程"
        A1["新请求进入"]
        A2["前缀缓存匹配<br/>tree_cache.match_prefix()"]
        A3["计算token需求<br/>input_tokens = len(fill_ids) - prefix_len"]
        A4{"token预算检查<br/>rem_total_tokens > 0?"}
        A5{"分块决策<br/>input_tokens > rem_chunk_tokens?"}
        A6["添加到can_run_list"]
        A7["创建分块请求<br/>new_chunked_req"]
        A8["更新token预算<br/>_update_prefill_budget()"]
        A9["返回AddReqResult"]
    end

    A1 --> A2
    A2 --> A3
    A3 --> A4
    A4 -->|是| A5
    A4 -->|否| A9
    A5 -->|否| A6
    A5 -->|是| A7
    A6 --> A8
    A7 --> A8
    A8 --> A9

    style A1 fill:#e3f2fd,color:#000000,stroke:#333
    style A4 fill:#fff3e0,color:#000000,stroke:#333
    style A5 fill:#fff3e0,color:#000000,stroke:#333
    style A9 fill:#ffebee,color:#000000,stroke:#333
```

**new_token_ratio的预算计算机制**：
new_token_ratio用于预估未来解码阶段的token消耗，确保预填充批次不会导致后续解码阶段的内存不足。计算公式为：

```
解码预算 = Σ(min(max_new_tokens - len(output_ids), CLIP_MAX_NEW_TOKENS) * new_token_ratio)
可用预算 = max_prefill_tokens - 解码预算 - 当前运行批次开销
```

### 3.2 前缀缓存集成机制

前缀缓存是SGLang性能优化的核心，PrefillAdder与TreeCache的集成实现了智能的缓存利用：

```python
# 前缀缓存匹配与统计
def add_one_req(self, req: Req, has_chunked_req: bool):
    # 初始化下一轮输入，触发前缀匹配
    req.init_next_round_input(self.tree_cache)
    
    # 统计缓存命中情况
    prefix_len = len(req.prefix_indices)       # 缓存命中的token数
    self.log_hit_tokens += prefix_len          # 累计命中统计
    self.log_input_tokens += len(req.fill_ids) # 累计输入统计
    
    # 计算实际需要处理的token数
    input_tokens = req.extend_input_len        # 扩展长度（去除前缀后的长度）
```

**缓存命中率优化**：
系统通过统计log_hit_tokens和log_input_tokens来监控前缀缓存的效果，缓存命中率 = log_hit_tokens / log_input_tokens。高缓存命中率意味着更少的重复计算。

### 3.3 分块预填充实现原理

当输入序列超过rem_chunk_tokens限制时，SGLang会启动分块预填充机制：

```python
# 分块预填充的核心决策逻辑
if self.rem_chunk_tokens is None or input_tokens <= self.rem_chunk_tokens:
    # 非分块路径：正常添加请求
    self.can_run_list.append(req)
    self._update_prefill_budget(prefix_len, input_tokens, max_new_tokens)
else:
    # 分块路径：截断序列并标记为分块请求
    trunc_len = self.rem_chunk_tokens - self.page_size + 1
    if trunc_len <= 0:
        return AddReqResult.OTHER  # 无法分块，拒绝请求
        
    req.extend_input_len = trunc_len  # 设置截断长度
    req.fill_ids = req.fill_ids[: len(req.prefix_indices) + trunc_len]  # 截断输入
    
    self.can_run_list.append(req)
    self.new_chunked_req = req  # 标记为新的分块请求
    self._update_prefill_budget(prefix_len, trunc_len, 0)  # 分块请求无解码预算
```

**分块请求的生命周期管理**：

```mermaid
graph LR
    subgraph "🔄 分块请求生命周期"
        A["长序列请求<br/>input_len > chunk_size"]
        B["创建分块请求<br/>new_chunked_req"]
        C["第一块处理<br/>chunk 1"]
        D["缓存未完成部分<br/>cache_unfinished_req()"]
        E["继续处理<br/>chunk 2"]
        F["完成处理<br/>chunked_req = None"]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F

    style A fill:#e3f2fd,color:#000000,stroke:#333
    style B fill:#f1f8e9,color:#000000,stroke:#333
    style C fill:#fff3e0,color:#000000,stroke:#333
    style D fill:#ffebee,color:#000000,stroke:#333
    style E fill:#f3e5f5,color:#000000,stroke:#333
    style F fill:#e8f5e8,color:#000000,stroke:#333
```

```python
class PrefillAdder:
    def __init__(
        self,
        page_size: int,
        tree_cache: BasePrefixCache,
        token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,
        running_batch: ScheduleBatch,
        new_token_ratio: float,
        rem_input_tokens: int,
        rem_chunk_tokens: Optional[int],
        mixed_with_decode_tokens: int = 0,
    ):
        self.page_size = page_size
        self.tree_cache = tree_cache
        self.token_to_kv_pool_allocator = token_to_kv_pool_allocator
        self.running_batch = running_batch
        self.new_token_ratio = new_token_ratio
        self.rem_input_tokens = rem_input_tokens - mixed_with_decode_tokens
        self.rem_chunk_tokens = rem_chunk_tokens
        if self.rem_chunk_tokens is not None:
            self.rem_chunk_tokens -= mixed_with_decode_tokens

        self.rem_total_token_offset = mixed_with_decode_tokens
        self.cur_rem_token_offset = mixed_with_decode_tokens

        self.req_states = None
        self.can_run_list = []
        self.new_chunked_req = None
        self.log_hit_tokens = 0
        self.log_input_tokens = 0

        # 计算解码阶段的token预算开销
        if running_batch is not None:
            self.rem_total_token_offset += sum(
                [
                    min(
                        (r.sampling_params.max_new_tokens - len(r.output_ids)),
                        CLIP_MAX_NEW_TOKENS,
                    )
                    * self.new_token_ratio
                    for r in running_batch.reqs
                ]
            )

        # 检查是否为混合缓存模式
        self.is_hybrid = isinstance(
            self.token_to_kv_pool_allocator, SWATokenToKVPoolAllocator
        )
```

### 3.2 add_one_req核心方法

add_one_req方法是PrefillAdder的核心，它实现了单个请求的智能添加逻辑。这个方法需要处理前缀缓存匹配、token预算计算、分块处理决策等复杂逻辑。

### 3.4 核心数据结构

PrefillAdder的核心字段设计体现了其复杂的预算管理和状态跟踪需求：

```python
class PrefillAdder:
    def __init__(self, ...):
        # 核心配置
        self.page_size = page_size                    # KV缓存分页大小
        self.tree_cache = tree_cache                  # 前缀缓存引用
        self.new_token_ratio = new_token_ratio        # 解码token预估比率
        
        # token预算管理
        self.rem_input_tokens = rem_input_tokens      # 剩余输入token预算
        self.rem_chunk_tokens = rem_chunk_tokens      # 分块token限制
        
        # 状态跟踪
        self.can_run_list = []                        # 可运行请求列表
        self.new_chunked_req = None                   # 新创建的分块请求
        self.log_hit_tokens = 0                       # 前缀缓存命中统计
        self.log_input_tokens = 0                     # 总输入token统计
        
        # 混合缓存支持
        self.is_hybrid = isinstance(
            self.token_to_kv_pool_allocator, SWATokenToKVPoolAllocator
        )
```

### 3.5 添加结果枚举

```python
class AddReqResult(Enum):
    CONTINUE = auto()    # 继续添加更多请求
    NO_TOKEN = auto()    # 没有剩余token预算
    OTHER = auto()       # 其他停止原因（如LoRA限制、分块冲突等）
```

---

## 4. 批次操作与内存管理

### 4.1 批次合并机制

批次合并是SGLang连续批处理的核心机制，它通过mix_with_running方法实现预填充批次与解码批次的智能合并。这个过程需要协调不同前向模式的请求，确保GPU计算的高效执行。

**合并过程的核心步骤**：
- **前向模式设置**：将批次模式设置为MIXED，支持预填充和解码的混合执行
- **解码信息准备**：为运行批次中的请求设置解码所需的fill_ids和extend_input_len
- **张量数据合并**：合并input_ids、out_cache_loc等关键张量数据
- **长度信息更新**：更新prefix_lens、extend_lens等长度统计信息

```python
def mix_with_running(self, running_batch: "ScheduleBatch"):
    self.forward_mode = ForwardMode.MIXED
    running_bs = running_batch.batch_size()

    for req in running_batch.reqs:
        req.fill_ids = req.origin_input_ids + req.output_ids
        req.extend_input_len = 1

    input_ids = torch.cat([self.input_ids, running_batch.input_ids])
    out_cache_loc = torch.cat([self.out_cache_loc, running_batch.out_cache_loc])

    self.merge_batch(running_batch)
    self.input_ids = input_ids
    self.out_cache_loc = out_cache_loc

    # For overlap scheduler, the output_ids has one step delay
    delta = 0 if self.enable_overlap else -1

    # NOTE: prefix_indices is what has been cached, but we don't cache each decode step
    self.prefix_lens.extend(
        [
            len(r.origin_input_ids) + len(r.output_ids) + delta
            for r in running_batch.reqs
        ]
    )
    self.extend_lens.extend([1] * running_bs)
    self.extend_num_tokens += running_bs
    # TODO (lianmin): Revisit this. It should be seq_len - 1
    self.extend_logprob_start_lens.extend([0] * running_bs)
```

### 4.2 解码阶段内存管理

解码阶段的内存管理需要精确计算每个请求的KV缓存需求，特别是在分页KV缓存模式下，需要准确预估新页面的分配需求。

**分页KV缓存的内存预估**：
在分页KV缓存系统中，每个请求的KV缓存被分割成固定大小的页面。解码阶段需要为每个请求分配新的页面来存储新生成token的KV状态。

**页面分配的计算逻辑**：
- 当请求的序列长度达到页面边界时（seqlen % page_size == 0），需要分配新页面
- 重叠调度模式下，使用当前序列长度；非重叠模式下，使用序列长度减1
- 页面大小为1时，每个请求每次解码都需要新页面

```python
def new_page_count_next_decode(self):
    page_size = self.token_to_kv_pool_allocator.page_size
    if page_size == 1:
        return len(self.reqs)  # 每个请求都需要新页面
    
    # 计算需要新页面的请求数量
    return (
        sum(1 for req in self.reqs if req.seqlen % page_size == 0)
        if self.enable_overlap
        else sum(1 for req in self.reqs if (req.seqlen - 1) % page_size == 0)
    )

def check_decode_mem(self, buf_multiplier=1):
    num_tokens = self.new_page_count_next_decode()  # 预估需要的页面数
    available_tokens = self.token_to_kv_pool_allocator.available_size()  # 可用页面数
    return num_tokens * buf_multiplier <= available_tokens  # 内存充足性检查
```

**内存预估的准确性**：
准确的内存预估对于避免OOM错误至关重要。系统通过buf_multiplier参数提供安全缓冲，确保在内存紧张时仍能稳定运行。

### 4.3 分块预填充处理

分块预填充是SGLang处理超长序列的关键机制，当输入序列超过单次处理能力时，系统会将其分割成多个chunk进行处理。

```python
def prepare_for_split_prefill(self):
    # For split prefill, we need to set the forward mode to SPLIT_PREFILL
    self.forward_mode = ForwardMode.SPLIT_PREFILL
```

## 5. 高级调度策略

### 5.1 连续批处理的流水线设计

SGLang的连续批处理采用了三级流水线设计，通过last_batch、running_batch、new_batch的协调，实现了GPU计算资源的最大化利用。

**流水线调度的核心原理**：

```mermaid
graph LR
    subgraph "🔄 批次流水线"
        A["last_batch<br/>上轮预填充结果"]
        B["running_batch<br/>当前解码批次"]  
        C["new_batch<br/>新预填充批次"]
        D["next_batch<br/>下轮批次"]
    end

    A -->|merge_batch()| B
    B -->|mix_with_running()| C
    C -->|forward执行| D
    D -->|状态流转| A

    style A fill:#e3f2fd,color:#000000,stroke:#333
    style B fill:#f1f8e9,color:#000000,stroke:#333
    style C fill:#fff3e0,color:#000000,stroke:#333
    style D fill:#ffebee,color:#000000,stroke:#333
```

**动态合并决策算法**：
系统根据批次状态动态决定执行模式，实现最优的GPU利用率：

```python
# 动态批次合并的决策逻辑
if new_batch is not None:
    if self.running_batch.is_empty():
        return new_batch                    # 纯预填充模式（EXTEND）
    else:
        new_batch.mix_with_running(self.running_batch)  # 混合模式（MIXED）
        return new_batch
else:
    return self.running_batch if not self.running_batch.is_empty() else None  # 纯解码模式（DECODE）
```

### 5.2 多维度约束优化

SGLang的批处理调度需要同时满足多个维度的约束条件，形成了复杂的多目标优化问题：

**约束优先级层次**：
1. **硬约束**：内存限制、请求数量限制（必须满足）
2. **软约束**：LoRA数量、分块冲突（影响性能但不影响正确性）
3. **优化目标**：前缀缓存命中率、批次大小最大化

**LoRA适配器约束管理**：
```python
# LoRA批次兼容性检查
if self.enable_lora and not self.tp_worker.can_run_lora_batch(
    lora_set | set([req.lora_id for req in adder.can_run_list]) | set([req.lora_id])
):
    self.running_batch.batch_is_full = True  # 达到LoRA限制，停止添加
    break
```

**分层缓存的预取协调**：
```python
# HiCache预取状态检查
if self.enable_hicache_storage:
    prefetch_done = self.tree_cache.check_prefetch_progress(req.rid)
    if not prefetch_done:
        continue  # 跳过预取未完成的请求，避免阻塞
```

### 5.3 性能监控与调优

SGLang提供了完整的性能监控机制，帮助开发者理解和优化批处理性能：

**关键性能指标**：
- **前缀缓存命中率**：log_hit_tokens / log_input_tokens
- **批次利用率**：实际批次大小 / 最大批次大小  
- **内存利用率**：已用token数 / 总可用token数
- **吞吐量指标**：处理的token数 / 时间

```python
# 性能统计的核心实现
def log_prefill_stats(self, adder: PrefillAdder, can_run_list: List[Req], running_bs: int):
    # 计算输入吞吐量
    gap_latency = time.perf_counter() - self.last_prefill_stats_tic
    self.last_input_throughput = self.last_prefill_tokens / gap_latency
    
    # 统计批次信息
    num_new_seq = len(can_run_list)           # 新序列数量
    new_tokens = adder.log_input_tokens       # 新token数量
    cached_tokens = adder.log_hit_tokens      # 缓存命中token数量
    
    logger.info(f"Prefill batch. #new-seq: {num_new_seq}, "
                f"#new-token: {new_tokens}, #cached-token: {cached_tokens}")
```

---

## 6. 架构总结与技术价值

### 6.1 批处理调度的核心贡献

SGLang的批处理调度系统在现代大语言模型推理领域做出了重要的技术贡献，其设计理念和实现方法为推理系统的发展提供了有价值的参考。

**技术创新要点**：
- **连续批处理架构**：三级流水线设计实现了GPU资源的最大化利用
- **智能请求调度**：多维度约束下的优化请求选择算法
- **分块预填充机制**：突破单次处理长度限制的创新解决方案
- **前缀缓存集成**：深度集成的缓存优化，显著减少重复计算

### 6.2 工程实现的复杂性

批处理调度系统的实现体现了生产级推理系统的工程复杂性：

**状态管理的精细化**：
```python
# 复杂的状态转换管理
chunked_req_to_exclude = set()              # 需要排除的分块请求
if self.chunked_req:
    chunked_req_to_exclude.add(self.chunked_req)
    self.tree_cache.cache_unfinished_req(self.chunked_req)  # 缓存未完成部分
    self.req_to_token_pool.free(self.chunked_req.req_pool_idx)  # 释放内存槽位
```

**多模式协调的复杂性**：
系统需要在EXTEND、DECODE、MIXED、SPLIT_PREFILL四种前向模式间进行智能切换，每种模式都有其特定的执行路径和优化策略。

**资源约束的全面考量**：
从基础的内存限制到高级的LoRA约束，从分离式架构的特殊需求到分层缓存的预取协调，系统需要综合考虑所有约束条件。

### 6.3 性能优化的系统性方法

SGLang的批处理调度采用了系统性的性能优化方法：

**计算效率优化**：
- 前缀缓存减少重复计算
- 批次合并最大化GPU利用率
- 分块处理突破长度限制

**内存效率优化**：
- 精确的token预算管理
- 分页KV缓存的高效分配
- 智能的内存回收机制

**调度效率优化**：
- 优先级驱动的请求选择
- 多维度约束的快速检查
- 动态的批次组合决策

**承上启下**：在前面章节中我们了解了调度器的架构、数据结构和请求处理机制，本章深入剖析了批处理调度的核心算法。接下来我们将探讨内存管理系统，了解SGLang如何实现高效的KV缓存管理和前缀缓存优化。