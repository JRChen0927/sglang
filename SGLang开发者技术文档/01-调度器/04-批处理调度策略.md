# 批处理调度策略

---

SGLang调度器通过智能的批处理机制来最大化GPU利用率和推理吞吐量。本章深入介绍调度器的核心批处理策略、连续批处理实现和动态调度算法，揭示SGLang如何实现高效的混合预填充-解码批处理。

---

## 1. 批处理架构总览

SGLang的批处理调度系统是其高性能推理的核心引擎，它通过智能的批次管理和动态调度算法，实现了预填充和解码阶段的高效协调。这个系统不仅要处理单一类型的批次，还要支持混合批次、分块预填充、连续批处理等复杂场景。

**批处理系统的核心挑战**：
- **异构请求管理**：不同长度、不同阶段的请求需要统一的批处理框架
- **内存效率优化**：在有限的GPU内存中最大化批次大小和处理效率
- **动态负载平衡**：根据系统状态动态调整批次组成和执行策略
- **多模式协调**：协调预填充、解码、混合等多种前向模式的执行

**调度策略的设计原则**：
- **连续批处理**：通过last_batch和running_batch的协调，实现无缝的连续处理
- **智能合并机制**：动态决定是否合并预填充和解码批次，优化GPU利用率
- **分块处理支持**：对超长序列提供分块预填充支持，突破单次处理的长度限制
- **前缀缓存集成**：与RadixCache等前缀缓存系统深度集成，减少重复计算

**状态管理的复杂性**：
批处理调度需要管理多个批次状态（last_batch、running_batch、chunked_req），每个状态都有其特定的生命周期和转换规则。这种设计确保了系统能够在复杂的调度场景下保持状态一致性。

### 1.1 批处理调度时序图

```mermaid
sequenceDiagram
    participant S as Scheduler
    participant LB as last_batch
    participant RB as running_batch
    participant PA as PrefillAdder
    participant TC as TreeCache
    participant WQ as waiting_queue

    Note over S: get_next_batch_to_run() 开始
    
    S->>S: 处理chunked_req排除逻辑
    alt 存在chunked_req
        S->>TC: cache_unfinished_req(chunked_req)
        S->>S: req_to_token_pool.free()
    end
    
    alt last_batch存在且为EXTEND模式
        S->>LB: filter_batch(chunked_req_to_exclude)
        LB-->>S: 过滤后的批次大小
        alt 批次大小减少
            S->>RB: batch_is_full = False
        end
        alt 非空且非仅预填充
            alt running_batch为空
                S->>S: running_batch = last_batch
            else
                S->>RB: merge_batch(last_batch)
            end
        end
    end
    
    S->>S: get_new_batch_prefill()
    Note over S: 获取新预填充批次
    
    S->>S: 检查grammar_queue
    S->>S: 验证预填充条件
    S->>S: 计算优先级
    S->>PA: 创建PrefillAdder
    
    loop 遍历waiting_queue
        S->>PA: add_one_req(req)
        PA->>TC: 前缀缓存匹配
        PA->>PA: token预算检查
        alt 预算充足
            PA-->>S: AddReqResult.CONTINUE
        else
            PA-->>S: AddReqResult.NO_TOKEN/OTHER
            break
        end
    end
    
    S->>S: 创建ScheduleBatch.init_new()
    
    alt new_batch存在
        alt running_batch为空
            S-->>S: return new_batch
        else
            S->>S: new_batch.mix_with_running(running_batch)
            S-->>S: return mixed_batch
        end
    else
        S-->>S: return running_batch或None
    end
```

### 1.2 批次状态机图

```mermaid
stateDiagram-v2
    [*] --> Empty: 系统启动
    
    Empty --> PrefillOnly: 获取预填充批次
    PrefillOnly --> Mixed: 合并解码请求
    PrefillOnly --> DecodeOnly: 预填充完成
    
    DecodeOnly --> Mixed: 获取新预填充批次
    DecodeOnly --> Empty: 所有请求完成
    
    Mixed --> DecodeOnly: 预填充部分完成
    Mixed --> Mixed: 持续混合处理
    Mixed --> Empty: 所有请求完成
    
    state PrefillOnly {
        [*] --> Extending
        Extending --> ChunkedPrefill: 序列过长
        ChunkedPrefill --> Extending: 分块完成
        Extending --> [*]: 预填充完成
    }
    
    state DecodeOnly {
        [*] --> Decoding
        Decoding --> [*]: 生成完成
    }
    
    state Mixed {
        [*] --> MixedForward
        MixedForward --> [*]: 混合处理完成
    }

    note right of PrefillOnly: EXTEND/SPLIT_PREFILL模式
    note right of DecodeOnly: DECODE模式  
    note right of Mixed: MIXED模式
```

### 1.3 内存分配映射图

```mermaid
graph TD
    subgraph "🔍 逻辑视图"
        R1["Req1<br/>seq_len=100"]
        R2["Req2<br/>seq_len=200"] 
        R3["Req3<br/>seq_len=150"]
    end

    subgraph "📊 内存池映射"
        RTT["ReqToTokenPool<br/>请求→Token映射"]
        TKV["TokenToKVPool<br/>Token→KV映射"]
    end

    subgraph "💾 物理内存"
        direction TB
        P1["Page0<br/>KV Cache"]
        P2["Page1<br/>KV Cache"]
        P3["Page2<br/>KV Cache"]
        P4["Page3<br/>KV Cache"]
        P5["Page4<br/>KV Cache"]
        P6["..."]
    end

    R1 --> RTT
    R2 --> RTT  
    R3 --> RTT
    RTT --> TKV
    
    TKV --> P1
    TKV --> P2
    TKV --> P3
    TKV --> P4
    TKV --> P5

    style R1 fill:#e3f2fd,color:#000000,stroke:#333
    style R2 fill:#f1f8e9,color:#000000,stroke:#333
    style R3 fill:#fff3e0,color:#000000,stroke:#333
    style RTT fill:#ffebee,color:#000000,stroke:#333
    style TKV fill:#f3e5f5,color:#000000,stroke:#333
    style P1 fill:#e8f5e8,color:#000000,stroke:#333
    style P2 fill:#e8f5e8,color:#000000,stroke:#333
    style P3 fill:#e8f5e8,color:#000000,stroke:#333
    style P4 fill:#e8f5e8,color:#000000,stroke:#333
    style P5 fill:#e8f5e8,color:#000000,stroke:#333
```

**图示说明**：
- **时序图**：展示了get_next_batch_to_run的完整执行流程和组件交互
- **状态机图**：描述了批次状态的转换逻辑和前向模式的切换
- **内存映射图**：展示了请求到物理内存的多层映射关系

---

## 2. 核心批处理方法

### 2.1 get_next_batch_to_run核心实现

get_next_batch_to_run方法是SGLang批处理调度的核心引擎，它负责协调多个批次状态的转换和合并。这个方法需要处理复杂的批次生命周期管理，包括分块请求的特殊处理、上一批次的合并、新预填充批次的获取等多个环节。

**批次调度的核心职责**：
- **分块请求管理**：处理超长序列的分块预填充，确保分块请求的正确状态转换
- **批次状态协调**：管理last_batch到running_batch的转换，实现连续批处理
- **动态合并决策**：根据系统状态决定是否合并预填充和解码批次
- **投机解码兼容**：处理投机解码与数据并行注意力的兼容性问题

**状态转换的复杂性**：
- **分块请求排除**：需要将完成的分块请求从批次中移除，同时缓存未完成的部分
- **批次过滤机制**：过滤掉需要排除的请求，更新批次的满载状态
- **内存池管理**：及时释放分块请求占用的内存池槽位，为新请求腾出空间

**合并策略优化**：
系统会根据批次类型智能决定合并策略。对于仅预填充批次（is_prefill_only），可以跳过解码阶段直接处理；对于混合批次，需要考虑预填充和解码的协调执行。

```python
def get_next_batch_to_run(self) -> Optional[ScheduleBatch]:
    # Merge the prefill batch into the running batch
    chunked_req_to_exclude = set()
    if self.chunked_req:
        # Move the chunked request out of the batch so that we can merge
        # only finished requests to running_batch.
        chunked_req_to_exclude.add(self.chunked_req)
        self.tree_cache.cache_unfinished_req(self.chunked_req)
        # chunked request keeps its rid but will get a new req_pool_idx
        self.req_to_token_pool.free(self.chunked_req.req_pool_idx)
        
    if self.last_batch and self.last_batch.forward_mode.is_extend():
        if self.last_batch.chunked_req is not None:
            # In the context pipeline parallelism, after the last chunk, the current microbatch still track outdated chunked_req.
            # We need to discard it.
            chunked_req_to_exclude.add(self.last_batch.chunked_req)

        # Filter batch
        last_bs = self.last_batch.batch_size()
        self.last_batch.filter_batch(
            chunked_req_to_exclude=list(chunked_req_to_exclude)
        )
        if self.last_batch.batch_size() < last_bs:
            self.running_batch.batch_is_full = False

        # Merge the new batch into the running batch.
        # For prefill-only batch, we can avoid going through decoding step.
        if not self.last_batch.is_empty() and not self.last_batch.is_prefill_only:
            if self.running_batch.is_empty():
                self.running_batch = self.last_batch
            else:
                # Merge running_batch with prefill batch
                self.running_batch.merge_batch(self.last_batch)

    new_batch = self.get_new_batch_prefill()
    
    need_dp_attn_preparation = require_mlp_sync(self.server_args)
    
    if need_dp_attn_preparation and not self.spec_algorithm.is_none():
        if new_batch is not None:
            new_batch.spec_algorithm = SpeculativeAlgorithm.NONE
        if not self.running_batch.is_empty():
            self.running_batch.spec_algorithm = SpeculativeAlgorithm.NONE

    # Return the next batch to run
    if new_batch is not None:
        if self.running_batch.is_empty():
            return new_batch
        else:
            new_batch.mix_with_running(self.running_batch)
            return new_batch
    else:
        return self.running_batch if not self.running_batch.is_empty() else None
```

### 2.2 get_new_batch_prefill实现

get_new_batch_prefill方法是预填充批次构建的核心组件，它从等待队列中智能选择请求并构建新的预填充批次。这个方法需要考虑多种约束条件，包括内存限制、LoRA约束、语法队列状态、分层缓存等复杂因素。

**预填充批次构建的核心流程**：
- **语法队列检查**：优先处理语法队列中已准备好的请求
- **容量预检查**：检查运行批次是否已满，避免不必要的处理开销
- **资源可用性验证**：确保有足够的内存和请求槽位来构建新批次
- **优先级计算**：通过调度策略计算请求的处理优先级

**约束条件的多维度检查**：
- **LoRA批次限制**：检查LoRA适配器的数量是否超过批次限制
- **内存资源限制**：验证可分配的请求数量和token数量
- **分离式架构限制**：在分离式模式下检查特定的资源约束
- **分层缓存状态**：检查HiCache的预取进度和可用性

**PrefillAdder集成**：
方法通过PrefillAdder实现智能的请求添加，该组件负责token预算管理、前缀缓存优化、分块处理等核心功能。PrefillAdder的设计确保了批次构建过程的高效性和准确性。

以下是核心流程的精简实现：

```python
def get_new_batch_prefill(self) -> Optional[ScheduleBatch]:
    # 1. 语法队列优先处理
    if self.grammar_queue:
        self.move_ready_grammar_requests()

    # 2. 预填充条件检查
    if (self.running_batch.batch_is_full or len(self.waiting_queue) == 0) and self.chunked_req is None:
        return None

    # 3. 创建PrefillAdder进行智能请求选择
    adder = PrefillAdder(
        self.page_size,                    # 分页大小
        self.tree_cache,                   # 前缀缓存
        self.token_to_kv_pool_allocator,   # KV缓存分配器
        self.running_batch,                # 当前运行批次
        self.new_token_ratio,              # 新token比率
        self.max_prefill_tokens,           # 最大预填充token数
        self.chunked_prefill_size,         # 分块预填充大小
        running_bs if self.is_mixed_chunk else 0,  # 混合模式下的解码token数
    )

    # 4. 处理分块请求（如果存在）
    if self.chunked_req is not None:
        self.chunked_req.init_next_round_input()
        self.chunked_req = adder.add_chunked_req(self.chunked_req)

    # 5. 遍历等待队列，应用多维度约束
    for req in self.waiting_queue:
        # LoRA约束检查
        if self.enable_lora and not self.tp_worker.can_run_lora_batch(...):
            self.running_batch.batch_is_full = True
            break

        # 请求数量限制检查
        if len(adder.can_run_list) >= self.get_num_allocatable_reqs(running_bs):
            self.running_batch.batch_is_full = True
            break

        # 添加请求到批次
        req.init_next_round_input(self.tree_cache)
        res = adder.add_one_req(req, has_chunked_req=(self.chunked_req is not None))
        
        if res != AddReqResult.CONTINUE:
            break

    # 6. 构建并返回新批次
    if len(adder.can_run_list) == 0:
        return None
        
    new_batch = ScheduleBatch.init_new(
        adder.can_run_list,              # 选中的请求列表
        self.req_to_token_pool,          # 内存池引用
        self.token_to_kv_pool_allocator, # KV缓存分配器
        self.tree_cache,                 # 前缀缓存
        # ... 其他配置参数
    )
    
    new_batch.prepare_for_extend()  # 准备预填充执行
    return new_batch
```

---

## 3. PrefillAdder智能添加策略

PrefillAdder是SGLang批处理系统的核心组件，它负责从等待队列中智能选择请求并构建预填充批次。这个组件需要在多种约束条件下进行优化决策，包括token预算管理、前缀缓存利用、分块处理支持等复杂功能。

**智能添加的核心算法**：
- **token预算管理**：基于new_token_ratio和max_prefill_tokens进行精确的资源预算
- **前缀缓存优化**：利用RadixCache等缓存机制减少重复计算开销
- **分块处理支持**：对超长序列提供分块预填充，突破单次处理限制
- **混合批次协调**：在混合模式下协调预填充和解码请求的资源分配

**约束条件的综合考量**：
- **内存资源约束**：确保token分配不超过GPU内存限制
- **LoRA适配器约束**：控制批次中LoRA适配器的数量
- **分离式架构约束**：在分离式模式下考虑特殊的内存管理需求
- **混合缓存约束**：在SWA等混合缓存模式下的特殊处理

### 3.1 调度决策算法

PrefillAdder的核心是基于多维度约束的智能决策算法，它需要在token预算、内存限制、LoRA约束、缓存状态等多个因素间找到最优平衡。

**决策算法的核心逻辑**：

```mermaid
graph TD
    subgraph "🎯 决策流程"
        A1["新请求进入"]
        A2["前缀缓存匹配<br/>tree_cache.match_prefix()"]
        A3["计算token需求<br/>input_tokens = len(fill_ids) - prefix_len"]
        A4{"token预算检查<br/>rem_total_tokens > 0?"}
        A5{"分块决策<br/>input_tokens > rem_chunk_tokens?"}
        A6["添加到can_run_list"]
        A7["创建分块请求<br/>new_chunked_req"]
        A8["更新token预算<br/>_update_prefill_budget()"]
        A9["返回AddReqResult"]
    end

    A1 --> A2
    A2 --> A3
    A3 --> A4
    A4 -->|是| A5
    A4 -->|否| A9
    A5 -->|否| A6
    A5 -->|是| A7
    A6 --> A8
    A7 --> A8
    A8 --> A9

    style A1 fill:#e3f2fd,color:#000000,stroke:#333
    style A4 fill:#fff3e0,color:#000000,stroke:#333
    style A5 fill:#fff3e0,color:#000000,stroke:#333
    style A9 fill:#ffebee,color:#000000,stroke:#333
```

**new_token_ratio的预算计算机制**：
new_token_ratio用于预估未来解码阶段的token消耗，确保预填充批次不会导致后续解码阶段的内存不足。计算公式为：

```
解码预算 = Σ(min(max_new_tokens - len(output_ids), CLIP_MAX_NEW_TOKENS) * new_token_ratio)
可用预算 = max_prefill_tokens - 解码预算 - 当前运行批次开销
```

### 3.2 前缀缓存集成机制

前缀缓存是SGLang性能优化的核心，PrefillAdder与TreeCache的集成实现了智能的缓存利用：

```python
# 前缀缓存匹配与统计
def add_one_req(self, req: Req, has_chunked_req: bool):
    # 初始化下一轮输入，触发前缀匹配
    req.init_next_round_input(self.tree_cache)
    
    # 统计缓存命中情况
    prefix_len = len(req.prefix_indices)       # 缓存命中的token数
    self.log_hit_tokens += prefix_len          # 累计命中统计
    self.log_input_tokens += len(req.fill_ids) # 累计输入统计
    
    # 计算实际需要处理的token数
    input_tokens = req.extend_input_len        # 扩展长度（去除前缀后的长度）
```

**缓存命中率优化**：
系统通过统计log_hit_tokens和log_input_tokens来监控前缀缓存的效果，缓存命中率 = log_hit_tokens / log_input_tokens。高缓存命中率意味着更少的重复计算。

### 3.3 分块预填充实现原理

当输入序列超过rem_chunk_tokens限制时，SGLang会启动分块预填充机制：

```python
# 分块预填充的核心决策逻辑
if self.rem_chunk_tokens is None or input_tokens <= self.rem_chunk_tokens:
    # 非分块路径：正常添加请求
    self.can_run_list.append(req)
    self._update_prefill_budget(prefix_len, input_tokens, max_new_tokens)
else:
    # 分块路径：截断序列并标记为分块请求
    trunc_len = self.rem_chunk_tokens - self.page_size + 1
    if trunc_len <= 0:
        return AddReqResult.OTHER  # 无法分块，拒绝请求
        
    req.extend_input_len = trunc_len  # 设置截断长度
    req.fill_ids = req.fill_ids[: len(req.prefix_indices) + trunc_len]  # 截断输入
    
    self.can_run_list.append(req)
    self.new_chunked_req = req  # 标记为新的分块请求
    self._update_prefill_budget(prefix_len, trunc_len, 0)  # 分块请求无解码预算
```

**分块请求的生命周期管理**：

```mermaid
graph LR
    subgraph "🔄 分块请求生命周期"
        A["长序列请求<br/>input_len > chunk_size"]
        B["创建分块请求<br/>new_chunked_req"]
        C["第一块处理<br/>chunk 1"]
        D["缓存未完成部分<br/>cache_unfinished_req()"]
        E["继续处理<br/>chunk 2"]
        F["完成处理<br/>chunked_req = None"]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F

    style A fill:#e3f2fd,color:#000000,stroke:#333
    style B fill:#f1f8e9,color:#000000,stroke:#333
    style C fill:#fff3e0,color:#000000,stroke:#333
    style D fill:#ffebee,color:#000000,stroke:#333
    style E fill:#f3e5f5,color:#000000,stroke:#333
    style F fill:#e8f5e8,color:#000000,stroke:#333
```

```python
class PrefillAdder:
    def __init__(
        self,
        page_size: int,
        tree_cache: BasePrefixCache,
        token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,
        running_batch: ScheduleBatch,
        new_token_ratio: float,
        rem_input_tokens: int,
        rem_chunk_tokens: Optional[int],
        mixed_with_decode_tokens: int = 0,
    ):
        self.page_size = page_size
        self.tree_cache = tree_cache
        self.token_to_kv_pool_allocator = token_to_kv_pool_allocator
        self.running_batch = running_batch
        self.new_token_ratio = new_token_ratio
        self.rem_input_tokens = rem_input_tokens - mixed_with_decode_tokens
        self.rem_chunk_tokens = rem_chunk_tokens
        if self.rem_chunk_tokens is not None:
            self.rem_chunk_tokens -= mixed_with_decode_tokens

        self.rem_total_token_offset = mixed_with_decode_tokens
        self.cur_rem_token_offset = mixed_with_decode_tokens

        self.req_states = None
        self.can_run_list = []
        self.new_chunked_req = None
        self.log_hit_tokens = 0
        self.log_input_tokens = 0

        # 计算解码阶段的token预算开销
        if running_batch is not None:
            self.rem_total_token_offset += sum(
                [
                    min(
                        (r.sampling_params.max_new_tokens - len(r.output_ids)),
                        CLIP_MAX_NEW_TOKENS,
                    )
                    * self.new_token_ratio
                    for r in running_batch.reqs
                ]
            )

        # 检查是否为混合缓存模式
        self.is_hybrid = isinstance(
            self.token_to_kv_pool_allocator, SWATokenToKVPoolAllocator
        )
```

### 3.4 核心数据结构

PrefillAdder的数据结构设计体现了现代推理系统在资源管理方面的精细化需求。每个字段都承载着特定的功能职责，共同支撑起复杂的批次构建逻辑。

**字段设计的核心考量**：
- **预算管理字段**：rem_input_tokens、rem_chunk_tokens等用于精确的token预算控制
- **状态跟踪字段**：can_run_list、new_chunked_req等用于跟踪添加过程的状态变化
- **性能统计字段**：log_hit_tokens、log_input_tokens等用于监控缓存效果和系统性能
- **配置参数字段**：page_size、new_token_ratio等用于控制添加策略的行为

**混合缓存模式支持**：
is_hybrid字段标识当前是否为SWA（Sliding Window Attention）混合缓存模式，这种模式需要特殊的锁定机制来保证缓存一致性。

**解码预算的前瞻性计算**：
rem_total_token_offset通过预估运行批次中每个请求的未来token消耗，确保预填充批次的构建不会导致后续解码阶段的内存不足。

```python
class PrefillAdder:
    def __init__(self, ...):
        # 核心配置
        self.page_size = page_size                    # KV缓存分页大小
        self.tree_cache = tree_cache                  # 前缀缓存引用
        self.new_token_ratio = new_token_ratio        # 解码token预估比率
        
        # token预算管理
        self.rem_input_tokens = rem_input_tokens      # 剩余输入token预算
        self.rem_chunk_tokens = rem_chunk_tokens      # 分块token限制
        
        # 状态跟踪
        self.can_run_list = []                        # 可运行请求列表
        self.new_chunked_req = None                   # 新创建的分块请求
        self.log_hit_tokens = 0                       # 前缀缓存命中统计
        self.log_input_tokens = 0                     # 总输入token统计
        
        # 混合缓存支持
        self.is_hybrid = isinstance(
            self.token_to_kv_pool_allocator, SWATokenToKVPoolAllocator
        )
```

### 3.5 添加结果枚举

```python
class AddReqResult(Enum):
    CONTINUE = auto()    # 继续添加更多请求
    NO_TOKEN = auto()    # 没有剩余token预算
    OTHER = auto()       # 其他停止原因（如LoRA限制、分块冲突等）
```

---

## 4. 批次操作与内存管理

### 4.1 批次合并机制

批次合并是SGLang连续批处理的核心机制，它通过mix_with_running方法实现预填充批次与解码批次的智能合并。这个过程需要协调不同前向模式的请求，确保GPU计算的高效执行。

**合并过程的核心步骤**：
- **前向模式设置**：将批次模式设置为MIXED，支持预填充和解码的混合执行
- **解码信息准备**：为运行批次中的请求设置解码所需的fill_ids和extend_input_len
- **张量数据合并**：合并input_ids、out_cache_loc等关键张量数据
- **长度信息更新**：更新prefix_lens、extend_lens等长度统计信息

```python
def mix_with_running(self, running_batch: "ScheduleBatch"):
    self.forward_mode = ForwardMode.MIXED
    running_bs = running_batch.batch_size()

    for req in running_batch.reqs:
        req.fill_ids = req.origin_input_ids + req.output_ids
        req.extend_input_len = 1

    input_ids = torch.cat([self.input_ids, running_batch.input_ids])
    out_cache_loc = torch.cat([self.out_cache_loc, running_batch.out_cache_loc])

    self.merge_batch(running_batch)
    self.input_ids = input_ids
    self.out_cache_loc = out_cache_loc

    # For overlap scheduler, the output_ids has one step delay
    delta = 0 if self.enable_overlap else -1

    # NOTE: prefix_indices is what has been cached, but we don't cache each decode step
    self.prefix_lens.extend(
        [
            len(r.origin_input_ids) + len(r.output_ids) + delta
            for r in running_batch.reqs
        ]
    )
    self.extend_lens.extend([1] * running_bs)
    self.extend_num_tokens += running_bs
    # TODO (lianmin): Revisit this. It should be seq_len - 1
    self.extend_logprob_start_lens.extend([0] * running_bs)
```

### 4.2 解码阶段内存管理

解码阶段的内存管理需要精确计算每个请求的KV缓存需求，特别是在分页KV缓存模式下，需要准确预估新页面的分配需求。

**分页KV缓存的内存预估**：
在分页KV缓存系统中，每个请求的KV缓存被分割成固定大小的页面。解码阶段需要为每个请求分配新的页面来存储新生成token的KV状态。

**页面分配的计算逻辑**：
- 当请求的序列长度达到页面边界时（seqlen % page_size == 0），需要分配新页面
- 重叠调度模式下，使用当前序列长度；非重叠模式下，使用序列长度减1
- 页面大小为1时，每个请求每次解码都需要新页面

```python
def new_page_count_next_decode(self):
    page_size = self.token_to_kv_pool_allocator.page_size
    if page_size == 1:
        return len(self.reqs)  # 每个请求都需要新页面
    
    # 计算需要新页面的请求数量
    return (
        sum(1 for req in self.reqs if req.seqlen % page_size == 0)
        if self.enable_overlap
        else sum(1 for req in self.reqs if (req.seqlen - 1) % page_size == 0)
    )

def check_decode_mem(self, buf_multiplier=1):
    num_tokens = self.new_page_count_next_decode()  # 预估需要的页面数
    available_tokens = self.token_to_kv_pool_allocator.available_size()  # 可用页面数
    return num_tokens * buf_multiplier <= available_tokens  # 内存充足性检查
```

**内存预估的准确性**：
准确的内存预估对于避免OOM错误至关重要。系统通过buf_multiplier参数提供安全缓冲，确保在内存紧张时仍能稳定运行。

### 4.3 分块预填充处理

分块预填充是SGLang处理超长序列的关键机制，它解决了GPU内存限制与长序列处理需求之间的矛盾。当输入序列超过单次处理能力时，系统会将其分割成多个chunk进行处理，每个chunk都能在GPU内存约束下正常执行。

**分块处理的核心挑战**：
- **状态连续性**：确保分块间的KV缓存状态正确传递
- **内存管理**：每个分块的内存分配和释放需要精确控制
- **性能优化**：最小化分块带来的额外开销
- **错误处理**：处理分块过程中可能出现的各种异常情况

**分块决策的智能化**：
系统通过rem_chunk_tokens参数控制分块的触发条件，当请求的input_tokens超过这个阈值时，会自动启动分块处理。分块长度的计算需要考虑页面大小，确保内存对齐。

**SPLIT_PREFILL模式**：
分块预填充使用专门的SPLIT_PREFILL前向模式，这种模式针对分块场景进行了特殊优化，包括KV缓存的分段管理和注意力计算的优化。

```python
def prepare_for_split_prefill(self):
    # For split prefill, we need to set the forward mode to SPLIT_PREFILL
    self.forward_mode = ForwardMode.SPLIT_PREFILL
```

## 5. 高级调度策略

### 5.1 连续批处理的流水线设计

SGLang的连续批处理采用了三级流水线设计，这是其实现高吞吐量的核心架构。通过last_batch、running_batch、new_batch的精密协调，系统能够在GPU执行当前批次的同时，并行准备下一个批次，实现了计算和调度的重叠执行。

**流水线设计的核心优势**：
- **计算调度重叠**：在GPU执行计算的同时，CPU并行进行下一批次的准备工作
- **状态无缝转换**：批次间的状态转换无需额外的同步开销
- **资源利用最大化**：通过智能合并避免GPU空闲时间
- **内存效率优化**：复用已分配的内存资源，减少分配释放开销

**三级流水线的协调机制**：
- **last_batch**：保存上一轮预填充的执行结果，等待与运行批次合并
- **running_batch**：当前正在解码的批次，包含所有活跃的生成请求
- **new_batch**：新构建的预填充批次，准备与运行批次合并或独立执行

**流水线调度的核心原理**：

```mermaid
graph LR
    subgraph "🔄 批次流水线"
        A["last_batch<br/>上轮预填充结果"]
        B["running_batch<br/>当前解码批次"]  
        C["new_batch<br/>新预填充批次"]
        D["next_batch<br/>下轮批次"]
    end

    A -->|merge_batch()| B
    B -->|mix_with_running()| C
    C -->|forward执行| D
    D -->|状态流转| A

    style A fill:#e3f2fd,color:#000000,stroke:#333
    style B fill:#f1f8e9,color:#000000,stroke:#333
    style C fill:#fff3e0,color:#000000,stroke:#333
    style D fill:#ffebee,color:#000000,stroke:#333
```

**动态合并决策算法**：
系统根据批次状态动态决定执行模式，实现最优的GPU利用率：

```python
# 动态批次合并的决策逻辑
if new_batch is not None:
    if self.running_batch.is_empty():
        return new_batch                    # 纯预填充模式（EXTEND）
    else:
        new_batch.mix_with_running(self.running_batch)  # 混合模式（MIXED）
        return new_batch
else:
    return self.running_batch if not self.running_batch.is_empty() else None  # 纯解码模式（DECODE）
```

### 5.2 多维度约束优化

SGLang的批处理调度面临着复杂的多维度约束优化问题，需要在满足各种资源限制的同时，最大化系统的性能表现。这种多目标优化的复杂性体现了生产级推理系统的工程挑战。

**约束优化的核心难题**：
- **约束冲突处理**：当多个约束条件同时生效时，需要智能的优先级决策
- **动态约束适应**：约束条件会随着系统状态动态变化，需要实时调整策略
- **性能目标平衡**：在满足约束的前提下，平衡吞吐量、延迟、资源利用率等多个性能目标
- **错误恢复机制**：当约束违反时，需要优雅的降级和恢复策略

**约束检查的执行顺序**：
系统按照约束的严格程度和检查成本进行排序，优先检查成本低且限制严格的约束，避免不必要的计算开销。

**约束优先级层次**：
1. **硬约束**：内存限制、请求数量限制（必须满足）
2. **软约束**：LoRA数量、分块冲突（影响性能但不影响正确性）
3. **优化目标**：前缀缓存命中率、批次大小最大化

**LoRA适配器约束管理**：
```python
# LoRA批次兼容性检查
if self.enable_lora and not self.tp_worker.can_run_lora_batch(
    lora_set | set([req.lora_id for req in adder.can_run_list]) | set([req.lora_id])
):
    self.running_batch.batch_is_full = True  # 达到LoRA限制，停止添加
    break
```

**分层缓存的预取协调**：
```python
# HiCache预取状态检查
if self.enable_hicache_storage:
    prefetch_done = self.tree_cache.check_prefetch_progress(req.rid)
    if not prefetch_done:
        continue  # 跳过预取未完成的请求，避免阻塞
```

### 5.3 性能监控与调优

SGLang的性能监控系统为批处理调度提供了全面的可观测性支持，通过多维度的性能指标和实时统计，帮助开发者深入理解系统行为并进行精准的性能调优。

**监控系统的设计理念**：
- **实时性**：所有关键指标都能实时计算和更新，为动态调优提供及时反馈
- **多维度覆盖**：从token级到批次级，从缓存效果到资源利用，全面覆盖性能要素
- **低开销**：监控机制本身的开销极小，不影响系统的正常性能
- **可操作性**：监控数据直接指向具体的优化方向，具有很强的实用价值

**性能指标的层次结构**：
- **基础指标**：token数量、序列数量、批次大小等基础统计
- **效率指标**：缓存命中率、内存利用率、吞吐量等效率度量
- **质量指标**：延迟分布、错误率、资源争用等质量评估

**关键性能指标**：
- **前缀缓存命中率**：log_hit_tokens / log_input_tokens
- **批次利用率**：实际批次大小 / 最大批次大小  
- **内存利用率**：已用token数 / 总可用token数
- **吞吐量指标**：处理的token数 / 时间

```python
# 性能统计的核心实现
def log_prefill_stats(self, adder: PrefillAdder, can_run_list: List[Req], running_bs: int):
    # 计算输入吞吐量
    gap_latency = time.perf_counter() - self.last_prefill_stats_tic
    self.last_input_throughput = self.last_prefill_tokens / gap_latency
    
    # 统计批次信息
    num_new_seq = len(can_run_list)           # 新序列数量
    new_tokens = adder.log_input_tokens       # 新token数量
    cached_tokens = adder.log_hit_tokens      # 缓存命中token数量
    
    logger.info(f"Prefill batch. #new-seq: {num_new_seq}, "
                f"#new-token: {new_tokens}, #cached-token: {cached_tokens}")
```

---

## 6. 架构总结与技术价值

### 6.1 批处理调度的核心贡献

SGLang的批处理调度系统在现代大语言模型推理领域展现了重要的技术价值，其设计理念和实现方法为推理系统的发展提供了有价值的参考。该系统通过解决传统批处理的多个技术难题，为高性能推理服务奠定了坚实基础。

**解决的核心技术难题**：
- **异构批次统一处理**：通过MIXED模式实现预填充和解码请求的统一批处理
- **长序列处理瓶颈**：通过分块预填充突破GPU内存对序列长度的限制
- **资源利用率优化**：通过连续批处理避免GPU计算资源的空闲浪费
- **多约束条件协调**：在复杂约束下实现最优的请求选择和批次构建

**架构设计的前瞻性**：
系统的模块化设计为未来的功能扩展预留了空间，无论是新的前向模式、缓存策略，还是约束条件，都能在现有架构基础上平滑集成。

**技术创新要点**：
- **连续批处理架构**：三级流水线设计实现了GPU资源的最大化利用
- **智能请求调度**：多维度约束下的优化请求选择算法
- **分块预填充机制**：突破单次处理长度限制的创新解决方案
- **前缀缓存集成**：深度集成的缓存优化，显著减少重复计算

### 6.2 工程实现的复杂性

批处理调度系统的实现充分展现了生产级推理系统的工程复杂性，从状态管理到资源协调，从性能优化到错误处理，每个环节都需要精心设计和细致实现。

**实现复杂性的多个维度**：
- **状态一致性维护**：在多批次并行执行的环境下，确保所有状态的一致性和正确性
- **资源竞争协调**：多个批次对GPU内存、计算资源的竞争需要精确的协调机制
- **异常处理完备性**：从内存不足到约束违反，需要处理各种可能的异常情况
- **性能监控集成**：在不影响性能的前提下，集成完整的监控和调试功能

**代码复杂度的必然性**：
系统的复杂性不是设计缺陷，而是功能完备性的必然结果。每一行代码都对应着实际生产环境中的具体需求和挑战。

**状态管理的精细化**：
```python
# 复杂的状态转换管理
chunked_req_to_exclude = set()              # 需要排除的分块请求
if self.chunked_req:
    chunked_req_to_exclude.add(self.chunked_req)
    self.tree_cache.cache_unfinished_req(self.chunked_req)  # 缓存未完成部分
    self.req_to_token_pool.free(self.chunked_req.req_pool_idx)  # 释放内存槽位
```

**多模式协调的复杂性**：
系统需要在EXTEND、DECODE、MIXED、SPLIT_PREFILL四种前向模式间进行智能切换，每种模式都有其特定的执行路径和优化策略。

**资源约束的全面考量**：
从基础的内存限制到高级的LoRA约束，从分离式架构的特殊需求到分层缓存的预取协调，系统需要综合考虑所有约束条件。

### 6.3 性能优化的系统性方法

SGLang的批处理调度采用了多层次、全方位的性能优化策略，形成了完整的性能优化体系。这种系统性的优化方法不仅提升了单一指标，更实现了整体性能的协调优化。

**优化策略的协同效应**：
- **计算与内存的协调优化**：通过前缀缓存减少计算量的同时，优化内存访问模式
- **调度与执行的协同优化**：调度策略与GPU执行特性深度适配，最大化硬件效率
- **短期与长期的平衡优化**：既考虑当前批次的性能，也考虑对未来批次的影响

**优化效果的量化评估**：
系统通过log_prefill_stats等机制提供详细的性能数据，包括吞吐量提升、缓存命中率改善、资源利用率优化等可量化的效果评估。

**计算效率优化**：
- 前缀缓存减少重复计算
- 批次合并最大化GPU利用率
- 分块处理突破长度限制

**内存效率优化**：
- 精确的token预算管理
- 分页KV缓存的高效分配
- 智能的内存回收机制

**调度效率优化**：
- 优先级驱动的请求选择
- 多维度约束的快速检查
- 动态的批次组合决策

**承上启下**：在前面章节中我们了解了调度器的架构、数据结构和请求处理机制，本章深入剖析了批处理调度的核心算法。接下来我们将探讨内存管理系统，了解SGLang如何实现高效的KV缓存管理和前缀缓存优化。