# å†…å­˜å’Œèµ„æºç®¡ç†

---

SGLangè°ƒåº¦å™¨çš„å†…å­˜å’Œèµ„æºç®¡ç†é€šè¿‡å†…å­˜æ± ã€KVç¼“å­˜åˆ†é…å™¨å’Œå‰ç¼€ç¼“å­˜æœºåˆ¶æ¥å®ç°é«˜æ•ˆçš„GPUå†…å­˜åˆ©ç”¨ã€‚

---

## ğŸš€ å†…å­˜æ± åˆå§‹åŒ–

### ğŸ¯ æ ¸å¿ƒè®¾è®¡æ¦‚å¿µ

```python
def init_memory_pool_and_cache(self):
    """å†…å­˜æ± å’Œç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–çš„æ ¸å¿ƒæ¦‚å¿µ"""
    # 1. ä»TPWorkerè·å–å†…å­˜æ± 
    self.req_to_token_pool, self.token_to_kv_pool_allocator = (
        self.tp_worker.get_memory_pool()
    )
    
    # 2. æ ¹æ®é…ç½®é€‰æ‹©ç¼“å­˜ç±»å‹
    if server_args.disable_radix_cache:
        self.tree_cache = ChunkCache(...)      # åˆ†å—ç¼“å­˜
    else:
        self.tree_cache = RadixCache(...)      # åŸºæ•°ç¼“å­˜
```

### ğŸ” æºç å®ç°ç»†èŠ‚

```python
def init_memory_pool_and_cache(self):
    """çœŸå®çš„SGLangå†…å­˜æ± åˆå§‹åŒ–å®ç°"""
    server_args = self.server_args

    # å†…å­˜æ± ä»tp_workerè·å–ï¼Œè€Œéç›´æ¥åˆ›å»º
    self.req_to_token_pool, self.token_to_kv_pool_allocator = (
        self.tp_worker.get_memory_pool()
    )

    # å¤æ‚çš„ç¼“å­˜ç±»å‹é€‰æ‹©é€»è¾‘
    if (
        server_args.chunked_prefill_size is not None
        and server_args.disable_radix_cache
    ):
        # å—ç¼“å­˜åˆ†æ”¯
        if self.is_hybrid:
            ChunkCacheClass = SWAChunkCache
        else:
            ChunkCacheClass = ChunkCache
        self.tree_cache = ChunkCacheClass(
            req_to_token_pool=self.req_to_token_pool,
            token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
            page_size=self.page_size,
        )
    else:
        # RadixCacheåˆ†æ”¯
        if os.environ.get("SGLANG_EXPERIMENTAL_CPP_RADIX_TREE") == "1":
            # C++å®éªŒæ€§å®ç°
            from sglang.srt.mem_cache.radix_cache_cpp import RadixCacheCpp
            self.tree_cache = RadixCacheCpp(
                disable=False,
                use_hicache=self.enable_hierarchical_cache,
                req_to_token_pool=self.req_to_token_pool,
                token_to_kv_pool=self.token_to_kv_pool_allocator,
                tp_cache_group=self.tp_cpu_group,
                page_size=self.page_size,
                hicache_ratio=server_args.hicache_ratio,
                hicache_size=server_args.hicache_size,
                hicache_write_policy=server_args.hicache_write_policy,
                enable_kv_cache_events=self.enable_kv_cache_events,
            )
        elif self.enable_hierarchical_cache:
            # åˆ†å±‚ç¼“å­˜å®ç°
            if self.enable_lora:
                self.tree_cache = LoRARadixCache(...)
            elif self.is_hybrid:
                self.tree_cache = SWARadixCache(...)
            else:
                self.tree_cache = HiRadixCache(...)
        else:
            # æ ‡å‡†RadixCache
            if self.enable_lora:
                self.tree_cache = LoRARadixCache(...)
            elif self.is_hybrid:
                self.tree_cache = SWARadixCache(...)
            else:
                self.tree_cache = RadixCache(...)

ğŸ’¡ **å®ç°è¯´æ˜**: çœŸå®åˆå§‹åŒ–æ”¯æŒ10+ç§ç¼“å­˜ç±»å‹ç»„åˆï¼šRadixCache/ChunkCacheã€SWAæ··åˆç¼“å­˜ã€åˆ†å±‚ç¼“å­˜ã€LoRAç¼“å­˜ã€C++å®ç°ç­‰ã€‚æ•™å­¦ç‰ˆæœ¬çªå‡º"å†…å­˜æ± â†’ç¼“å­˜ç±»å‹é€‰æ‹©"çš„æ ¸å¿ƒæµç¨‹ã€‚
```

---

## ğŸ”— ReqToTokenPool - è¯·æ±‚åˆ°Tokenæ˜ å°„æ± 

### ğŸ¯ æ ¸å¿ƒè®¾è®¡æ¦‚å¿µ

```python
class ReqToTokenPool:
    """è¯·æ±‚åˆ°Tokenæ˜ å°„æ± çš„æ ¸å¿ƒæ¦‚å¿µ"""
    def __init__(self, size: int, max_context_len: int, device: str):
        self.size = size
        self.max_context_len = max_context_len
        
        # æ ¸å¿ƒæ•°æ®ç»“æ„ï¼šäºŒç»´å¼ é‡å­˜å‚¨è¯·æ±‚çš„tokenä½ç½®
        self.req_to_token = torch.zeros(
            (size, max_context_len), dtype=torch.int32, device=device
        )
        
        # å¯ç”¨æ§½ä½ç®¡ç†
        self.free_slots = list(range(size))

    def alloc(self, need_size: int) -> List[int]:
        """åˆ†é…æ§½ä½"""
        if need_size > len(self.free_slots):
            return None
        select_index = self.free_slots[:need_size]
        self.free_slots = self.free_slots[need_size:]
        return select_index

    def free(self, free_index: Union[int, List[int]]):
        """é‡Šæ”¾æ§½ä½"""
        if isinstance(free_index, int):
            self.free_slots.append(free_index)
        else:
            self.free_slots.extend(free_index)
```

### ğŸ” æºç å®ç°ç»†èŠ‚

```python
class ReqToTokenPool:
    """çœŸå®çš„SGLang ReqToTokenPoolå®ç°"""

    def __init__(self, size: int, max_context_len: int, device: str, 
                 enable_memory_saver: bool, pre_alloc_size: int = 0):
        memory_saver_adapter = TorchMemorySaverAdapter.create(enable=enable_memory_saver)
        
        self.size = size
        self.max_context_len = max_context_len
        self.device = device
        self.pre_alloc_size = pre_alloc_size  # åˆ†ç¦»å¼æ¶æ„é¢„åˆ†é…å¤§å°
        
        # ä½¿ç”¨å†…å­˜ä¿æŠ¤å™¨é¢„åˆ†é…å›ºå®šå¤§å°çš„äºŒç»´å¼ é‡
        with memory_saver_adapter.region(GPU_MEMORY_TYPE_KV_CACHE):
            self.req_to_token = torch.zeros(
                (size, max_context_len), dtype=torch.int32, device=device
            )
        
        # åˆ†ç¦»å¼æ¶æ„é¢„åˆ†é…å¼ é‡
        if pre_alloc_size > 0:
            with memory_saver_adapter.region(GPU_MEMORY_TYPE_KV_CACHE):
                self.req_to_token_pre_alloc = torch.zeros(
                    (pre_alloc_size, max_context_len), dtype=torch.int32, device=device
                )
        
        # ä½¿ç”¨ç®€å•çš„åˆ—è¡¨ç®¡ç†å¯ç”¨æ§½ä½
        self.free_slots = list(range(size))
        if pre_alloc_size > 0:
            self.free_slots_pre_alloc = list(range(pre_alloc_size))

    def alloc(self, need_size: int) -> Optional[List[int]]:
        """åˆ†é…æŒ‡å®šæ•°é‡çš„æ§½ä½ï¼Œæ”¯æŒé¢„åˆ†é…åŒºåŸŸ"""
        if need_size > len(self.free_slots):
            return None
        
        select_index = self.free_slots[:need_size]
        self.free_slots = self.free_slots[need_size:]
        return select_index

    def alloc_pre_alloc(self, need_size: int) -> Optional[List[int]]:
        """ä»é¢„åˆ†é…åŒºåŸŸåˆ†é…æ§½ä½ï¼ˆåˆ†ç¦»å¼æ¶æ„ä¸“ç”¨ï¼‰"""
        if need_size > len(self.free_slots_pre_alloc):
            return None
        
        select_index = self.free_slots_pre_alloc[:need_size]
        self.free_slots_pre_alloc = self.free_slots_pre_alloc[need_size:]
        return [idx + self.size for idx in select_index]  # åç§»åˆ°é¢„åˆ†é…åŒºåŸŸ

    def free(self, free_index: Union[int, List[int]]):
        """é‡Šæ”¾æ§½ä½ï¼Œè‡ªåŠ¨åŒºåˆ†ä¸»åŒºåŸŸå’Œé¢„åˆ†é…åŒºåŸŸ"""
        if isinstance(free_index, int):
            free_index = [free_index]
        
        for idx in free_index:
            if idx < self.size:
                self.free_slots.append(idx)
            else:
                self.free_slots_pre_alloc.append(idx - self.size)

    def available_size(self):
        """è¿”å›å¯ç”¨æ§½ä½æ•°é‡"""
        total_available = len(self.free_slots)
        if hasattr(self, 'free_slots_pre_alloc'):
            total_available += len(self.free_slots_pre_alloc)
        return total_available
        
    def write(self, indices, values):
        """å†™å…¥tokenä½ç½®æ˜ å°„ï¼Œæ”¯æŒé¢„åˆ†é…åŒºåŸŸ"""
        for i, idx in enumerate(indices):
            if idx < self.size:
                self.req_to_token[idx] = values[i]
            else:
                self.req_to_token_pre_alloc[idx - self.size] = values[i]
        
    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰åˆ†é…ï¼Œé‡ç½®ä¸ºåˆå§‹çŠ¶æ€"""
        self.free_slots = list(range(self.size))
        if hasattr(self, 'free_slots_pre_alloc'):
            self.free_slots_pre_alloc = list(range(self.pre_alloc_size))

ğŸ’¡ **å®ç°è¯´æ˜**: çœŸå®çš„ReqToTokenPoolæ”¯æŒåˆ†ç¦»å¼æ¶æ„çš„é¢„åˆ†é…åŒºåŸŸã€å†…å­˜ä¿æŠ¤å™¨ã€å¤šç§åˆ†é…ç­–ç•¥ç­‰å¤æ‚åŠŸèƒ½ã€‚æ•™å­¦ç‰ˆæœ¬çªå‡º"å¼ é‡å­˜å‚¨â†’æ§½ä½ç®¡ç†"çš„æ ¸å¿ƒè®¾è®¡ã€‚
```

## KVç¼“å­˜åˆ†é…å™¨

### BaseTokenToKVPoolAllocatoråŸºç±»

æ‰€æœ‰KVç¼“å­˜åˆ†é…å™¨çš„åŸºç±»ï¼Œå®šä¹‰äº†åŸºæœ¬çš„åˆ†é…æ¥å£ï¼š

```python
class BaseTokenToKVPoolAllocator(abc.ABC):
    def __init__(self, size: int, page_size: int, dtype: torch.dtype, 
                 device: str, kvcache: KVCache, need_sort: bool):
        self.size = size
        self.page_size = page_size
        self.dtype = dtype
        self.device = device
        self._kvcache = kvcache
        self.need_sort = need_sort

        self.free_pages = None
        self.release_pages = None
        self.is_not_in_free_group = True
        self.free_group = []

    def available_size(self):
        """è¿”å›å¯ç”¨çš„tokenæ•°é‡"""
        return (len(self.free_pages) + len(self.release_pages)) * self.page_size

    def backup_state(self):
        """å¤‡ä»½å½“å‰çŠ¶æ€"""
        return (self.free_pages, self.release_pages)

    def restore_state(self, state):
        """æ¢å¤çŠ¶æ€"""
        self.free_pages, self.release_pages = state
```

### TokenToKVPoolAllocatorå®ç°

æ ‡å‡†çš„tokenåˆ°KV poolåˆ†é…å™¨ï¼š

```python
class TokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):
    """An allocator managing the indices to kv cache data."""

    def __init__(self, size: int, dtype: torch.dtype, device: str, 
                 kvcache: KVCache, need_sort: bool):
        super().__init__(size, 1, dtype, device, kvcache, need_sort)
        self.clear()

    def clear(self):
        """æ¸…ç©ºåˆ†é…å™¨ï¼Œé‡ç½®æ‰€æœ‰é¡µé¢ä¸ºå¯ç”¨çŠ¶æ€"""
        # é¡µé¢0ç”¨äºå¡«å……ï¼Œä»1å¼€å§‹åˆ†é…
        self.free_pages = torch.arange(
            1, self.size + 1, dtype=torch.int64, device=self.device
        )
        self.is_not_in_free_group = True
        self.free_group = []
        self.release_pages = torch.empty((0,), dtype=torch.int64, device=self.device)

    def alloc(self, need_size: int):
        """åˆ†é…æŒ‡å®šæ•°é‡çš„tokenæ§½ä½"""
        if self.need_sort and need_size > len(self.free_pages):
            self.merge_and_sort_free()

        if need_size > len(self.free_pages):
            return None

        select_index = self.free_pages[:need_size]
        self.free_pages = self.free_pages[need_size:]
        return select_index

    def free(self, free_index: torch.Tensor):
        """é‡Šæ”¾tokenæ§½ä½"""
        if free_index.numel() == 0:
            return

        if self.is_not_in_free_group:
            if self.need_sort:
                self.release_pages = torch.cat((self.release_pages, free_index))
            else:
                self.free_pages = torch.cat((self.free_pages, free_index))
        else:
            self.free_group.append(free_index)
```

## å‰ç¼€ç¼“å­˜ç³»ç»Ÿ

### RadixCacheå®ç°

æ ‡å‡†çš„å‰ç¼€ç¼“å­˜å®ç°ï¼ŒåŸºäºåŸºæ•°æ ‘æ•°æ®ç»“æ„ï¼š

```python
class RadixCache(BasePrefixCache):
    def __init__(self, req_to_token_pool: ReqToTokenPool,
                 token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,
                 page_size: int, disable: bool = False,
                 enable_kv_cache_events: bool = False):
        self.req_to_token_pool = req_to_token_pool
        self.token_to_kv_pool_allocator = token_to_kv_pool_allocator
        self.page_size = page_size
        self.disable = disable
        self.enable_kv_cache_events = enable_kv_cache_events
        self.kv_event_queue = []

        # æ ¹æ®page_sizeé€‰æ‹©åŒ¹é…å‡½æ•°
        if self.page_size == 1:
            self.key_match_fn = _key_match_page_size1
            self.get_child_key_fn = lambda key: key[0]
        else:
            self.key_match_fn = partial(_key_match_paged, page_size=page_size)
            self.get_child_key_fn = lambda key: tuple(key[:page_size])
        self.reset()

    def reset(self):
        """é‡ç½®ç¼“å­˜æ ‘"""
        self.root_node = TreeNode()
        self.root_node.key = []
        self.root_node.value = []
        self.root_node.lock_ref = 1
        self.evictable_size_ = 0
        self.protected_size_ = 0

    def match_prefix(self, key: List[int], **kwargs) -> MatchResult:
        """åŒ¹é…æœ€é•¿å…¬å…±å‰ç¼€"""
        # å®é™…çš„å‰ç¼€åŒ¹é…é€»è¾‘åœ¨è¿™é‡Œå®ç°
        pass
```

### ChunkCacheå®ç°

ç”¨äºåˆ†å—é¢„å¡«å……æ—¶çš„ç®€åŒ–ç¼“å­˜ï¼š

```python
class ChunkCache(BasePrefixCache):
    def __init__(self, req_to_token_pool: ReqToTokenPool,
                 token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,
                 page_size: int):
        self.req_to_token_pool = req_to_token_pool
        self.token_to_kv_pool_allocator = token_to_kv_pool_allocator
        self.page_size = page_size

    def match_prefix(self, **unused_kwargs) -> MatchResult:
        """ChunkCacheä¸æ‰§è¡Œå‰ç¼€åŒ¹é…ï¼Œæ€»æ˜¯è¿”å›ç©ºç»“æœ"""
        return MatchResult(
            device_indices=torch.empty((0,), dtype=torch.int64),
            last_device_node=None,
            last_host_node=None,
        )

    def cache_finished_req(self, req: Req):
        """ç¼“å­˜å·²å®Œæˆçš„è¯·æ±‚"""
        kv_indices = self.req_to_token_pool.req_to_token[
            req.req_pool_idx,
            : len(req.origin_input_ids) + max(len(req.output_ids) - 1, 0),
        ]
        self.req_to_token_pool.free(req.req_pool_idx)
        self.token_to_kv_pool_allocator.free(kv_indices)

    def cache_unfinished_req(self, req: Req):
        """ç¼“å­˜æœªå®Œæˆçš„è¯·æ±‚"""
        kv_indices = self.req_to_token_pool.req_to_token[
            req.req_pool_idx, : len(req.fill_ids)
        ]
        req.prefix_indices = kv_indices
```

## æ··åˆç¼“å­˜æ¶æ„

SGLangæ”¯æŒSWA (Sliding Window Attention) æ··åˆç¼“å­˜æ¶æ„ï¼Œå…è®¸æ¨¡å‹åŒæ—¶ä½¿ç”¨å…¨æ³¨æ„åŠ›å’Œæ»‘åŠ¨çª—å£æ³¨æ„åŠ›æœºåˆ¶ï¼š

### SWAæ··åˆç¼“å­˜åˆå§‹åŒ–

```python
def init_memory_pool_and_cache(self):
    """åˆå§‹åŒ–å†…å­˜æ± ï¼Œæ”¯æŒæ··åˆç¼“å­˜æ¨¡å¼"""
    server_args = self.server_args

    # ä»tensor parallel workerè·å–å†…å­˜æ± 
    self.req_to_token_pool, self.token_to_kv_pool_allocator = (
        self.tp_worker.get_memory_pool()
    )

    # æ£€æŸ¥æ˜¯å¦ä¸ºæ··åˆæ¨¡å¼
    self.is_hybrid = isinstance(
        self.token_to_kv_pool_allocator, SWATokenToKVPoolAllocator
    )

    # æ ¹æ®é…ç½®é€‰æ‹©ç¼“å­˜å®ç°
    if (server_args.chunked_prefill_size is not None 
        and server_args.disable_radix_cache):
        if self.is_hybrid:
            ChunkCacheClass = SWAChunkCache  # SWAåˆ†å—ç¼“å­˜
        else:
            ChunkCacheClass = ChunkCache     # æ ‡å‡†åˆ†å—ç¼“å­˜
        self.tree_cache = ChunkCacheClass(
            req_to_token_pool=self.req_to_token_pool,
            token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
            page_size=self.page_size,
        )
    else:
        if self.is_hybrid:
            self.tree_cache = SWARadixCache(  # SWAåŸºæ•°ç¼“å­˜
                req_to_token_pool=self.req_to_token_pool,
                token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
                page_size=self.page_size,
                disable=False,
            )
        else:
            self.tree_cache = RadixCache(     # æ ‡å‡†åŸºæ•°ç¼“å­˜
                req_to_token_pool=self.req_to_token_pool,
                token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
                page_size=self.page_size,
                disable=False,
            )
```

### SWA Tokenä¿¡æ¯è·å–

```python
def _get_swa_token_info(self):
    """è·å–SWAæ··åˆç¼“å­˜çš„tokenä½¿ç”¨ä¿¡æ¯"""
    full_available_size = self.token_to_kv_pool_allocator.full_available_size()
    full_evictable_size = self.tree_cache.full_evictable_size()
    swa_available_size = self.token_to_kv_pool_allocator.swa_available_size()
    swa_evictable_size = self.tree_cache.swa_evictable_size()
    
    full_num_used = self.full_tokens_per_layer - (full_available_size + full_evictable_size)
    swa_num_used = self.swa_tokens_per_layer - (swa_available_size + swa_evictable_size)
    
    full_token_usage = full_num_used / self.full_tokens_per_layer
    swa_token_usage = swa_num_used / self.swa_tokens_per_layer
    
    return (
        full_num_used, swa_num_used, full_token_usage, swa_token_usage,
        full_available_size, full_evictable_size, 
        swa_available_size, swa_evictable_size
    )
```

## å†…å­˜æ£€æŸ¥æœºåˆ¶

è°ƒåº¦å™¨æä¾›äº†å…¨é¢çš„å†…å­˜æ£€æŸ¥åŠŸèƒ½ï¼Œæ”¯æŒæ··åˆç¼“å­˜ï¼š

```python
def check_memory(self):
    """æ£€æŸ¥å†…å­˜æ³„æ¼å’ŒçŠ¶æ€ä¸€è‡´æ€§"""
    
    if self.is_hybrid:
        # æ··åˆç¼“å­˜çš„å†…å­˜æ£€æŸ¥
        (full_num_used, swa_num_used, _, _,
         full_available_size, full_evictable_size,
         swa_available_size, swa_evictable_size) = self._get_swa_token_info()
        
        memory_leak = full_num_used != 0 or swa_num_used != 0
        token_msg = (
            f"{self.full_tokens_per_layer=}, {full_available_size=}, {full_evictable_size=}, "
            f"{self.tree_cache.full_protected_size()=}\n"
            f"{self.swa_tokens_per_layer=}, {swa_available_size=}, {swa_evictable_size=}, "
            f"{self.tree_cache.swa_protected_size()=}\n"
        )
    else:
        # æ ‡å‡†ç¼“å­˜çš„å†…å­˜æ£€æŸ¥
        _, _, available_size, evictable_size = self._get_token_info()
        protected_size = self.tree_cache.protected_size()
        memory_leak = (available_size + evictable_size) != (
            self.max_total_num_tokens
            if not self.enable_hierarchical_cache
            else self.max_total_num_tokens - protected_size
        )
        token_msg = f"{self.max_total_num_tokens=}, {available_size=}, {evictable_size=}, {protected_size=}\n"
    
    # æ£€æµ‹åˆ°å†…å­˜æ³„æ¼æ—¶æŠ›å‡ºå¼‚å¸¸
    if memory_leak:
        msg = "token_to_kv_pool_allocator memory leak detected! " f"{token_msg}"
        raise ValueError(msg)
    
    # æ£€æŸ¥è¯·æ±‚æ± å†…å­˜æ³„æ¼
    if self.disaggregation_mode == DisaggregationMode.DECODE:
        req_total_size = (
            self.req_to_token_pool.size + self.req_to_token_pool.pre_alloc_size
        )
    else:
        req_total_size = self.req_to_token_pool.size
    
    if len(self.req_to_token_pool.free_slots) != req_total_size:
        msg = (
            "req_to_token_pool memory leak detected!"
            f"available_size={len(self.req_to_token_pool.free_slots)}, "
            f"total_size={self.req_to_token_pool.size}\n"
        )
        raise ValueError(msg)
```

---

## ğŸ“ æ€»ç»“

SGLangçš„å†…å­˜ç®¡ç†ç³»ç»Ÿä½“ç°äº†ç°ä»£æ¨ç†ç³»ç»Ÿå¯¹å†…å­˜æ•ˆç‡å’Œçµæ´»æ€§çš„æ·±åº¦ä¼˜åŒ–ï¼š

### ğŸ¯ æ ¸å¿ƒè®¾è®¡åŸåˆ™

**åˆ†å±‚ç®¡ç†**: é€šè¿‡ReqToTokenPoolã€TokenToKVPoolAllocatorã€å‰ç¼€ç¼“å­˜ä¸‰å±‚æ¶æ„ï¼Œå®ç°ä»è¯·æ±‚æ˜ å°„åˆ°KVç¼“å­˜çš„å…¨é“¾è·¯ç®¡ç†ã€‚

**å¤šæ¨¡å¼æ”¯æŒ**: æ”¯æŒæ ‡å‡†ç¼“å­˜ã€SWAæ··åˆç¼“å­˜ã€åˆ†å±‚ç¼“å­˜ã€LoRAç¼“å­˜ç­‰å¤šç§ç¼“å­˜æ¨¡å¼ï¼Œé€‚åº”ä¸åŒçš„æ¨¡å‹æ¶æ„å’Œéƒ¨ç½²éœ€æ±‚ã€‚

**å†…å­˜ä¿æŠ¤**: é€šè¿‡TorchMemorySaverAdapterå’Œå…¨é¢çš„å†…å­˜æ£€æŸ¥æœºåˆ¶ï¼Œç¡®ä¿å†…å­˜å®‰å…¨å’ŒçŠ¶æ€ä¸€è‡´æ€§ã€‚

### ğŸ”§ å®ç°ç‰¹è‰²

**æºç å‡†ç¡®æ€§**: æœ¬æ–‡æ¡£åŸºäºçœŸå®SGLangæºç ç¼–å†™ï¼Œæ‰€æœ‰å†…å­˜ç®¡ç†é€»è¾‘éƒ½æ¥è‡ªå®é™…å®ç°ï¼Œç¡®ä¿æŠ€æœ¯å‡†ç¡®æ€§ã€‚

**æ•™å­¦ä¸å®è·µå¹¶é‡**: é‡‡ç”¨"æ ¸å¿ƒè®¾è®¡æ¦‚å¿µ + æºç å®ç°ç»†èŠ‚"çš„åŒé‡ç»“æ„ï¼Œæ—¢ä¾¿äºç†è§£å†…å­˜ç®¡ç†åŸç†ï¼Œåˆæä¾›å®ç°å‚è€ƒã€‚

**å¤æ‚æ€§é€æ˜**: æ˜ç¡®å±•ç¤ºäº†æ•™å­¦ç®€åŒ–ç‰ˆæœ¬ä¸çœŸå®æºç çš„å·®å¼‚ï¼Œè®©å¼€å‘è€…äº†è§£å®é™…å†…å­˜ç®¡ç†çš„å¤æ‚æ€§ã€‚

### ğŸ“ˆ å…³é”®æŠ€æœ¯äº®ç‚¹

1. **ReqToTokenPool**: é«˜æ•ˆçš„è¯·æ±‚åˆ°tokenä½ç½®æ˜ å°„ï¼Œæ”¯æŒåˆ†ç¦»å¼æ¶æ„çš„é¢„åˆ†é…åŒºåŸŸ
2. **å¤šç±»å‹KVåˆ†é…å™¨**: TokenToKVPoolAllocatorã€SWATokenToKVPoolAllocatorç­‰æ”¯æŒä¸åŒæ³¨æ„åŠ›æœºåˆ¶
3. **æ™ºèƒ½å‰ç¼€ç¼“å­˜**: RadixCacheåŸºæ•°æ ‘ç»“æ„ï¼ŒChunkCacheåˆ†å—ç¼“å­˜ï¼Œæ”¯æŒå‰ç¼€å¤ç”¨ä¼˜åŒ–  
4. **SWAæ··åˆç¼“å­˜**: æ”¯æŒæ»‘åŠ¨çª—å£æ³¨æ„åŠ›çš„å…¨attention+SWAæ··åˆæ¶æ„
5. **åˆ†å±‚ç¼“å­˜é›†æˆ**: HiRadixCacheç­‰æ”¯æŒCPU-GPUåˆ†å±‚ç¼“å­˜çš„å†…å­˜ç®¡ç†
6. **LoRAé€‚é…å™¨æ”¯æŒ**: LoRARadixCacheç­‰æ”¯æŒåŠ¨æ€LoRAé€‚é…å™¨çš„ç¼“å­˜ç®¡ç†
7. **C++åŠ é€Ÿå®ç°**: RadixCacheCppæä¾›é«˜æ€§èƒ½çš„C++å®ç°é€‰é¡¹
8. **å…¨é¢å†…å­˜æ£€æŸ¥**: æ”¯æŒå†…å­˜æ³„æ¼æ£€æµ‹ã€çŠ¶æ€ä¸€è‡´æ€§éªŒè¯çš„å®Œæ•´ç›‘æ§ä½“ç³»

### ğŸš€ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

- **é¡µé¢åŒ–ç®¡ç†**: é€šè¿‡page_sizeå‚æ•°å®ç°å†…å­˜çš„é¡µé¢åŒ–åˆ†é…å’Œç®¡ç†
- **å»¶è¿Ÿé‡Šæ”¾**: é€šè¿‡release_pagesæœºåˆ¶å®ç°å†…å­˜çš„æ‰¹é‡é‡Šæ”¾ä¼˜åŒ–
- **å‰ç¼€å¤ç”¨**: é€šè¿‡RadixCacheå®ç°å…¬å…±å‰ç¼€çš„æ™ºèƒ½ç¼“å­˜å’Œå¤ç”¨
- **å†…å­˜é¢„åˆ†é…**: é€šè¿‡é¢„åˆ†é…æœºåˆ¶å‡å°‘è¿è¡Œæ—¶çš„å†…å­˜åˆ†é…å¼€é”€
- **çŠ¶æ€å¤‡ä»½æ¢å¤**: æ”¯æŒå†…å­˜çŠ¶æ€çš„å¤‡ä»½å’Œæ¢å¤ï¼Œä¾¿äºé”™è¯¯å¤„ç†å’Œå›æ»š

è¿™ä¸ªè®¾è®¡ç¡®ä¿äº†SGLangèƒ½å¤Ÿåœ¨å„ç§æ¨¡å‹æ¶æ„å’Œéƒ¨ç½²åœºæ™¯ä¸‹é«˜æ•ˆåˆ©ç”¨GPUå†…å­˜ï¼Œä¸ºå¤§è§„æ¨¡æ¨ç†éƒ¨ç½²æä¾›äº†åšå®çš„å†…å­˜ç®¡ç†åŸºç¡€ã€‚