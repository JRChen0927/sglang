# 内存和资源管理

SGLang调度器的内存和资源管理通过内存池、KV缓存分配器和前缀缓存机制来实现高效的GPU内存利用。

## 内存池初始化

调度器通过`init_memory_pool_and_cache()`方法初始化内存管理组件：

```python
def init_memory_pool_and_cache(self):
    server_args = self.server_args

    # 从tensor parallel worker获取内存池
    self.req_to_token_pool, self.token_to_kv_pool_allocator = (
        self.tp_worker.get_memory_pool()
    )

    # 根据配置选择缓存实现
    if (server_args.chunked_prefill_size is not None 
        and server_args.disable_radix_cache):
        if self.is_hybrid:
            ChunkCacheClass = SWAChunkCache
        else:
            ChunkCacheClass = ChunkCache
        self.tree_cache = ChunkCacheClass(
            req_to_token_pool=self.req_to_token_pool,
            token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
            page_size=self.page_size,
        )
    else:
        # 实验性的C++实现RadixCache
        if os.environ.get("SGLANG_EXPERIMENTAL_CPP_RADIX_TREE") == "1":
            from sglang.srt.mem_cache.radix_cache_cpp import RadixCacheCpp
            self.tree_cache = RadixCacheCpp(
                disable=False,
                use_hicache=self.enable_hierarchical_cache,
                req_to_token_pool=self.req_to_token_pool,
                token_to_kv_pool=self.token_to_kv_pool_allocator,
                tp_cache_group=self.tp_cpu_group,
                page_size=self.page_size,
                hicache_ratio=server_args.hicache_ratio,
                hicache_size=server_args.hicache_size,
                hicache_write_policy=server_args.hicache_write_policy,
                enable_kv_cache_events=self.enable_kv_cache_events,
            )
        # 标准Python实现的RadixCache
        else:
            self.tree_cache = RadixCache(
                req_to_token_pool=self.req_to_token_pool,
                token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
                page_size=self.page_size,
                disable=False,
                enable_kv_cache_events=self.enable_kv_cache_events,
            )
```

## ReqToTokenPool - 请求到Token映射池

`ReqToTokenPool`负责管理请求ID到其token位置的映射关系：

```python
class ReqToTokenPool:
    """A memory pool that maps a request to its token locations."""

    def __init__(self, size: int, max_context_len: int, device: str, enable_memory_saver: bool):
        memory_saver_adapter = TorchMemorySaverAdapter.create(enable=enable_memory_saver)
        
        self.size = size
        self.max_context_len = max_context_len
        self.device = device
        
        # 预分配固定大小的二维张量存储请求的token位置
        with memory_saver_adapter.region(GPU_MEMORY_TYPE_KV_CACHE):
            self.req_to_token = torch.zeros(
                (size, max_context_len), dtype=torch.int32, device=device
            )
        
        # 使用简单的列表管理可用槽位
        self.free_slots = list(range(size))

    def alloc(self, need_size: int) -> List[int]:
        """分配指定数量的槽位"""
        if need_size > len(self.free_slots):
            return None
        
        select_index = self.free_slots[:need_size]
        self.free_slots = self.free_slots[need_size:]
        return select_index

    def free(self, free_index: Union[int, List[int]]):
        """释放槽位"""
        if isinstance(free_index, (int,)):
            self.free_slots.append(free_index)
        else:
            self.free_slots.extend(free_index)

    def available_size(self):
        """返回可用槽位数量"""
        return len(self.free_slots)
        
    def write(self, indices, values):
        """写入token位置映射"""
        self.req_to_token[indices] = values
        
    def clear(self):
        """清空所有分配，重置为初始状态"""
        self.free_slots = list(range(self.size))
```

## KV缓存分配器

### BaseTokenToKVPoolAllocator基类

所有KV缓存分配器的基类，定义了基本的分配接口：

```python
class BaseTokenToKVPoolAllocator(abc.ABC):
    def __init__(self, size: int, page_size: int, dtype: torch.dtype, 
                 device: str, kvcache: KVCache, need_sort: bool):
        self.size = size
        self.page_size = page_size
        self.dtype = dtype
        self.device = device
        self._kvcache = kvcache
        self.need_sort = need_sort

        self.free_pages = None
        self.release_pages = None
        self.is_not_in_free_group = True
        self.free_group = []

    def available_size(self):
        """返回可用的token数量"""
        return (len(self.free_pages) + len(self.release_pages)) * self.page_size

    def backup_state(self):
        """备份当前状态"""
        return (self.free_pages, self.release_pages)

    def restore_state(self, state):
        """恢复状态"""
        self.free_pages, self.release_pages = state
```

### TokenToKVPoolAllocator实现

标准的token到KV pool分配器：

```python
class TokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):
    """An allocator managing the indices to kv cache data."""

    def __init__(self, size: int, dtype: torch.dtype, device: str, 
                 kvcache: KVCache, need_sort: bool):
        super().__init__(size, 1, dtype, device, kvcache, need_sort)
        self.clear()

    def clear(self):
        """清空分配器，重置所有页面为可用状态"""
        # 页面0用于填充，从1开始分配
        self.free_pages = torch.arange(
            1, self.size + 1, dtype=torch.int64, device=self.device
        )
        self.is_not_in_free_group = True
        self.free_group = []
        self.release_pages = torch.empty((0,), dtype=torch.int64, device=self.device)

    def alloc(self, need_size: int):
        """分配指定数量的token槽位"""
        if self.need_sort and need_size > len(self.free_pages):
            self.merge_and_sort_free()

        if need_size > len(self.free_pages):
            return None

        select_index = self.free_pages[:need_size]
        self.free_pages = self.free_pages[need_size:]
        return select_index

    def free(self, free_index: torch.Tensor):
        """释放token槽位"""
        if free_index.numel() == 0:
            return

        if self.is_not_in_free_group:
            if self.need_sort:
                self.release_pages = torch.cat((self.release_pages, free_index))
            else:
                self.free_pages = torch.cat((self.free_pages, free_index))
        else:
            self.free_group.append(free_index)
```

## 前缀缓存系统

### RadixCache实现

标准的前缀缓存实现，基于基数树数据结构：

```python
class RadixCache(BasePrefixCache):
    def __init__(self, req_to_token_pool: ReqToTokenPool,
                 token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,
                 page_size: int, disable: bool = False,
                 enable_kv_cache_events: bool = False):
        self.req_to_token_pool = req_to_token_pool
        self.token_to_kv_pool_allocator = token_to_kv_pool_allocator
        self.page_size = page_size
        self.disable = disable
        self.enable_kv_cache_events = enable_kv_cache_events
        self.kv_event_queue = []

        # 根据page_size选择匹配函数
        if self.page_size == 1:
            self.key_match_fn = _key_match_page_size1
            self.get_child_key_fn = lambda key: key[0]
        else:
            self.key_match_fn = partial(_key_match_paged, page_size=page_size)
            self.get_child_key_fn = lambda key: tuple(key[:page_size])
        self.reset()

    def reset(self):
        """重置缓存树"""
        self.root_node = TreeNode()
        self.root_node.key = []
        self.root_node.value = []
        self.root_node.lock_ref = 1
        self.evictable_size_ = 0
        self.protected_size_ = 0

    def match_prefix(self, key: List[int], **kwargs) -> MatchResult:
        """匹配最长公共前缀"""
        # 实际的前缀匹配逻辑在这里实现
        pass
```

### ChunkCache实现

用于分块预填充时的简化缓存：

```python
class ChunkCache(BasePrefixCache):
    def __init__(self, req_to_token_pool: ReqToTokenPool,
                 token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,
                 page_size: int):
        self.req_to_token_pool = req_to_token_pool
        self.token_to_kv_pool_allocator = token_to_kv_pool_allocator
        self.page_size = page_size

    def match_prefix(self, **unused_kwargs) -> MatchResult:
        """ChunkCache不执行前缀匹配，总是返回空结果"""
        return MatchResult(
            device_indices=torch.empty((0,), dtype=torch.int64),
            last_device_node=None,
            last_host_node=None,
        )

    def cache_finished_req(self, req: Req):
        """缓存已完成的请求"""
        kv_indices = self.req_to_token_pool.req_to_token[
            req.req_pool_idx,
            : len(req.origin_input_ids) + max(len(req.output_ids) - 1, 0),
        ]
        self.req_to_token_pool.free(req.req_pool_idx)
        self.token_to_kv_pool_allocator.free(kv_indices)

    def cache_unfinished_req(self, req: Req):
        """缓存未完成的请求"""
        kv_indices = self.req_to_token_pool.req_to_token[
            req.req_pool_idx, : len(req.fill_ids)
        ]
        req.prefix_indices = kv_indices
```

## 内存检查机制

调度器提供了简单的内存检查功能：

```python
def check_memory(self):
    """检查内存使用状态"""
    available_token_pool = self.req_to_token_pool.available_size()
    available_kv_cache = self.token_to_kv_pool_allocator.available_size()
    
    logger.info(f"Token pool available: {available_token_pool}")
    logger.info(f"KV cache available: {available_kv_cache}")
    
    if available_token_pool < 10 or available_kv_cache < 100:
        logger.warning("Memory pool running low")
```

## 总结

SGLang的内存管理系统通过以下几个核心组件实现：

1. **ReqToTokenPool**: 管理请求到token位置的映射
2. **TokenToKVPoolAllocator**: 管理KV缓存的分配和释放
3. **RadixCache/ChunkCache**: 提供前缀缓存功能
4. **简单的内存检查**: 监控内存使用状态

这个设计注重简洁性和实用性，避免了过度复杂的内存管理策略，专注于高效的GPU内存利用。