# 内存和资源管理

SGLang调度器的内存和资源管理通过内存池、KV缓存分配器和前缀缓存机制来实现高效的GPU内存利用。

## 内存池初始化

调度器通过`init_memory_pool_and_cache()`方法初始化内存管理组件：

```python
def init_memory_pool_and_cache(self):
    server_args = self.server_args

    # 从tensor parallel worker获取内存池
    self.req_to_token_pool, self.token_to_kv_pool_allocator = (
        self.tp_worker.get_memory_pool()
    )

    # 根据配置选择缓存实现
    if (server_args.chunked_prefill_size is not None 
        and server_args.disable_radix_cache):
        if self.is_hybrid:
            ChunkCacheClass = SWAChunkCache
        else:
            ChunkCacheClass = ChunkCache
        self.tree_cache = ChunkCacheClass(
            req_to_token_pool=self.req_to_token_pool,
            token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
            page_size=self.page_size,
        )
    else:
        # 实验性的C++实现RadixCache
        if os.environ.get("SGLANG_EXPERIMENTAL_CPP_RADIX_TREE") == "1":
            from sglang.srt.mem_cache.radix_cache_cpp import RadixCacheCpp
            self.tree_cache = RadixCacheCpp(
                disable=False,
                use_hicache=self.enable_hierarchical_cache,
                req_to_token_pool=self.req_to_token_pool,
                token_to_kv_pool=self.token_to_kv_pool_allocator,
                tp_cache_group=self.tp_cpu_group,
                page_size=self.page_size,
                hicache_ratio=server_args.hicache_ratio,
                hicache_size=server_args.hicache_size,
                hicache_write_policy=server_args.hicache_write_policy,
                enable_kv_cache_events=self.enable_kv_cache_events,
            )
        # 标准Python实现的RadixCache
        else:
            self.tree_cache = RadixCache(
                req_to_token_pool=self.req_to_token_pool,
                token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
                page_size=self.page_size,
                disable=False,
                enable_kv_cache_events=self.enable_kv_cache_events,
            )
```

## ReqToTokenPool - 请求到Token映射池

`ReqToTokenPool`负责管理请求ID到其token位置的映射关系：

```python
class ReqToTokenPool:
    """A memory pool that maps a request to its token locations."""

    def __init__(self, size: int, max_context_len: int, device: str, enable_memory_saver: bool):
        memory_saver_adapter = TorchMemorySaverAdapter.create(enable=enable_memory_saver)
        
        self.size = size
        self.max_context_len = max_context_len
        self.device = device
        
        # 预分配固定大小的二维张量存储请求的token位置
        with memory_saver_adapter.region(GPU_MEMORY_TYPE_KV_CACHE):
            self.req_to_token = torch.zeros(
                (size, max_context_len), dtype=torch.int32, device=device
            )
        
        # 使用简单的列表管理可用槽位
        self.free_slots = list(range(size))

    def alloc(self, need_size: int) -> List[int]:
        """分配指定数量的槽位"""
        if need_size > len(self.free_slots):
            return None
        
        select_index = self.free_slots[:need_size]
        self.free_slots = self.free_slots[need_size:]
        return select_index

    def free(self, free_index: Union[int, List[int]]):
        """释放槽位"""
        if isinstance(free_index, (int,)):
            self.free_slots.append(free_index)
        else:
            self.free_slots.extend(free_index)

    def available_size(self):
        """返回可用槽位数量"""
        return len(self.free_slots)
        
    def write(self, indices, values):
        """写入token位置映射"""
        self.req_to_token[indices] = values
        
    def clear(self):
        """清空所有分配，重置为初始状态"""
        self.free_slots = list(range(self.size))
```

## KV缓存分配器

### BaseTokenToKVPoolAllocator基类

所有KV缓存分配器的基类，定义了基本的分配接口：

```python
class BaseTokenToKVPoolAllocator(abc.ABC):
    def __init__(self, size: int, page_size: int, dtype: torch.dtype, 
                 device: str, kvcache: KVCache, need_sort: bool):
        self.size = size
        self.page_size = page_size
        self.dtype = dtype
        self.device = device
        self._kvcache = kvcache
        self.need_sort = need_sort

        self.free_pages = None
        self.release_pages = None
        self.is_not_in_free_group = True
        self.free_group = []

    def available_size(self):
        """返回可用的token数量"""
        return (len(self.free_pages) + len(self.release_pages)) * self.page_size

    def backup_state(self):
        """备份当前状态"""
        return (self.free_pages, self.release_pages)

    def restore_state(self, state):
        """恢复状态"""
        self.free_pages, self.release_pages = state
```

### TokenToKVPoolAllocator实现

标准的token到KV pool分配器：

```python
class TokenToKVPoolAllocator(BaseTokenToKVPoolAllocator):
    """An allocator managing the indices to kv cache data."""

    def __init__(self, size: int, dtype: torch.dtype, device: str, 
                 kvcache: KVCache, need_sort: bool):
        super().__init__(size, 1, dtype, device, kvcache, need_sort)
        self.clear()

    def clear(self):
        """清空分配器，重置所有页面为可用状态"""
        # 页面0用于填充，从1开始分配
        self.free_pages = torch.arange(
            1, self.size + 1, dtype=torch.int64, device=self.device
        )
        self.is_not_in_free_group = True
        self.free_group = []
        self.release_pages = torch.empty((0,), dtype=torch.int64, device=self.device)

    def alloc(self, need_size: int):
        """分配指定数量的token槽位"""
        if self.need_sort and need_size > len(self.free_pages):
            self.merge_and_sort_free()

        if need_size > len(self.free_pages):
            return None

        select_index = self.free_pages[:need_size]
        self.free_pages = self.free_pages[need_size:]
        return select_index

    def free(self, free_index: torch.Tensor):
        """释放token槽位"""
        if free_index.numel() == 0:
            return

        if self.is_not_in_free_group:
            if self.need_sort:
                self.release_pages = torch.cat((self.release_pages, free_index))
            else:
                self.free_pages = torch.cat((self.free_pages, free_index))
        else:
            self.free_group.append(free_index)
```

## 前缀缓存系统

### RadixCache实现

标准的前缀缓存实现，基于基数树数据结构：

```python
class RadixCache(BasePrefixCache):
    def __init__(self, req_to_token_pool: ReqToTokenPool,
                 token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,
                 page_size: int, disable: bool = False,
                 enable_kv_cache_events: bool = False):
        self.req_to_token_pool = req_to_token_pool
        self.token_to_kv_pool_allocator = token_to_kv_pool_allocator
        self.page_size = page_size
        self.disable = disable
        self.enable_kv_cache_events = enable_kv_cache_events
        self.kv_event_queue = []

        # 根据page_size选择匹配函数
        if self.page_size == 1:
            self.key_match_fn = _key_match_page_size1
            self.get_child_key_fn = lambda key: key[0]
        else:
            self.key_match_fn = partial(_key_match_paged, page_size=page_size)
            self.get_child_key_fn = lambda key: tuple(key[:page_size])
        self.reset()

    def reset(self):
        """重置缓存树"""
        self.root_node = TreeNode()
        self.root_node.key = []
        self.root_node.value = []
        self.root_node.lock_ref = 1
        self.evictable_size_ = 0
        self.protected_size_ = 0

    def match_prefix(self, key: List[int], **kwargs) -> MatchResult:
        """匹配最长公共前缀"""
        # 实际的前缀匹配逻辑在这里实现
        pass
```

### ChunkCache实现

用于分块预填充时的简化缓存：

```python
class ChunkCache(BasePrefixCache):
    def __init__(self, req_to_token_pool: ReqToTokenPool,
                 token_to_kv_pool_allocator: BaseTokenToKVPoolAllocator,
                 page_size: int):
        self.req_to_token_pool = req_to_token_pool
        self.token_to_kv_pool_allocator = token_to_kv_pool_allocator
        self.page_size = page_size

    def match_prefix(self, **unused_kwargs) -> MatchResult:
        """ChunkCache不执行前缀匹配，总是返回空结果"""
        return MatchResult(
            device_indices=torch.empty((0,), dtype=torch.int64),
            last_device_node=None,
            last_host_node=None,
        )

    def cache_finished_req(self, req: Req):
        """缓存已完成的请求"""
        kv_indices = self.req_to_token_pool.req_to_token[
            req.req_pool_idx,
            : len(req.origin_input_ids) + max(len(req.output_ids) - 1, 0),
        ]
        self.req_to_token_pool.free(req.req_pool_idx)
        self.token_to_kv_pool_allocator.free(kv_indices)

    def cache_unfinished_req(self, req: Req):
        """缓存未完成的请求"""
        kv_indices = self.req_to_token_pool.req_to_token[
            req.req_pool_idx, : len(req.fill_ids)
        ]
        req.prefix_indices = kv_indices
```

## 混合缓存架构

SGLang支持SWA (Sliding Window Attention) 混合缓存架构，允许模型同时使用全注意力和滑动窗口注意力机制：

### SWA混合缓存初始化

```python
def init_memory_pool_and_cache(self):
    """初始化内存池，支持混合缓存模式"""
    server_args = self.server_args

    # 从tensor parallel worker获取内存池
    self.req_to_token_pool, self.token_to_kv_pool_allocator = (
        self.tp_worker.get_memory_pool()
    )

    # 检查是否为混合模式
    self.is_hybrid = isinstance(
        self.token_to_kv_pool_allocator, SWATokenToKVPoolAllocator
    )

    # 根据配置选择缓存实现
    if (server_args.chunked_prefill_size is not None 
        and server_args.disable_radix_cache):
        if self.is_hybrid:
            ChunkCacheClass = SWAChunkCache  # SWA分块缓存
        else:
            ChunkCacheClass = ChunkCache     # 标准分块缓存
        self.tree_cache = ChunkCacheClass(
            req_to_token_pool=self.req_to_token_pool,
            token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
            page_size=self.page_size,
        )
    else:
        if self.is_hybrid:
            self.tree_cache = SWARadixCache(  # SWA基数缓存
                req_to_token_pool=self.req_to_token_pool,
                token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
                page_size=self.page_size,
                disable=False,
            )
        else:
            self.tree_cache = RadixCache(     # 标准基数缓存
                req_to_token_pool=self.req_to_token_pool,
                token_to_kv_pool_allocator=self.token_to_kv_pool_allocator,
                page_size=self.page_size,
                disable=False,
            )
```

### SWA Token信息获取

```python
def _get_swa_token_info(self):
    """获取SWA混合缓存的token使用信息"""
    full_available_size = self.token_to_kv_pool_allocator.full_available_size()
    full_evictable_size = self.tree_cache.full_evictable_size()
    swa_available_size = self.token_to_kv_pool_allocator.swa_available_size()
    swa_evictable_size = self.tree_cache.swa_evictable_size()
    
    full_num_used = self.full_tokens_per_layer - (full_available_size + full_evictable_size)
    swa_num_used = self.swa_tokens_per_layer - (swa_available_size + swa_evictable_size)
    
    full_token_usage = full_num_used / self.full_tokens_per_layer
    swa_token_usage = swa_num_used / self.swa_tokens_per_layer
    
    return (
        full_num_used, swa_num_used, full_token_usage, swa_token_usage,
        full_available_size, full_evictable_size, 
        swa_available_size, swa_evictable_size
    )
```

## 内存检查机制

调度器提供了全面的内存检查功能，支持混合缓存：

```python
def check_memory(self):
    """检查内存泄漏和状态一致性"""
    
    if self.is_hybrid:
        # 混合缓存的内存检查
        (full_num_used, swa_num_used, _, _,
         full_available_size, full_evictable_size,
         swa_available_size, swa_evictable_size) = self._get_swa_token_info()
        
        memory_leak = full_num_used != 0 or swa_num_used != 0
        token_msg = (
            f"{self.full_tokens_per_layer=}, {full_available_size=}, {full_evictable_size=}, "
            f"{self.tree_cache.full_protected_size()=}\n"
            f"{self.swa_tokens_per_layer=}, {swa_available_size=}, {swa_evictable_size=}, "
            f"{self.tree_cache.swa_protected_size()=}\n"
        )
    else:
        # 标准缓存的内存检查
        _, _, available_size, evictable_size = self._get_token_info()
        protected_size = self.tree_cache.protected_size()
        memory_leak = (available_size + evictable_size) != (
            self.max_total_num_tokens
            if not self.enable_hierarchical_cache
            else self.max_total_num_tokens - protected_size
        )
        token_msg = f"{self.max_total_num_tokens=}, {available_size=}, {evictable_size=}, {protected_size=}\n"
    
    # 检测到内存泄漏时抛出异常
    if memory_leak:
        msg = "token_to_kv_pool_allocator memory leak detected! " f"{token_msg}"
        raise ValueError(msg)
    
    # 检查请求池内存泄漏
    if self.disaggregation_mode == DisaggregationMode.DECODE:
        req_total_size = (
            self.req_to_token_pool.size + self.req_to_token_pool.pre_alloc_size
        )
    else:
        req_total_size = self.req_to_token_pool.size
    
    if len(self.req_to_token_pool.free_slots) != req_total_size:
        msg = (
            "req_to_token_pool memory leak detected!"
            f"available_size={len(self.req_to_token_pool.free_slots)}, "
            f"total_size={self.req_to_token_pool.size}\n"
        )
        raise ValueError(msg)
```

## 总结

SGLang的内存管理系统通过以下几个核心组件实现：

1. **ReqToTokenPool**: 管理请求到token位置的映射
2. **TokenToKVPoolAllocator**: 管理KV缓存的分配和释放，支持标准和SWA混合模式
3. **RadixCache/ChunkCache**: 提供前缀缓存功能，支持SWA混合缓存架构
4. **全面的内存检查**: 监控内存泄漏和状态一致性，支持混合缓存模式
5. **SWA混合缓存**: 支持滑动窗口注意力的混合缓存架构

这个设计既保持了简洁性和实用性，又支持了先进的混合注意力机制，确保在不同场景下都能高效利用GPU内存。