# 调度器监控与调试

SGLang调度器提供了基础的监控和调试功能，通过指标收集、性能分析和内存检查，帮助开发者了解系统状态和排查问题。本章基于真实源码解析这些功能。

## 性能指标体系

### SchedulerMetricsMixin核心指标

根据`scheduler_metrics_mixin.py`的实际实现，调度器收集以下核心指标：

```python
class SchedulerMetricsMixin:
    def init_metrics(self, tp_rank: int, pp_rank: int, dp_rank: Optional[int]):
        """初始化指标收集系统"""
        self.last_gen_throughput: float = 0.0          # 最近生成吞吐量
        self.last_input_throughput: float = 0.0        # 最近输入吞吐量
        self.step_time_dict = defaultdict(list)         # 批次大小 -> 步骤时间映射
        self.spec_num_total_accepted_tokens = 0         # 投机解码接受token总数
        self.spec_num_total_forward_ct = 0              # 投机解码前向计算次数
        self.cum_spec_accept_length = 0                 # 累计投机接受长度
        self.cum_spec_accept_count = 0                  # 累计投机接受次数
        self.total_retracted_reqs = 0                   # 总回退请求数
        self.stats = SchedulerStats()                   # 详细统计信息
        
        # 如果启用指标收集，创建收集器
        if self.enable_metrics:
            engine_type = "unified"
            labels = {
                "model_name": self.server_args.served_model_name,
                "engine_type": engine_type,
                "tp_rank": tp_rank,
                "pp_rank": pp_rank,
            }
            if dp_rank is not None:
                labels["dp_rank"] = dp_rank
            self.metrics_collector = SchedulerMetricsCollector(labels=labels)
```

### KV缓存事件监控

```python
def init_kv_events(self, kv_events_config: Optional[str]):
    """初始化KV缓存事件监控"""
    if self.enable_kv_cache_events:
        self.kv_event_publisher = EventPublisherFactory.create(
            kv_events_config, self.attn_dp_rank
        )
```

## 统计信息记录

### 预填充阶段统计

```python
def log_prefill_stats(self, adder: PrefillAdder, can_run_list: List[Req], running_bs: int):
    """记录预填充阶段的统计信息"""
    
    # 计算可以运行的请求数量和token数
    num_can_run_reqs = len(can_run_list)
    num_new_tokens = sum(req.extend_input_len for req in can_run_list)
    
    # 计算新token比例
    if adder.cur_rem_tokens != 0:
        new_token_ratio = num_new_tokens / adder.cur_rem_tokens
    else:
        new_token_ratio = 0.0
    
    # 构建日志消息
    running_reqs_info = ""
    if running_bs > 0:
        running_reqs_info = f", #running_reqs: {running_bs}"
    
    msg = (
        f"#queue_req: {len(self.waiting_queue)}, "
        f"#can_run_req: {num_can_run_reqs}, "
        f"#new_token: {num_new_tokens}, "
        f"new_token_ratio: {new_token_ratio:.3f}"
        f"{running_reqs_info}"
    )
    
    logger.info(msg)
```

### 解码阶段统计

```python
def log_decode_stats(self, can_run_cuda_graph: bool, running_batch: ScheduleBatch = None):
    """记录解码阶段的统计信息"""
    
    # 获取运行中的请求信息
    running_batch = running_batch or self.running_batch
    num_running_reqs = len(running_batch.reqs)
    
    if num_running_reqs == 0:
        return
    
    # 计算token使用情况
    if hasattr(self, '_get_token_info'):
        if self.is_hybrid:
            # 处理混合缓存情况
            (full_num_used, swa_num_used, _, _, 
             full_available_size, full_evictable_size,
             swa_available_size, swa_evictable_size) = self._get_swa_token_info()
            num_used = full_num_used + swa_num_used
            available_size = full_available_size + swa_available_size
        else:
            num_used, _, available_size, evictable_size = self._get_token_info()
    else:
        num_used = available_size = 0
    
    # 计算token使用率
    if self.max_total_num_tokens > 0:
        token_usage = num_used / self.max_total_num_tokens
    else:
        token_usage = 0.0
    
    # 计算投机解码接受长度
    if self.cum_spec_accept_count > 0:
        spec_accept_length = self.cum_spec_accept_length / self.cum_spec_accept_count
    else:
        spec_accept_length = 0.0
    
    # 构建详细的状态信息
    msg_parts = [
        f"#running_req: {num_running_reqs}",
        f"#queue_req: {len(self.waiting_queue)}",
        f"#token: {num_used}",
        f"token_usage: {token_usage:.3f}",
        f"gen_throughput: {self.last_gen_throughput:.3f} token/s",
    ]
    
    if hasattr(self, 'grammar_queue'):
        msg_parts.append(f"#grammar_queue_req: {len(self.grammar_queue)}")
    
    if spec_accept_length > 0:
        msg_parts.append(f"spec_accept_length: {spec_accept_length:.3f}")
    
    if can_run_cuda_graph:
        msg_parts.append("cuda_graph: True")
    
    msg = ", ".join(msg_parts)
    logger.info(msg)
    
    # 更新统计信息
    if self.enable_metrics:
        self.stats.num_running_reqs = num_running_reqs
        self.stats.num_used_tokens = num_used
        self.stats.token_usage = round(token_usage, 2)
        self.stats.cache_hit_rate = 0.0  # TODO: 实际计算缓存命中率
        self.stats.gen_throughput = self.last_gen_throughput
        self.stats.num_queue_reqs = len(self.waiting_queue)
        if hasattr(self, 'grammar_queue'):
            self.stats.num_grammar_queue_reqs = len(self.grammar_queue)
        self.stats.spec_accept_length = spec_accept_length
        self.stats.total_retracted_reqs = self.total_retracted_reqs
        
        # 发送指标到收集器
        self.metrics_collector.log_stats(self.stats)
        
        # 处理分离式架构的额外指标
        if self.disaggregation_mode == DisaggregationMode.DECODE:
            self.stats.num_decode_prealloc_queue_reqs = len(
                self.disagg_decode_prealloc_queue.queue
            )
            self.stats.num_decode_transfer_queue_reqs = len(
                self.disagg_decode_transfer_queue.queue
            )
        
        # 发送KV指标
        self._emit_kv_metrics()
    
    # 发布KV事件
    self._publish_kv_events()
```

### KV指标发送

```python
def _emit_kv_metrics(self):
    """发送KV缓存相关指标"""
    kv_metrics = KvMetrics()
    kv_metrics.request_active_slots = self.stats.num_running_reqs
    kv_metrics.request_total_slots = self.max_running_requests
    kv_metrics.kv_active_blocks = int(
        self.stats.token_usage * self.max_total_num_tokens
    )
    kv_metrics.kv_total_blocks = self.max_total_num_tokens
    kv_metrics.num_requests_waiting = self.stats.num_queue_reqs
    kv_metrics.gpu_cache_usage_perc = self.stats.token_usage
    kv_metrics.gpu_prefix_cache_hit_rate = self.stats.cache_hit_rate
    kv_metrics.data_parallel_rank = self.dp_rank if self.dp_rank is not None else 0
    
    # 通过IPC发送指标
    if not self.send_metrics_from_scheduler.closed:
        self.send_metrics_from_scheduler.send_pyobj(kv_metrics)
```

## 性能分析工具

### SchedulerProfilerMixin

调度器集成了PyTorch Profiler用于性能分析：

```python
class SchedulerProfilerMixin:
    def init_profier(self):
        """初始化profiler相关变量"""
        self.torch_profiler = None
        self.torch_profiler_output_dir: Optional[str] = None
        self.profiler_activities: Optional[List[str]] = None
        self.profile_id: Optional[str] = None
        self.profiler_start_forward_ct: Optional[int] = None
        self.profiler_target_forward_ct: Optional[int] = None
        self.profiler_target_prefill_ct: Optional[int] = None
        self.profiler_target_decode_ct: Optional[int] = None
        self.profiler_prefill_ct: Optional[int] = None
        self.profiler_decode_ct: Optional[int] = None
        self.profile_by_stage: bool = False
        self.profile_steps: Optional[int] = None
        self.profile_in_progress: bool = False
        self.rpd_profiler = None
```

### 性能分析配置

```python
def init_profile(self, output_dir: Optional[str], start_step: Optional[int],
                num_steps: Optional[int], activities: Optional[List[str]],
                with_stack: Optional[bool], record_shapes: Optional[bool],
                profile_by_stage: bool, profile_id: str) -> ProfileReqOutput:
    """初始化性能分析配置"""
    
    if self.profile_in_progress:
        return ProfileReqOutput(
            success=False,
            message="Profiling is already in progress. Call /stop_profile first.",
        )
    
    self.profile_by_stage = profile_by_stage
    
    # 设置默认值
    if output_dir is None:
        output_dir = os.getenv("SGLANG_TORCH_PROFILER_DIR", "/tmp")
    if activities is None:
        activities = ["CPU", "GPU"]
    
    # 保存配置
    self.torch_profiler_output_dir = output_dir
    self.torch_profiler_with_stack = with_stack
    self.torch_profiler_record_shapes = record_shapes
    self.profiler_activities = activities
    self.profile_id = profile_id
    
    # 设置开始步骤
    if start_step:
        self.profiler_start_forward_ct = max(start_step, self.forward_ct + 1)
    
    # 设置分析步数
    if num_steps:
        self.profile_steps = num_steps
        if self.profile_by_stage:
            self.profiler_target_prefill_ct = num_steps
            self.profiler_target_decode_ct = num_steps
            self.profiler_prefill_ct = 0
            self.profiler_decode_ct = 0
        elif start_step:
            self.profiler_target_forward_ct = (
                self.profiler_start_forward_ct + num_steps
            )
        else:
            self.profiler_target_forward_ct = self.forward_ct + num_steps
    else:
        self.profiler_target_forward_ct = None
    
    return ProfileReqOutput(success=True, message="Succeeded")
```

## 系统状态检查

### 内存泄漏检测

调度器提供了实际的内存检查功能：

```python
def check_memory(self):
    """检查内存泄漏和状态一致性"""
    
    if self.is_hybrid:
        # 混合缓存的内存检查
        (full_num_used, swa_num_used, _, _,
         full_available_size, full_evictable_size,
         swa_available_size, swa_evictable_size) = self._get_swa_token_info()
        
        memory_leak = full_num_used != 0 or swa_num_used != 0
        token_msg = (
            f"{self.full_tokens_per_layer=}, {full_available_size=}, {full_evictable_size=}, "
            f"{self.tree_cache.full_protected_size()=}\n"
            f"{self.swa_tokens_per_layer=}, {swa_available_size=}, {swa_evictable_size=}, "
            f"{self.tree_cache.swa_protected_size()=}\n"
        )
    else:
        # 标准缓存的内存检查
        _, _, available_size, evictable_size = self._get_token_info()
        protected_size = self.tree_cache.protected_size()
        memory_leak = (available_size + evictable_size) != (
            self.max_total_num_tokens
            if not self.enable_hierarchical_cache
            else self.max_total_num_tokens - protected_size
        )
        token_msg = f"{self.max_total_num_tokens=}, {available_size=}, {evictable_size=}, {protected_size=}\n"
    
    # 检测到内存泄漏时抛出异常
    if memory_leak:
        msg = "token_to_kv_pool_allocator memory leak detected! " f"{token_msg}"
        raise ValueError(msg)
    
    # 检查请求池内存泄漏
    if self.disaggregation_mode == DisaggregationMode.DECODE:
        req_total_size = (
            self.req_to_token_pool.size + self.req_to_token_pool.pre_alloc_size
        )
    else:
        req_total_size = self.req_to_token_pool.size
    
    if len(self.req_to_token_pool.free_slots) != req_total_size:
        msg = (
            "req_to_token_pool memory leak detected!"
            f"available_size={len(self.req_to_token_pool.free_slots)}, "
            f"total_size={self.req_to_token_pool.size}\n"
        )
        raise ValueError(msg)
```

### 调度器状态查询

```python
def current_scheduler_metrics_enabled(self):
    """检查当前调度器是否启用指标收集"""
    return self.attn_tp_rank == 0 or self.enable_metrics_for_all_schedulers

def get_print_prefix(self):
    """获取日志打印前缀"""
    prefix = ""
    if self.attn_dp_rank is not None:
        prefix += f" DP{self.attn_dp_rank}"
    if self.server_args.tp_size > 1:
        prefix += f" TP{self.tp_rank}"
    if self.pp_size > 1:
        prefix += f" PP{self.pp_rank}"
    return prefix
```

## 空闲时的系统维护

### 空闲检查机制

```python
def self_check_during_idle(self):
    """系统空闲时的自检和维护"""
    
    # 执行内存检查
    self.check_memory()
    
    # 如果有空闲睡眠器，可能进入睡眠节能模式
    self.maybe_sleep_on_idle()

def maybe_sleep_on_idle(self):
    """空闲时可能进入睡眠状态以节省CPU"""
    if self.idle_sleeper is not None:
        self.idle_sleeper.maybe_sleep()
```

### IdleSleeper节能机制

```python
class IdleSleeper:
    """
    在长时间不活跃期间，通过减少系统功耗来节能。
    这不仅能节省电力，还能在请求到来时提供更多的CPU热容量。
    这在多GPU连接的情况下特别重要，否则每个GPU都会让一个线程100%占用CPU。
    
    最简单的解决方案是在所有可能接收需要立即处理数据的socket上使用zmq.Poller。
    """
    pass  # 具体实现在类中
```

## 调试和问题排查

### 环境变量控制

SGLang提供了多个环境变量来控制调试行为：

```python
# 记录步骤时间
RECORD_STEP_TIME = get_bool_env_var("SGLANG_RECORD_STEP_TIME")

# Profiler输出目录
output_dir = os.getenv("SGLANG_TORCH_PROFILER_DIR", "/tmp")
```

### 垃圾回收控制

```python
def handle_freeze_gc(self, recv_req: FreezeGCReq):
    """处理冻结GC请求：冻结调度器的GC并转发到detokenizer"""
    freeze_gc("Scheduler")
    self.send_to_detokenizer.send_pyobj(recv_req)
    return None
```

## 总结

SGLang调度器的监控与调试系统具有以下实际特性：

**基础指标收集**: 通过SchedulerMetricsMixin收集吞吐量、token使用率、队列长度等关键指标。

**性能分析集成**: 集成PyTorch Profiler，支持CPU/GPU活动分析、内存分析等。

**内存泄漏检测**: 提供实际的内存一致性检查，能够检测token池和请求池的内存泄漏。

**状态日志**: 详细的预填充和解码阶段统计日志，便于性能分析和问题排查。

**节能机制**: 在空闲期间通过IdleSleeper机制减少CPU占用，适合多GPU部署。

**IPC指标传输**: 通过进程间通信将指标发送到上层组件，支持分布式监控。

这些功能虽然相对简洁，但提供了生产环境所需的基本监控和调试能力。