# 请求处理机制

---

SGLang调度器通过结构化的请求处理流程来管理各种类型的请求。本章介绍调度器的请求接收、分发和处理机制。

---

## 1. 请求接收流程

### 1.1 recv_requests方法

**网络请求接收的核心机制**：调度器通过`recv_requests()`方法从tokenizer接收请求，采用非阻塞模式确保高效的批量接收。

> 📝 **简化说明**：以下为请求接收的核心逻辑简化版本，突出非阻塞接收机制。真实实现包含TP广播、流水线处理和接收跳过器等复杂逻辑。

```python
def recv_requests(self) -> List[Req]:
    """接收来自tokenizer的请求（简化版）"""
    recv_reqs = []
    
    # 使用非阻塞方式接收请求
    while True:
        try:
            recv_req = self.recv_from_tokenizer.recv_pyobj(zmq.NOBLOCK)
            recv_reqs.append(recv_req)
        except zmq.ZMQError:
            break
    
    return recv_reqs
```

### 1.2 process_input_requests方法

**请求处理的分发和过滤机制**：接收到请求后，调度器通过`process_input_requests()`方法进行处理，包括健康检查过滤、队列容量检查和类型分发等步骤。

> 📝 **简化说明**：以下为请求处理的核心逻辑简化版本，突出分发机制。真实实现包含更多边界情况处理和错误恢复逻辑。

```python
def process_input_requests(self, recv_reqs: List):
    """处理输入请求列表（简化版）"""
    for recv_req in recv_reqs:
        # 健康检查请求的特殊处理
        if is_health_check_generate_req(recv_req) and (
            self.chunked_req is not None
            or not self.running_batch.is_empty()
        ):
            self.return_health_check_ct += 1
            continue

        # 工作请求的队列大小检查
        if is_work_request(recv_req):
            if len(self.waiting_queue) + 1 > self.max_queued_requests:
                abort_req = AbortReq(
                    recv_req.rid,
                    finished_reason={
                        "type": "abort",
                        "status_code": HTTPStatus.SERVICE_UNAVAILABLE,
                        "message": "The request queue is full.",
                    },
                )
                self.send_to_tokenizer.send_pyobj(abort_req)
                continue
                
        # 使用请求分发器处理请求
        output = self._request_dispatcher(recv_req)
        if output is not None:
            if isinstance(output, RpcReqOutput):
                if self.recv_from_rpc is not None:
                    self.recv_from_rpc.send_pyobj(output)
            else:
                self.send_to_tokenizer.send_pyobj(output)
```

---

## 2. 请求分发机制

### 2.1 核心设计概念

```python
# TypeBasedDispatcher的核心概念
self._request_dispatcher = TypeBasedDispatcher([
    (TokenizedGenerateReqInput, self.handle_generate_request),
    (TokenizedEmbeddingReqInput, self.handle_embedding_request),
    (FlushCacheReqInput, self.flush_cache_wrapped),
    (AbortReq, self.abort_request),
    (OpenSessionReqInput, self.open_session),
    (CloseSessionReqInput, self.close_session),
    # ... 更多请求类型映射
])

# 使用方式
for recv_req in recv_reqs:
    output = self._request_dispatcher(recv_req)  # 自动路由到对应处理器
```

### 🔍 源码实现细节

```python
# 真实的调度器请求分发器完整配置
self._request_dispatcher = TypeBasedDispatcher([
    (TokenizedGenerateReqInput, self.handle_generate_request),
    (TokenizedEmbeddingReqInput, self.handle_embedding_request),
    (BatchTokenizedGenerateReqInput, self.handle_batch_generate_request),
    (BatchTokenizedEmbeddingReqInput, self.handle_batch_embedding_request),
    (FlushCacheReqInput, self.flush_cache_wrapped),
    (AbortReq, self.abort_request),
    (OpenSessionReqInput, self.open_session),
    (CloseSessionReqInput, self.close_session),
    (UpdateWeightFromDiskReqInput, self.update_weights_from_disk),
    (InitWeightsUpdateGroupReqInput, self.init_weights_update_group),
    (UpdateWeightsFromDistributedReqInput, self.update_weights_from_distributed),
    (UpdateWeightsFromTensorReqInput, self.update_weights_from_tensor),
    (GetWeightsByNameReqInput, self.get_weights_by_name),
    (ReleaseMemoryOccupationReqInput, self.release_memory_occupation),
    (ResumeMemoryOccupationReqInput, self.resume_memory_occupation),
    (SlowDownReqInput, self.slow_down),
    (ProfileReq, self.profile),
    (FreezeGCReq, self.handle_freeze_gc),
    (GetInternalStateReq, self.get_internal_state),
    (SetInternalStateReq, self.set_internal_state),
    (RpcReqInput, self.handle_rpc_request),
    (ExpertDistributionReq, self.expert_distribution_handle),
    (LoadLoRAAdapterReqInput, self.load_lora_adapter),
    (UnloadLoRAAdapterReqInput, self.unload_lora_adapter),
])

💡 **实现说明**: 真实分发器支持20+种请求类型，从基本的生成/嵌入到高级的权重更新、LoRA管理、系统控制等。TypeBasedDispatcher通过反射机制实现请求类型到处理方法的自动映射。
```

---

## 3. 主要请求类型处理

### 3.1 生成请求处理

#### 3.1.1 核心设计概念

**文本生成请求的处理流程**：handle_generate_request方法负责将外部请求转换为内部Req对象，处理会话管理、参数验证和队列分配等核心逻辑。

> 📝 **简化说明**：以下为生成请求处理的核心步骤简化版本，突出主要流程。真实实现包含更多参数处理和错误检查逻辑。

```python
def handle_generate_request(self, recv_req: TokenizedGenerateReqInput):
    """处理文本生成请求（简化版）"""
    # 创建Req对象
    req = Req(
        recv_req.rid,
        recv_req.input_text,
        recv_req.input_ids,
        recv_req.sampling_params,
        return_logprob=recv_req.return_logprob,
        stream=recv_req.stream,
        lora_id=recv_req.lora_id,
    )
    req.tokenizer = self.tokenizer
    
    # 添加到等待队列
    self.waiting_queue.append(req)
```

#### 🔍 源码实现细节

```python
def handle_generate_request(self, recv_req: TokenizedGenerateReqInput):
    """真实的SGLang生成请求处理实现"""
    
    # 数据并行负载均衡相关
    if (self.server_args.enable_dp_attention 
        and self.server_args.load_balance_method == "minimum_tokens"):
        self.recv_dp_balance_id_this_term.append(recv_req.dp_balance_id)

    # 会话管理：创建新请求或使用现有会话
    if (recv_req.session_params is None 
        or recv_req.session_params.id is None
        or recv_req.session_params.id not in self.sessions):
        
        # 处理输入嵌入的特殊情况
        if recv_req.input_embeds is not None:
            seq_length = len(recv_req.input_embeds)
            fake_input_ids = [1] * seq_length
            recv_req.input_ids = fake_input_ids

        # 分离式架构：设置默认bootstrap端口
        if recv_req.bootstrap_port is None:
            recv_req.bootstrap_port = self.server_args.disaggregation_bootstrap_port

        # 创建新的Req对象，包含所有参数
        req = Req(
            recv_req.rid,
            recv_req.input_text,
            recv_req.input_ids,
            recv_req.sampling_params,
            return_logprob=recv_req.return_logprob,
            top_logprobs_num=recv_req.top_logprobs_num,
            token_ids_logprob=recv_req.token_ids_logprob,
            stream=recv_req.stream,
            origin_input_ids_unpadded=recv_req.origin_input_ids_unpadded,
            lora_id=recv_req.lora_id,
            input_embeds=recv_req.input_embeds,
            token_type_ids=recv_req.token_type_ids,
            session_id=None,
            custom_logit_processor=recv_req.custom_logit_processor,
            return_hidden_states=recv_req.return_hidden_states,
            eos_token_ids=self.model_config.hf_eos_token_id,
            bootstrap_host=recv_req.bootstrap_host,
            bootstrap_port=recv_req.bootstrap_port,
            bootstrap_room=recv_req.bootstrap_room,
            data_parallel_rank=recv_req.data_parallel_rank,
            vocab_size=self.model_config.vocab_size,
        )
        req.tokenizer = self.tokenizer
        
        # 多模态输入处理
        if recv_req.mm_inputs is not None:
            mm_inputs = MultimodalInputs.from_dict(recv_req.mm_inputs)
            req.origin_input_ids = self.pad_input_ids_func(
                req.origin_input_ids, mm_inputs
            )
            req.extend_image_inputs(mm_inputs)

        # 输入长度验证
        error_msg = validate_input_length(
            req,
            self.max_req_input_len,
            self.server_args.allow_auto_truncate,
        )
        if error_msg:
            req.set_finish_with_abort(error_msg)

        # 语法约束处理（JSON Schema、Regex、EBNF）
        self._handle_grammar_constraints(req)
        
        # 添加到相应队列
        if hasattr(req, 'grammar_key'):
            self.grammar_queue.append(req)
        else:
            self._add_request_to_queue(req)
            
    else:
        # 使用现有会话处理请求
        session = self.sessions[recv_req.session_params.id]
        req = session.create_req(recv_req, self.tokenizer)
        if not req.finished:
            self._add_request_to_queue(req)

💡 **实现说明**: 真实的生成请求处理包含会话管理、多模态输入、语法约束、输入验证、分离式架构支持等复杂功能。教学版本突出"输入→Req对象→队列"的核心流程。
```

---

### 🔢 嵌入请求处理

#### 🎯 核心设计概念

```python
def handle_embedding_request(self, recv_req: TokenizedEmbeddingReqInput):
    """处理嵌入请求的核心概念"""
    # 创建嵌入Req对象
    req = Req(
        recv_req.rid,
        recv_req.input_text,
        recv_req.input_ids,
        recv_req.sampling_params,
        token_type_ids=recv_req.token_type_ids,
    )
    req.tokenizer = self.tokenizer
    
    # 添加到等待队列
    self._add_request_to_queue(req)
```

#### 🔍 源码实现细节

```python
def handle_embedding_request(self, recv_req: TokenizedEmbeddingReqInput):
    """真实的SGLang嵌入请求处理实现"""
    req = Req(
        recv_req.rid,
        recv_req.input_text,
        recv_req.input_ids,
        recv_req.sampling_params,
        token_type_ids=recv_req.token_type_ids,
    )
    req.tokenizer = self.tokenizer

    # 多模态输入处理
    if recv_req.image_inputs is not None:
        image_inputs = MultimodalInputs.from_dict(recv_req.image_inputs)
        # 将单个图像token扩展为多个虚拟token以接收图像嵌入
        req.origin_input_ids = self.pad_input_ids_func(
            req.origin_input_ids, image_inputs
        )
        req.extend_image_inputs(image_inputs)

    # 输入长度验证
    error_msg = validate_input_length(
        req,
        self.max_req_input_len,
        self.server_args.allow_auto_truncate,
    )
    if error_msg:
        req.set_finish_with_abort(error_msg)
        self._add_request_to_queue(req)
        return

    # 设置logprob起始长度
    req.logprob_start_len = len(req.origin_input_ids) - 1
    self._add_request_to_queue(req)

💡 **实现说明**: 嵌入请求处理相对简单，主要处理多模态输入和长度验证。与生成请求不同，嵌入请求不需要采样参数和流式输出。
```

### 批量请求处理

SGLang支持批量请求处理以提高性能，减少网络开销和处理延迟：

#### 批量生成请求

```python
def handle_batch_generate_request(self, recv_req: BatchTokenizedGenerateReqInput):
    """处理批量生成请求优化"""
    logger.debug(f"Processing batch generate request with {len(recv_req)} requests")
    
    # 批量处理每个请求
    for tokenized_req in recv_req:
        self.handle_generate_request(tokenized_req)
```

#### 批量嵌入请求

```python
def handle_batch_embedding_request(self, recv_req: BatchTokenizedEmbeddingReqInput):
    """处理批量嵌入请求优化"""
    logger.debug(f"Processing batch embedding request with {len(recv_req)} requests")
    
    # 批量处理每个请求
    for tokenized_req in recv_req:
        self.handle_embedding_request(tokenized_req)
```

### 语法约束队列处理

调度器维护一个语法队列处理结构化输出约束（JSON Schema、正则表达式、EBNF等）：

```python
def handle_generate_request(self, recv_req: TokenizedGenerateReqInput):
    """处理生成请求，包括语法约束初始化"""
    
    # 初始化语法缓存
    add_to_grammar_queue = False
    if (
        req.sampling_params.json_schema is not None
        or req.sampling_params.regex is not None
        or req.sampling_params.ebnf is not None
        or req.sampling_params.structural_tag is not None
    ):
        assert self.grammar_backend is not None
        
        # 构建语法缓存键
        if req.sampling_params.json_schema is not None:
            key = ("json", req.sampling_params.json_schema)
        elif req.sampling_params.regex is not None:
            key = ("regex", req.sampling_params.regex)
        elif req.sampling_params.ebnf is not None:
            key = ("ebnf", req.sampling_params.ebnf)
        elif req.sampling_params.structural_tag:
            key = ("structural_tag", req.sampling_params.structural_tag)

        value, cache_hit = self.grammar_backend.get_cached_or_future_value(key)
        req.grammar = value

        if not cache_hit:
            req.grammar_key = key
            add_to_grammar_queue = True
        else:
            if value is INVALID_GRAMMAR_OBJ:  # 缓存的无效语法
                error_msg = f"Invalid grammar request with cache hit: {key=}"
                req.set_finish_with_abort(error_msg)

    # 根据语法状态决定队列分配
    if add_to_grammar_queue:
        req.queue_time_start = time.perf_counter()
        self.grammar_queue.append(req)
    else:
        self._add_request_to_queue(req)
```

### 缓存和控制请求

**缓存刷新**：
```python
def flush_cache_wrapped(self, recv_req: FlushCacheReqInput):
    """刷新缓存的包装方法"""
    success = self.flush_cache()
    return FlushCacheReqOutput(success)
```

**会话管理**：
```python
def open_session(self, recv_req: OpenSessionReqInput):
    """打开新会话"""
    if recv_req.session_id not in self.sessions:
        self.sessions[recv_req.session_id] = Session(
            recv_req.capacity_of_str_len, recv_req.session_id
        )
    return OpenSessionReqOutput(recv_req.session_id)

def close_session(self, recv_req: CloseSessionReqInput):
    """关闭会话"""
    if recv_req.session_id in self.sessions:
        session = self.sessions[recv_req.session_id]
        session.clear()
        del self.sessions[recv_req.session_id]
    return CloseSessionReqOutput(recv_req.session_id)
```

**请求中止**：
```python
def abort_request(self, recv_req: AbortReq):
    """中止指定的请求"""
    # 从等待队列中移除
    for i, req in enumerate(self.waiting_queue):
        if req.rid == recv_req.rid:
            req.set_finish_with_abort(recv_req.finished_reason["message"])
            del self.waiting_queue[i]
            return
    
    # 从运行批次中移除
    if self.running_batch:
        for req in self.running_batch.reqs:
            if req.rid == recv_req.rid:
                req.set_finish_with_abort(recv_req.finished_reason["message"])
                return
```

## 请求输入阻塞

### SchedulerInputBlocker

调度器支持请求阻塞机制，用于流量控制：

```python
class SchedulerInputBlocker:
    def __init__(self, noop: bool):
        self._state = _State.UNBLOCKED
        self._pending_reqs = []
        self._noop = noop
        self._global_unblock_barrier = PollBasedBarrier(noop=noop)

    def handle(self, recv_reqs: Optional[List[Any]]):
        """处理接收到的请求，根据阻塞状态决定是否放行"""
        if not self._noop:
            output_reqs = []
            for recv_req in recv_reqs:
                output_reqs += self._handle_recv_req(recv_req)
        
        # 检查全局解除阻塞屏障
        global_arrived_unblock_barrier = (
            self._global_unblock_barrier.poll_global_arrived()
        )
        if (self._state == _State.GLOBAL_UNBLOCK_BARRIER 
            and global_arrived_unblock_barrier):
            output_reqs += self._handle_arrive_unblock_barrier()

        if not self._noop:
            return output_reqs

    def _handle_recv_req(self, recv_req):
        """处理单个请求"""
        if isinstance(recv_req, BlockReqInput):
            if recv_req.type == BlockReqType.BLOCK:
                self._execute_block_req()
                return []
            elif recv_req.type == BlockReqType.UNBLOCK:
                self._execute_unblock_req()
                return []
        else:
            if self._state == _State.UNBLOCKED:
                return [recv_req]
            else:
                self._pending_reqs.append(recv_req)
                return []
```

## 请求流转过程

### 完整的请求处理流程

1. **接收阶段**: `recv_requests()` 从ZMQ管道接收请求
2. **预处理阶段**: `process_input_requests()` 进行基本检查和过滤
3. **分发阶段**: `TypeBasedDispatcher` 根据请求类型分发到对应处理方法
4. **处理阶段**: 各专门的处理方法创建`Req`对象并加入等待队列
5. **调度阶段**: 调度器从等待队列取出请求组成批次执行

### 输入数据结构

**TokenizedGenerateReqInput**：
```python
@dataclass
class TokenizedGenerateReqInput:
    rid: str                    # 请求ID
    input_text: str            # 输入文本
    input_ids: List[int]       # token化后的输入
    mm_inputs: dict            # 多模态输入
    sampling_params: SamplingParams  # 采样参数
    return_logprob: bool       # 是否返回log概率
    stream: bool               # 是否流式输出
    lora_id: Optional[str]     # LoRA适配器ID
    input_embeds: Optional[List] # 输入嵌入
    session_params: Optional[SessionParams]  # 会话参数
    custom_logit_processor: Optional[str]    # 自定义logit处理器
    bootstrap_host: Optional[str]  # 分离式推理主机
    bootstrap_port: Optional[int] # 分离式推理端口
    data_parallel_rank: Optional[int] # 数据并行rank
```

## 总结

SGLang调度器的请求处理机制具有以下特点：

1. **类型化分发**: 使用`TypeBasedDispatcher`根据请求类型自动分发
2. **队列管理**: 通过等待队列管理无法立即处理的请求
3. **会话支持**: 支持连续对话的会话管理
4. **流量控制**: 通过`SchedulerInputBlocker`实现请求阻塞
5. **多种请求类型**: 支持生成、嵌入、缓存控制、权重更新等多种请求
6. **错误处理**: 对队列满、资源不足等情况进行适当处理

这个设计确保了调度器能够高效处理各种类型的请求，同时保持良好的扩展性和可维护性。