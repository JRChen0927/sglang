# è¯·æ±‚å¤„ç†æœºåˆ¶

---

SGLangè°ƒåº¦å™¨é€šè¿‡ç»“æ„åŒ–çš„è¯·æ±‚å¤„ç†æµç¨‹æ¥ç®¡ç†å„ç§ç±»å‹çš„è¯·æ±‚ã€‚æœ¬ç« ä»‹ç»è°ƒåº¦å™¨çš„è¯·æ±‚æ¥æ”¶ã€åˆ†å‘å’Œå¤„ç†æœºåˆ¶ã€‚

---

## 1. è¯·æ±‚æ¥æ”¶æµç¨‹

### 1.1 recv_requestsæ–¹æ³•

**ç½‘ç»œè¯·æ±‚æ¥æ”¶çš„æ ¸å¿ƒæœºåˆ¶**ï¼šè°ƒåº¦å™¨é€šè¿‡`recv_requests()`æ–¹æ³•ä»tokenizeræ¥æ”¶è¯·æ±‚ï¼Œé‡‡ç”¨éé˜»å¡æ¨¡å¼ç¡®ä¿é«˜æ•ˆçš„æ‰¹é‡æ¥æ”¶ã€‚

> ğŸ“ **ç®€åŒ–è¯´æ˜**ï¼šä»¥ä¸‹ä¸ºè¯·æ±‚æ¥æ”¶çš„æ ¸å¿ƒé€»è¾‘ç®€åŒ–ç‰ˆæœ¬ï¼Œçªå‡ºéé˜»å¡æ¥æ”¶æœºåˆ¶ã€‚çœŸå®å®ç°åŒ…å«TPå¹¿æ’­ã€æµæ°´çº¿å¤„ç†å’Œæ¥æ”¶è·³è¿‡å™¨ç­‰å¤æ‚é€»è¾‘ã€‚

```python
def recv_requests(self) -> List[Req]:
    """æ¥æ”¶æ¥è‡ªtokenizerçš„è¯·æ±‚ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    recv_reqs = []
    
    # ä½¿ç”¨éé˜»å¡æ–¹å¼æ¥æ”¶è¯·æ±‚
    while True:
        try:
            recv_req = self.recv_from_tokenizer.recv_pyobj(zmq.NOBLOCK)
            recv_reqs.append(recv_req)
        except zmq.ZMQError:
            break
    
    return recv_reqs
```

### 1.2 process_input_requestsæ–¹æ³•

**è¯·æ±‚å¤„ç†çš„åˆ†å‘å’Œè¿‡æ»¤æœºåˆ¶**ï¼šæ¥æ”¶åˆ°è¯·æ±‚åï¼Œè°ƒåº¦å™¨é€šè¿‡`process_input_requests()`æ–¹æ³•è¿›è¡Œå¤„ç†ï¼ŒåŒ…æ‹¬å¥åº·æ£€æŸ¥è¿‡æ»¤ã€é˜Ÿåˆ—å®¹é‡æ£€æŸ¥å’Œç±»å‹åˆ†å‘ç­‰æ­¥éª¤ã€‚

> ğŸ“ **ç®€åŒ–è¯´æ˜**ï¼šä»¥ä¸‹ä¸ºè¯·æ±‚å¤„ç†çš„æ ¸å¿ƒé€»è¾‘ç®€åŒ–ç‰ˆæœ¬ï¼Œçªå‡ºåˆ†å‘æœºåˆ¶ã€‚çœŸå®å®ç°åŒ…å«æ›´å¤šè¾¹ç•Œæƒ…å†µå¤„ç†å’Œé”™è¯¯æ¢å¤é€»è¾‘ã€‚

```python
def process_input_requests(self, recv_reqs: List):
    """å¤„ç†è¾“å…¥è¯·æ±‚åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    for recv_req in recv_reqs:
        # å¥åº·æ£€æŸ¥è¯·æ±‚çš„ç‰¹æ®Šå¤„ç†
        if is_health_check_generate_req(recv_req) and (
            self.chunked_req is not None
            or not self.running_batch.is_empty()
        ):
            self.return_health_check_ct += 1
            continue

        # å·¥ä½œè¯·æ±‚çš„é˜Ÿåˆ—å¤§å°æ£€æŸ¥
        if is_work_request(recv_req):
            if len(self.waiting_queue) + 1 > self.max_queued_requests:
                abort_req = AbortReq(
                    recv_req.rid,
                    finished_reason={
                        "type": "abort",
                        "status_code": HTTPStatus.SERVICE_UNAVAILABLE,
                        "message": "The request queue is full.",
                    },
                )
                self.send_to_tokenizer.send_pyobj(abort_req)
                continue
                
        # ä½¿ç”¨è¯·æ±‚åˆ†å‘å™¨å¤„ç†è¯·æ±‚
        output = self._request_dispatcher(recv_req)
        if output is not None:
            if isinstance(output, RpcReqOutput):
                if self.recv_from_rpc is not None:
                    self.recv_from_rpc.send_pyobj(output)
            else:
                self.send_to_tokenizer.send_pyobj(output)
```

---

## 2. è¯·æ±‚åˆ†å‘æœºåˆ¶

### 2.1 æ ¸å¿ƒè®¾è®¡æ¦‚å¿µ

```python
# TypeBasedDispatcherçš„æ ¸å¿ƒæ¦‚å¿µ
self._request_dispatcher = TypeBasedDispatcher([
    (TokenizedGenerateReqInput, self.handle_generate_request),
    (TokenizedEmbeddingReqInput, self.handle_embedding_request),
    (FlushCacheReqInput, self.flush_cache_wrapped),
    (AbortReq, self.abort_request),
    (OpenSessionReqInput, self.open_session),
    (CloseSessionReqInput, self.close_session),
    # ... æ›´å¤šè¯·æ±‚ç±»å‹æ˜ å°„
])

# ä½¿ç”¨æ–¹å¼
for recv_req in recv_reqs:
    output = self._request_dispatcher(recv_req)  # è‡ªåŠ¨è·¯ç”±åˆ°å¯¹åº”å¤„ç†å™¨
```

### ğŸ” æºç å®ç°ç»†èŠ‚

```python
# çœŸå®çš„è°ƒåº¦å™¨è¯·æ±‚åˆ†å‘å™¨å®Œæ•´é…ç½®
self._request_dispatcher = TypeBasedDispatcher([
    (TokenizedGenerateReqInput, self.handle_generate_request),
    (TokenizedEmbeddingReqInput, self.handle_embedding_request),
    (BatchTokenizedGenerateReqInput, self.handle_batch_generate_request),
    (BatchTokenizedEmbeddingReqInput, self.handle_batch_embedding_request),
    (FlushCacheReqInput, self.flush_cache_wrapped),
    (AbortReq, self.abort_request),
    (OpenSessionReqInput, self.open_session),
    (CloseSessionReqInput, self.close_session),
    (UpdateWeightFromDiskReqInput, self.update_weights_from_disk),
    (InitWeightsUpdateGroupReqInput, self.init_weights_update_group),
    (UpdateWeightsFromDistributedReqInput, self.update_weights_from_distributed),
    (UpdateWeightsFromTensorReqInput, self.update_weights_from_tensor),
    (GetWeightsByNameReqInput, self.get_weights_by_name),
    (ReleaseMemoryOccupationReqInput, self.release_memory_occupation),
    (ResumeMemoryOccupationReqInput, self.resume_memory_occupation),
    (SlowDownReqInput, self.slow_down),
    (ProfileReq, self.profile),
    (FreezeGCReq, self.handle_freeze_gc),
    (GetInternalStateReq, self.get_internal_state),
    (SetInternalStateReq, self.set_internal_state),
    (RpcReqInput, self.handle_rpc_request),
    (ExpertDistributionReq, self.expert_distribution_handle),
    (LoadLoRAAdapterReqInput, self.load_lora_adapter),
    (UnloadLoRAAdapterReqInput, self.unload_lora_adapter),
])

ğŸ’¡ **å®ç°è¯´æ˜**: çœŸå®åˆ†å‘å™¨æ”¯æŒ20+ç§è¯·æ±‚ç±»å‹ï¼Œä»åŸºæœ¬çš„ç”Ÿæˆ/åµŒå…¥åˆ°é«˜çº§çš„æƒé‡æ›´æ–°ã€LoRAç®¡ç†ã€ç³»ç»Ÿæ§åˆ¶ç­‰ã€‚TypeBasedDispatcheré€šè¿‡åå°„æœºåˆ¶å®ç°è¯·æ±‚ç±»å‹åˆ°å¤„ç†æ–¹æ³•çš„è‡ªåŠ¨æ˜ å°„ã€‚
```

---

## 3. ä¸»è¦è¯·æ±‚ç±»å‹å¤„ç†

### 3.1 ç”Ÿæˆè¯·æ±‚å¤„ç†

#### 3.1.1 æ ¸å¿ƒè®¾è®¡æ¦‚å¿µ

**æ–‡æœ¬ç”Ÿæˆè¯·æ±‚çš„å¤„ç†æµç¨‹**ï¼šhandle_generate_requestæ–¹æ³•è´Ÿè´£å°†å¤–éƒ¨è¯·æ±‚è½¬æ¢ä¸ºå†…éƒ¨Reqå¯¹è±¡ï¼Œå¤„ç†ä¼šè¯ç®¡ç†ã€å‚æ•°éªŒè¯å’Œé˜Ÿåˆ—åˆ†é…ç­‰æ ¸å¿ƒé€»è¾‘ã€‚

> ğŸ“ **ç®€åŒ–è¯´æ˜**ï¼šä»¥ä¸‹ä¸ºç”Ÿæˆè¯·æ±‚å¤„ç†çš„æ ¸å¿ƒæ­¥éª¤ç®€åŒ–ç‰ˆæœ¬ï¼Œçªå‡ºä¸»è¦æµç¨‹ã€‚çœŸå®å®ç°åŒ…å«æ›´å¤šå‚æ•°å¤„ç†å’Œé”™è¯¯æ£€æŸ¥é€»è¾‘ã€‚

```python
def handle_generate_request(self, recv_req: TokenizedGenerateReqInput):
    """å¤„ç†æ–‡æœ¬ç”Ÿæˆè¯·æ±‚ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    # åˆ›å»ºReqå¯¹è±¡
    req = Req(
        recv_req.rid,
        recv_req.input_text,
        recv_req.input_ids,
        recv_req.sampling_params,
        return_logprob=recv_req.return_logprob,
        stream=recv_req.stream,
        lora_id=recv_req.lora_id,
    )
    req.tokenizer = self.tokenizer
    
    # æ·»åŠ åˆ°ç­‰å¾…é˜Ÿåˆ—
    self.waiting_queue.append(req)
```

#### ğŸ” æºç å®ç°ç»†èŠ‚

```python
def handle_generate_request(self, recv_req: TokenizedGenerateReqInput):
    """çœŸå®çš„SGLangç”Ÿæˆè¯·æ±‚å¤„ç†å®ç°"""
    
    # æ•°æ®å¹¶è¡Œè´Ÿè½½å‡è¡¡ç›¸å…³
    if (self.server_args.enable_dp_attention 
        and self.server_args.load_balance_method == "minimum_tokens"):
        self.recv_dp_balance_id_this_term.append(recv_req.dp_balance_id)

    # ä¼šè¯ç®¡ç†ï¼šåˆ›å»ºæ–°è¯·æ±‚æˆ–ä½¿ç”¨ç°æœ‰ä¼šè¯
    if (recv_req.session_params is None 
        or recv_req.session_params.id is None
        or recv_req.session_params.id not in self.sessions):
        
        # å¤„ç†è¾“å…¥åµŒå…¥çš„ç‰¹æ®Šæƒ…å†µ
        if recv_req.input_embeds is not None:
            seq_length = len(recv_req.input_embeds)
            fake_input_ids = [1] * seq_length
            recv_req.input_ids = fake_input_ids

        # åˆ†ç¦»å¼æ¶æ„ï¼šè®¾ç½®é»˜è®¤bootstrapç«¯å£
        if recv_req.bootstrap_port is None:
            recv_req.bootstrap_port = self.server_args.disaggregation_bootstrap_port

        # åˆ›å»ºæ–°çš„Reqå¯¹è±¡ï¼ŒåŒ…å«æ‰€æœ‰å‚æ•°
        req = Req(
            recv_req.rid,
            recv_req.input_text,
            recv_req.input_ids,
            recv_req.sampling_params,
            return_logprob=recv_req.return_logprob,
            top_logprobs_num=recv_req.top_logprobs_num,
            token_ids_logprob=recv_req.token_ids_logprob,
            stream=recv_req.stream,
            origin_input_ids_unpadded=recv_req.origin_input_ids_unpadded,
            lora_id=recv_req.lora_id,
            input_embeds=recv_req.input_embeds,
            token_type_ids=recv_req.token_type_ids,
            session_id=None,
            custom_logit_processor=recv_req.custom_logit_processor,
            return_hidden_states=recv_req.return_hidden_states,
            eos_token_ids=self.model_config.hf_eos_token_id,
            bootstrap_host=recv_req.bootstrap_host,
            bootstrap_port=recv_req.bootstrap_port,
            bootstrap_room=recv_req.bootstrap_room,
            data_parallel_rank=recv_req.data_parallel_rank,
            vocab_size=self.model_config.vocab_size,
        )
        req.tokenizer = self.tokenizer
        
        # å¤šæ¨¡æ€è¾“å…¥å¤„ç†
        if recv_req.mm_inputs is not None:
            mm_inputs = MultimodalInputs.from_dict(recv_req.mm_inputs)
            req.origin_input_ids = self.pad_input_ids_func(
                req.origin_input_ids, mm_inputs
            )
            req.extend_image_inputs(mm_inputs)

        # è¾“å…¥é•¿åº¦éªŒè¯
        error_msg = validate_input_length(
            req,
            self.max_req_input_len,
            self.server_args.allow_auto_truncate,
        )
        if error_msg:
            req.set_finish_with_abort(error_msg)

        # è¯­æ³•çº¦æŸå¤„ç†ï¼ˆJSON Schemaã€Regexã€EBNFï¼‰
        self._handle_grammar_constraints(req)
        
        # æ·»åŠ åˆ°ç›¸åº”é˜Ÿåˆ—
        if hasattr(req, 'grammar_key'):
            self.grammar_queue.append(req)
        else:
            self._add_request_to_queue(req)
            
    else:
        # ä½¿ç”¨ç°æœ‰ä¼šè¯å¤„ç†è¯·æ±‚
        session = self.sessions[recv_req.session_params.id]
        req = session.create_req(recv_req, self.tokenizer)
        if not req.finished:
            self._add_request_to_queue(req)

ğŸ’¡ **å®ç°è¯´æ˜**: çœŸå®çš„ç”Ÿæˆè¯·æ±‚å¤„ç†åŒ…å«ä¼šè¯ç®¡ç†ã€å¤šæ¨¡æ€è¾“å…¥ã€è¯­æ³•çº¦æŸã€è¾“å…¥éªŒè¯ã€åˆ†ç¦»å¼æ¶æ„æ”¯æŒç­‰å¤æ‚åŠŸèƒ½ã€‚æ•™å­¦ç‰ˆæœ¬çªå‡º"è¾“å…¥â†’Reqå¯¹è±¡â†’é˜Ÿåˆ—"çš„æ ¸å¿ƒæµç¨‹ã€‚
```

---

### ğŸ”¢ åµŒå…¥è¯·æ±‚å¤„ç†

#### ğŸ¯ æ ¸å¿ƒè®¾è®¡æ¦‚å¿µ

```python
def handle_embedding_request(self, recv_req: TokenizedEmbeddingReqInput):
    """å¤„ç†åµŒå…¥è¯·æ±‚çš„æ ¸å¿ƒæ¦‚å¿µ"""
    # åˆ›å»ºåµŒå…¥Reqå¯¹è±¡
    req = Req(
        recv_req.rid,
        recv_req.input_text,
        recv_req.input_ids,
        recv_req.sampling_params,
        token_type_ids=recv_req.token_type_ids,
    )
    req.tokenizer = self.tokenizer
    
    # æ·»åŠ åˆ°ç­‰å¾…é˜Ÿåˆ—
    self._add_request_to_queue(req)
```

#### ğŸ” æºç å®ç°ç»†èŠ‚

```python
def handle_embedding_request(self, recv_req: TokenizedEmbeddingReqInput):
    """çœŸå®çš„SGLangåµŒå…¥è¯·æ±‚å¤„ç†å®ç°"""
    req = Req(
        recv_req.rid,
        recv_req.input_text,
        recv_req.input_ids,
        recv_req.sampling_params,
        token_type_ids=recv_req.token_type_ids,
    )
    req.tokenizer = self.tokenizer

    # å¤šæ¨¡æ€è¾“å…¥å¤„ç†
    if recv_req.image_inputs is not None:
        image_inputs = MultimodalInputs.from_dict(recv_req.image_inputs)
        # å°†å•ä¸ªå›¾åƒtokenæ‰©å±•ä¸ºå¤šä¸ªè™šæ‹Ÿtokenä»¥æ¥æ”¶å›¾åƒåµŒå…¥
        req.origin_input_ids = self.pad_input_ids_func(
            req.origin_input_ids, image_inputs
        )
        req.extend_image_inputs(image_inputs)

    # è¾“å…¥é•¿åº¦éªŒè¯
    error_msg = validate_input_length(
        req,
        self.max_req_input_len,
        self.server_args.allow_auto_truncate,
    )
    if error_msg:
        req.set_finish_with_abort(error_msg)
        self._add_request_to_queue(req)
        return

    # è®¾ç½®logprobèµ·å§‹é•¿åº¦
    req.logprob_start_len = len(req.origin_input_ids) - 1
    self._add_request_to_queue(req)

ğŸ’¡ **å®ç°è¯´æ˜**: åµŒå…¥è¯·æ±‚å¤„ç†ç›¸å¯¹ç®€å•ï¼Œä¸»è¦å¤„ç†å¤šæ¨¡æ€è¾“å…¥å’Œé•¿åº¦éªŒè¯ã€‚ä¸ç”Ÿæˆè¯·æ±‚ä¸åŒï¼ŒåµŒå…¥è¯·æ±‚ä¸éœ€è¦é‡‡æ ·å‚æ•°å’Œæµå¼è¾“å‡ºã€‚
```

### æ‰¹é‡è¯·æ±‚å¤„ç†

SGLangæ”¯æŒæ‰¹é‡è¯·æ±‚å¤„ç†ä»¥æé«˜æ€§èƒ½ï¼Œå‡å°‘ç½‘ç»œå¼€é”€å’Œå¤„ç†å»¶è¿Ÿï¼š

#### æ‰¹é‡ç”Ÿæˆè¯·æ±‚

```python
def handle_batch_generate_request(self, recv_req: BatchTokenizedGenerateReqInput):
    """å¤„ç†æ‰¹é‡ç”Ÿæˆè¯·æ±‚ä¼˜åŒ–"""
    logger.debug(f"Processing batch generate request with {len(recv_req)} requests")
    
    # æ‰¹é‡å¤„ç†æ¯ä¸ªè¯·æ±‚
    for tokenized_req in recv_req:
        self.handle_generate_request(tokenized_req)
```

#### æ‰¹é‡åµŒå…¥è¯·æ±‚

```python
def handle_batch_embedding_request(self, recv_req: BatchTokenizedEmbeddingReqInput):
    """å¤„ç†æ‰¹é‡åµŒå…¥è¯·æ±‚ä¼˜åŒ–"""
    logger.debug(f"Processing batch embedding request with {len(recv_req)} requests")
    
    # æ‰¹é‡å¤„ç†æ¯ä¸ªè¯·æ±‚
    for tokenized_req in recv_req:
        self.handle_embedding_request(tokenized_req)
```

### è¯­æ³•çº¦æŸé˜Ÿåˆ—å¤„ç†

è°ƒåº¦å™¨ç»´æŠ¤ä¸€ä¸ªè¯­æ³•é˜Ÿåˆ—å¤„ç†ç»“æ„åŒ–è¾“å‡ºçº¦æŸï¼ˆJSON Schemaã€æ­£åˆ™è¡¨è¾¾å¼ã€EBNFç­‰ï¼‰ï¼š

```python
def handle_generate_request(self, recv_req: TokenizedGenerateReqInput):
    """å¤„ç†ç”Ÿæˆè¯·æ±‚ï¼ŒåŒ…æ‹¬è¯­æ³•çº¦æŸåˆå§‹åŒ–"""
    
    # åˆå§‹åŒ–è¯­æ³•ç¼“å­˜
    add_to_grammar_queue = False
    if (
        req.sampling_params.json_schema is not None
        or req.sampling_params.regex is not None
        or req.sampling_params.ebnf is not None
        or req.sampling_params.structural_tag is not None
    ):
        assert self.grammar_backend is not None
        
        # æ„å»ºè¯­æ³•ç¼“å­˜é”®
        if req.sampling_params.json_schema is not None:
            key = ("json", req.sampling_params.json_schema)
        elif req.sampling_params.regex is not None:
            key = ("regex", req.sampling_params.regex)
        elif req.sampling_params.ebnf is not None:
            key = ("ebnf", req.sampling_params.ebnf)
        elif req.sampling_params.structural_tag:
            key = ("structural_tag", req.sampling_params.structural_tag)

        value, cache_hit = self.grammar_backend.get_cached_or_future_value(key)
        req.grammar = value

        if not cache_hit:
            req.grammar_key = key
            add_to_grammar_queue = True
        else:
            if value is INVALID_GRAMMAR_OBJ:  # ç¼“å­˜çš„æ— æ•ˆè¯­æ³•
                error_msg = f"Invalid grammar request with cache hit: {key=}"
                req.set_finish_with_abort(error_msg)

    # æ ¹æ®è¯­æ³•çŠ¶æ€å†³å®šé˜Ÿåˆ—åˆ†é…
    if add_to_grammar_queue:
        req.queue_time_start = time.perf_counter()
        self.grammar_queue.append(req)
    else:
        self._add_request_to_queue(req)
```

### ç¼“å­˜å’Œæ§åˆ¶è¯·æ±‚

**ç¼“å­˜åˆ·æ–°**ï¼š
```python
def flush_cache_wrapped(self, recv_req: FlushCacheReqInput):
    """åˆ·æ–°ç¼“å­˜çš„åŒ…è£…æ–¹æ³•"""
    success = self.flush_cache()
    return FlushCacheReqOutput(success)
```

**ä¼šè¯ç®¡ç†**ï¼š
```python
def open_session(self, recv_req: OpenSessionReqInput):
    """æ‰“å¼€æ–°ä¼šè¯"""
    if recv_req.session_id not in self.sessions:
        self.sessions[recv_req.session_id] = Session(
            recv_req.capacity_of_str_len, recv_req.session_id
        )
    return OpenSessionReqOutput(recv_req.session_id)

def close_session(self, recv_req: CloseSessionReqInput):
    """å…³é—­ä¼šè¯"""
    if recv_req.session_id in self.sessions:
        session = self.sessions[recv_req.session_id]
        session.clear()
        del self.sessions[recv_req.session_id]
    return CloseSessionReqOutput(recv_req.session_id)
```

**è¯·æ±‚ä¸­æ­¢**ï¼š
```python
def abort_request(self, recv_req: AbortReq):
    """ä¸­æ­¢æŒ‡å®šçš„è¯·æ±‚"""
    # ä»ç­‰å¾…é˜Ÿåˆ—ä¸­ç§»é™¤
    for i, req in enumerate(self.waiting_queue):
        if req.rid == recv_req.rid:
            req.set_finish_with_abort(recv_req.finished_reason["message"])
            del self.waiting_queue[i]
            return
    
    # ä»è¿è¡Œæ‰¹æ¬¡ä¸­ç§»é™¤
    if self.running_batch:
        for req in self.running_batch.reqs:
            if req.rid == recv_req.rid:
                req.set_finish_with_abort(recv_req.finished_reason["message"])
                return
```

## è¯·æ±‚è¾“å…¥é˜»å¡

### SchedulerInputBlocker

è°ƒåº¦å™¨æ”¯æŒè¯·æ±‚é˜»å¡æœºåˆ¶ï¼Œç”¨äºæµé‡æ§åˆ¶ï¼š

```python
class SchedulerInputBlocker:
    def __init__(self, noop: bool):
        self._state = _State.UNBLOCKED
        self._pending_reqs = []
        self._noop = noop
        self._global_unblock_barrier = PollBasedBarrier(noop=noop)

    def handle(self, recv_reqs: Optional[List[Any]]):
        """å¤„ç†æ¥æ”¶åˆ°çš„è¯·æ±‚ï¼Œæ ¹æ®é˜»å¡çŠ¶æ€å†³å®šæ˜¯å¦æ”¾è¡Œ"""
        if not self._noop:
            output_reqs = []
            for recv_req in recv_reqs:
                output_reqs += self._handle_recv_req(recv_req)
        
        # æ£€æŸ¥å…¨å±€è§£é™¤é˜»å¡å±éšœ
        global_arrived_unblock_barrier = (
            self._global_unblock_barrier.poll_global_arrived()
        )
        if (self._state == _State.GLOBAL_UNBLOCK_BARRIER 
            and global_arrived_unblock_barrier):
            output_reqs += self._handle_arrive_unblock_barrier()

        if not self._noop:
            return output_reqs

    def _handle_recv_req(self, recv_req):
        """å¤„ç†å•ä¸ªè¯·æ±‚"""
        if isinstance(recv_req, BlockReqInput):
            if recv_req.type == BlockReqType.BLOCK:
                self._execute_block_req()
                return []
            elif recv_req.type == BlockReqType.UNBLOCK:
                self._execute_unblock_req()
                return []
        else:
            if self._state == _State.UNBLOCKED:
                return [recv_req]
            else:
                self._pending_reqs.append(recv_req)
                return []
```

## è¯·æ±‚æµè½¬è¿‡ç¨‹

### å®Œæ•´çš„è¯·æ±‚å¤„ç†æµç¨‹

1. **æ¥æ”¶é˜¶æ®µ**: `recv_requests()` ä»ZMQç®¡é“æ¥æ”¶è¯·æ±‚
2. **é¢„å¤„ç†é˜¶æ®µ**: `process_input_requests()` è¿›è¡ŒåŸºæœ¬æ£€æŸ¥å’Œè¿‡æ»¤
3. **åˆ†å‘é˜¶æ®µ**: `TypeBasedDispatcher` æ ¹æ®è¯·æ±‚ç±»å‹åˆ†å‘åˆ°å¯¹åº”å¤„ç†æ–¹æ³•
4. **å¤„ç†é˜¶æ®µ**: å„ä¸“é—¨çš„å¤„ç†æ–¹æ³•åˆ›å»º`Req`å¯¹è±¡å¹¶åŠ å…¥ç­‰å¾…é˜Ÿåˆ—
5. **è°ƒåº¦é˜¶æ®µ**: è°ƒåº¦å™¨ä»ç­‰å¾…é˜Ÿåˆ—å–å‡ºè¯·æ±‚ç»„æˆæ‰¹æ¬¡æ‰§è¡Œ

### è¾“å…¥æ•°æ®ç»“æ„

**TokenizedGenerateReqInput**ï¼š
```python
@dataclass
class TokenizedGenerateReqInput:
    rid: str                    # è¯·æ±‚ID
    input_text: str            # è¾“å…¥æ–‡æœ¬
    input_ids: List[int]       # tokenåŒ–åçš„è¾“å…¥
    mm_inputs: dict            # å¤šæ¨¡æ€è¾“å…¥
    sampling_params: SamplingParams  # é‡‡æ ·å‚æ•°
    return_logprob: bool       # æ˜¯å¦è¿”å›logæ¦‚ç‡
    stream: bool               # æ˜¯å¦æµå¼è¾“å‡º
    lora_id: Optional[str]     # LoRAé€‚é…å™¨ID
    input_embeds: Optional[List] # è¾“å…¥åµŒå…¥
    session_params: Optional[SessionParams]  # ä¼šè¯å‚æ•°
    custom_logit_processor: Optional[str]    # è‡ªå®šä¹‰logitå¤„ç†å™¨
    bootstrap_host: Optional[str]  # åˆ†ç¦»å¼æ¨ç†ä¸»æœº
    bootstrap_port: Optional[int] # åˆ†ç¦»å¼æ¨ç†ç«¯å£
    data_parallel_rank: Optional[int] # æ•°æ®å¹¶è¡Œrank
```

## æ€»ç»“

SGLangè°ƒåº¦å™¨çš„è¯·æ±‚å¤„ç†æœºåˆ¶å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

1. **ç±»å‹åŒ–åˆ†å‘**: ä½¿ç”¨`TypeBasedDispatcher`æ ¹æ®è¯·æ±‚ç±»å‹è‡ªåŠ¨åˆ†å‘
2. **é˜Ÿåˆ—ç®¡ç†**: é€šè¿‡ç­‰å¾…é˜Ÿåˆ—ç®¡ç†æ— æ³•ç«‹å³å¤„ç†çš„è¯·æ±‚
3. **ä¼šè¯æ”¯æŒ**: æ”¯æŒè¿ç»­å¯¹è¯çš„ä¼šè¯ç®¡ç†
4. **æµé‡æ§åˆ¶**: é€šè¿‡`SchedulerInputBlocker`å®ç°è¯·æ±‚é˜»å¡
5. **å¤šç§è¯·æ±‚ç±»å‹**: æ”¯æŒç”Ÿæˆã€åµŒå…¥ã€ç¼“å­˜æ§åˆ¶ã€æƒé‡æ›´æ–°ç­‰å¤šç§è¯·æ±‚
6. **é”™è¯¯å¤„ç†**: å¯¹é˜Ÿåˆ—æ»¡ã€èµ„æºä¸è¶³ç­‰æƒ…å†µè¿›è¡Œé€‚å½“å¤„ç†

è¿™ä¸ªè®¾è®¡ç¡®ä¿äº†è°ƒåº¦å™¨èƒ½å¤Ÿé«˜æ•ˆå¤„ç†å„ç§ç±»å‹çš„è¯·æ±‚ï¼ŒåŒæ—¶ä¿æŒè‰¯å¥½çš„æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚