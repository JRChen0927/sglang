# 请求处理机制

SGLang调度器通过结构化的请求处理流程来管理各种类型的请求。本章介绍调度器的请求接收、分发和处理机制。

## 请求接收流程

### recv_requests方法

调度器通过`recv_requests()`方法从通信管道接收请求：

```python
def recv_requests(self) -> List[Req]:
    """接收来自tokenizer的请求"""
    recv_reqs = []
    
    # 使用非阻塞方式接收请求
    while True:
        try:
            recv_req = self.recv_from_tokenizer.recv_pyobj(zmq.NOBLOCK)
            recv_reqs.append(recv_req)
        except zmq.ZMQError:
            break
    
    return recv_reqs
```

### process_input_requests方法

接收到请求后，调度器通过`process_input_requests()`方法处理：

```python
def process_input_requests(self, recv_reqs: List):
    """处理输入请求列表"""
    for recv_req in recv_reqs:
        # 健康检查请求的特殊处理
        if is_health_check_generate_req(recv_req) and (
            self.chunked_req is not None
            or not self.running_batch.is_empty()
            or len(self.offload_tags) > 0
        ):
            self.return_health_check_ct += 1
            continue

        # 工作请求的队列大小检查
        if is_work_request(recv_req):
            if len(self.waiting_queue) + 1 > self.max_queued_requests:
                abort_req = AbortReq(
                    recv_req.rid,
                    finished_reason={
                        "type": "abort",
                        "status_code": HTTPStatus.SERVICE_UNAVAILABLE,
                        "message": "The request queue is full.",
                    },
                )
                self.send_to_tokenizer.send_pyobj(abort_req)
                continue
                
        # 使用请求分发器处理请求
        output = self._request_dispatcher(recv_req)
        if output is not None:
            if isinstance(output, RpcReqOutput):
                if self.recv_from_rpc is not None:
                    self.recv_from_rpc.send_pyobj(output)
            else:
                self.send_to_tokenizer.send_pyobj(output)
```

## 请求分发机制

### TypeBasedDispatcher

调度器使用类型分发器来处理不同类型的请求：

```python
# 在调度器初始化时创建请求分发器
self._request_dispatcher = TypeBasedDispatcher([
    (TokenizedGenerateReqInput, self.handle_generate_request),
    (TokenizedEmbeddingReqInput, self.handle_embedding_request),
    (BatchTokenizedGenerateReqInput, self.handle_batch_generate_request),
    (BatchTokenizedEmbeddingReqInput, self.handle_batch_embedding_request),
    (FlushCacheReqInput, self.flush_cache_wrapped),
    (AbortReq, self.abort_request),
    (OpenSessionReqInput, self.open_session),
    (CloseSessionReqInput, self.close_session),
    (UpdateWeightFromDiskReqInput, self.update_weights_from_disk),
    (InitWeightsUpdateGroupReqInput, self.init_weights_update_group),
    (UpdateWeightsFromDistributedReqInput, self.update_weights_from_distributed),
    (UpdateWeightsFromTensorReqInput, self.update_weights_from_tensor),
    (GetWeightsByNameReqInput, self.get_weights_by_name),
    (ReleaseMemoryOccupationReqInput, self.release_memory_occupation),
    (ResumeMemoryOccupationReqInput, self.resume_memory_occupation),
    (SlowDownReqInput, self.slow_down),
    (ProfileReq, self.profile),
    (FreezeGCReq, self.handle_freeze_gc),
    (GetInternalStateReq, self.get_internal_state),
    (SetInternalStateReq, self.set_internal_state),
    (RpcReqInput, self.handle_rpc_request),
    (ExpertDistributionReq, self.expert_distribution_handle),
    (LoadLoRAAdapterReqInput, self.load_lora_adapter),
    (UnloadLoRAAdapterReqInput, self.unload_lora_adapter),
])
```

## 主要请求类型处理

### 生成请求处理

`handle_generate_request`是最重要的请求处理方法：

```python
def handle_generate_request(self, recv_req: TokenizedGenerateReqInput):
    """处理文本生成请求"""
    
    # 数据并行负载均衡相关
    if (self.server_args.enable_dp_attention 
        and self.server_args.load_balance_method == "minimum_tokens"):
        self.recv_dp_balance_id_this_term.append(recv_req.dp_balance_id)

    # 创建新请求或使用会话
    if (recv_req.session_params is None 
        or recv_req.session_params.id is None
        or recv_req.session_params.id not in self.sessions):
        
        # 处理输入嵌入的特殊情况
        if recv_req.input_embeds is not None:
            seq_length = len(recv_req.input_embeds)
            fake_input_ids = [1] * seq_length
            recv_req.input_ids = fake_input_ids

        # 设置默认bootstrap端口
        if recv_req.bootstrap_port is None:
            recv_req.bootstrap_port = self.server_args.disaggregation_bootstrap_port

        # 创建新的Req对象
        req = Req(
            recv_req.rid,
            recv_req.input_text,
            recv_req.input_ids,
            recv_req.sampling_params,
            return_logprob=recv_req.return_logprob,
            top_logprobs_num=recv_req.top_logprobs_num,
            token_ids_logprob=recv_req.token_ids_logprob,
            stream=recv_req.stream,
            lora_id=recv_req.lora_id,
            input_embeds=recv_req.input_embeds,
            custom_logit_processor=recv_req.custom_logit_processor,
            return_hidden_states=recv_req.return_hidden_states,
            eos_token_ids=self.model_config.hf_eos_token_id,
            bootstrap_host=recv_req.bootstrap_host,
            bootstrap_port=recv_req.bootstrap_port,
            bootstrap_room=recv_req.bootstrap_room,
            data_parallel_rank=recv_req.data_parallel_rank,
            vocab_size=self.model_config.vocab_size,
        )
        req.tokenizer = self.tokenizer
        
        # 添加到等待队列
        self.waiting_queue.append(req)
    else:
        # 使用现有会话处理请求
        session = self.sessions[recv_req.session_params.id]
        req = session.create_req(recv_req, self.tokenizer)
        if not req.finished:
            self.waiting_queue.append(req)
```

### 嵌入请求处理

```python
def handle_embedding_request(self, recv_req: TokenizedEmbeddingReqInput):
    """处理嵌入生成请求"""
    req = Req(
        recv_req.rid,
        recv_req.input_text,
        recv_req.input_ids,
        recv_req.sampling_params,
        token_type_ids=recv_req.token_type_ids,
    )
    req.tokenizer = self.tokenizer

    # 处理多模态输入
    if recv_req.image_inputs is not None:
        image_inputs = MultimodalInputs.from_dict(recv_req.image_inputs)
        # 将单个图像token扩展为多个虚拟token以接收图像嵌入
        req.origin_input_ids = self.pad_input_ids_func(
            req.origin_input_ids, image_inputs
        )
        req.extend_image_inputs(image_inputs)

    # 验证提示长度
    error_msg = validate_input_length(
        req,
        self.max_req_input_len,
        self.server_args.allow_auto_truncate,
    )
    if error_msg:
        self._add_request_to_queue(req)
        return

    # 复制更多属性
    req.logprob_start_len = len(req.origin_input_ids) - 1
    self._add_request_to_queue(req)
```

### 批量请求处理

SGLang支持批量请求处理以提高性能，减少网络开销和处理延迟：

#### 批量生成请求

```python
def handle_batch_generate_request(self, recv_req: BatchTokenizedGenerateReqInput):
    """处理批量生成请求优化"""
    logger.debug(f"Processing batch generate request with {len(recv_req)} requests")
    
    # 批量处理每个请求
    for tokenized_req in recv_req:
        self.handle_generate_request(tokenized_req)
```

#### 批量嵌入请求

```python
def handle_batch_embedding_request(self, recv_req: BatchTokenizedEmbeddingReqInput):
    """处理批量嵌入请求优化"""
    logger.debug(f"Processing batch embedding request with {len(recv_req)} requests")
    
    # 批量处理每个请求
    for tokenized_req in recv_req:
        self.handle_embedding_request(tokenized_req)
```

### 语法约束队列处理

调度器维护一个语法队列处理结构化输出约束（JSON Schema、正则表达式、EBNF等）：

```python
def handle_generate_request(self, recv_req: TokenizedGenerateReqInput):
    """处理生成请求，包括语法约束初始化"""
    
    # 初始化语法缓存
    add_to_grammar_queue = False
    if (
        req.sampling_params.json_schema is not None
        or req.sampling_params.regex is not None
        or req.sampling_params.ebnf is not None
        or req.sampling_params.structural_tag is not None
    ):
        assert self.grammar_backend is not None
        
        # 构建语法缓存键
        if req.sampling_params.json_schema is not None:
            key = ("json", req.sampling_params.json_schema)
        elif req.sampling_params.regex is not None:
            key = ("regex", req.sampling_params.regex)
        elif req.sampling_params.ebnf is not None:
            key = ("ebnf", req.sampling_params.ebnf)
        elif req.sampling_params.structural_tag:
            key = ("structural_tag", req.sampling_params.structural_tag)

        value, cache_hit = self.grammar_backend.get_cached_or_future_value(key)
        req.grammar = value

        if not cache_hit:
            req.grammar_key = key
            add_to_grammar_queue = True
        else:
            if value is INVALID_GRAMMAR_OBJ:  # 缓存的无效语法
                error_msg = f"Invalid grammar request with cache hit: {key=}"
                req.set_finish_with_abort(error_msg)

    # 根据语法状态决定队列分配
    if add_to_grammar_queue:
        req.queue_time_start = time.perf_counter()
        self.grammar_queue.append(req)
    else:
        self._add_request_to_queue(req)
```

### 缓存和控制请求

**缓存刷新**：
```python
def flush_cache_wrapped(self, recv_req: FlushCacheReqInput):
    """刷新缓存的包装方法"""
    success = self.flush_cache()
    return FlushCacheReqOutput(success)
```

**会话管理**：
```python
def open_session(self, recv_req: OpenSessionReqInput):
    """打开新会话"""
    if recv_req.session_id not in self.sessions:
        self.sessions[recv_req.session_id] = Session(
            recv_req.capacity_of_str_len, recv_req.session_id
        )
    return OpenSessionReqOutput(recv_req.session_id)

def close_session(self, recv_req: CloseSessionReqInput):
    """关闭会话"""
    if recv_req.session_id in self.sessions:
        session = self.sessions[recv_req.session_id]
        session.clear()
        del self.sessions[recv_req.session_id]
    return CloseSessionReqOutput(recv_req.session_id)
```

**请求中止**：
```python
def abort_request(self, recv_req: AbortReq):
    """中止指定的请求"""
    # 从等待队列中移除
    for i, req in enumerate(self.waiting_queue):
        if req.rid == recv_req.rid:
            req.set_finish_with_abort(recv_req.finished_reason["message"])
            del self.waiting_queue[i]
            return
    
    # 从运行批次中移除
    if self.running_batch:
        for req in self.running_batch.reqs:
            if req.rid == recv_req.rid:
                req.set_finish_with_abort(recv_req.finished_reason["message"])
                return
```

## 请求输入阻塞

### SchedulerInputBlocker

调度器支持请求阻塞机制，用于流量控制：

```python
class SchedulerInputBlocker:
    def __init__(self, noop: bool):
        self._state = _State.UNBLOCKED
        self._pending_reqs = []
        self._noop = noop
        self._global_unblock_barrier = PollBasedBarrier(noop=noop)

    def handle(self, recv_reqs: Optional[List[Any]]):
        """处理接收到的请求，根据阻塞状态决定是否放行"""
        if not self._noop:
            output_reqs = []
            for recv_req in recv_reqs:
                output_reqs += self._handle_recv_req(recv_req)
        
        # 检查全局解除阻塞屏障
        global_arrived_unblock_barrier = (
            self._global_unblock_barrier.poll_global_arrived()
        )
        if (self._state == _State.GLOBAL_UNBLOCK_BARRIER 
            and global_arrived_unblock_barrier):
            output_reqs += self._handle_arrive_unblock_barrier()

        if not self._noop:
            return output_reqs

    def _handle_recv_req(self, recv_req):
        """处理单个请求"""
        if isinstance(recv_req, BlockReqInput):
            if recv_req.type == BlockReqType.BLOCK:
                self._execute_block_req()
                return []
            elif recv_req.type == BlockReqType.UNBLOCK:
                self._execute_unblock_req()
                return []
        else:
            if self._state == _State.UNBLOCKED:
                return [recv_req]
            else:
                self._pending_reqs.append(recv_req)
                return []
```

## 请求流转过程

### 完整的请求处理流程

1. **接收阶段**: `recv_requests()` 从ZMQ管道接收请求
2. **预处理阶段**: `process_input_requests()` 进行基本检查和过滤
3. **分发阶段**: `TypeBasedDispatcher` 根据请求类型分发到对应处理方法
4. **处理阶段**: 各专门的处理方法创建`Req`对象并加入等待队列
5. **调度阶段**: 调度器从等待队列取出请求组成批次执行

### 输入数据结构

**TokenizedGenerateReqInput**：
```python
@dataclass
class TokenizedGenerateReqInput:
    rid: str                    # 请求ID
    input_text: str            # 输入文本
    input_ids: List[int]       # token化后的输入
    mm_inputs: dict            # 多模态输入
    sampling_params: SamplingParams  # 采样参数
    return_logprob: bool       # 是否返回log概率
    stream: bool               # 是否流式输出
    lora_id: Optional[str]     # LoRA适配器ID
    input_embeds: Optional[List] # 输入嵌入
    session_params: Optional[SessionParams]  # 会话参数
    custom_logit_processor: Optional[str]    # 自定义logit处理器
    bootstrap_host: Optional[str]  # 分离式推理主机
    bootstrap_port: Optional[int] # 分离式推理端口
    data_parallel_rank: Optional[int] # 数据并行rank
```

## 总结

SGLang调度器的请求处理机制具有以下特点：

1. **类型化分发**: 使用`TypeBasedDispatcher`根据请求类型自动分发
2. **队列管理**: 通过等待队列管理无法立即处理的请求
3. **会话支持**: 支持连续对话的会话管理
4. **流量控制**: 通过`SchedulerInputBlocker`实现请求阻塞
5. **多种请求类型**: 支持生成、嵌入、缓存控制、权重更新等多种请求
6. **错误处理**: 对队列满、资源不足等情况进行适当处理

这个设计确保了调度器能够高效处理各种类型的请求，同时保持良好的扩展性和可维护性。